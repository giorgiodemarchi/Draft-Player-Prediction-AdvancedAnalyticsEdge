{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/px/tjlhxsg56bg6d74d3c4cnhrc0000gn/T/ipykernel_54494/3729246849.py:2: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/CollegeBasketballPlayers2009-2021.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>team</th>\n",
       "      <th>conf</th>\n",
       "      <th>GP</th>\n",
       "      <th>Min_per</th>\n",
       "      <th>Ortg</th>\n",
       "      <th>usg</th>\n",
       "      <th>eFG</th>\n",
       "      <th>TS_per</th>\n",
       "      <th>ORB_per</th>\n",
       "      <th>DRB_per</th>\n",
       "      <th>AST_per</th>\n",
       "      <th>TO_per</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT_per</th>\n",
       "      <th>twoPM</th>\n",
       "      <th>twoPA</th>\n",
       "      <th>twoP_per</th>\n",
       "      <th>TPM</th>\n",
       "      <th>TPA</th>\n",
       "      <th>TP_per</th>\n",
       "      <th>blk_per</th>\n",
       "      <th>stl_per</th>\n",
       "      <th>ftr</th>\n",
       "      <th>yr</th>\n",
       "      <th>ht</th>\n",
       "      <th>num</th>\n",
       "      <th>porpag</th>\n",
       "      <th>adjoe</th>\n",
       "      <th>pfr</th>\n",
       "      <th>year</th>\n",
       "      <th>pid</th>\n",
       "      <th>type</th>\n",
       "      <th>Rec Rank</th>\n",
       "      <th>ast/tov</th>\n",
       "      <th>rimmade</th>\n",
       "      <th>rimmade+rimmiss</th>\n",
       "      <th>midmade</th>\n",
       "      <th>midmade+midmiss</th>\n",
       "      <th>rimmade/(rimmade+rimmiss)</th>\n",
       "      <th>midmade/(midmade+midmiss)</th>\n",
       "      <th>dunksmade</th>\n",
       "      <th>dunksmiss+dunksmade</th>\n",
       "      <th>dunksmade/(dunksmade+dunksmiss)</th>\n",
       "      <th>pick</th>\n",
       "      <th>drtg</th>\n",
       "      <th>adrtg</th>\n",
       "      <th>dporpag</th>\n",
       "      <th>stops</th>\n",
       "      <th>bpm</th>\n",
       "      <th>obpm</th>\n",
       "      <th>dbpm</th>\n",
       "      <th>gbpm</th>\n",
       "      <th>mp</th>\n",
       "      <th>ogbpm</th>\n",
       "      <th>dgbpm</th>\n",
       "      <th>oreb</th>\n",
       "      <th>dreb</th>\n",
       "      <th>treb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>pts</th>\n",
       "      <th>Unnamed: 64</th>\n",
       "      <th>Unnamed: 65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeAndrae Ross</td>\n",
       "      <td>South Alabama</td>\n",
       "      <td>SB</td>\n",
       "      <td>26</td>\n",
       "      <td>29.5</td>\n",
       "      <td>97.3</td>\n",
       "      <td>16.6</td>\n",
       "      <td>42.5</td>\n",
       "      <td>44.43</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>16.3</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0.714</td>\n",
       "      <td>26</td>\n",
       "      <td>68</td>\n",
       "      <td>0.382</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.1</td>\n",
       "      <td>So</td>\n",
       "      <td>2-Jun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258086</td>\n",
       "      <td>89.3938</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.823646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.321</td>\n",
       "      <td>108.527</td>\n",
       "      <td>0.893017</td>\n",
       "      <td>49.9644</td>\n",
       "      <td>-4.995140</td>\n",
       "      <td>-1.623360</td>\n",
       "      <td>-3.371780</td>\n",
       "      <td>-4.723150</td>\n",
       "      <td>14.5769</td>\n",
       "      <td>-2.781990</td>\n",
       "      <td>-1.941150</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>1.1923</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>3.8846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.22026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pooh Williams</td>\n",
       "      <td>Utah St.</td>\n",
       "      <td>WAC</td>\n",
       "      <td>34</td>\n",
       "      <td>60.9</td>\n",
       "      <td>108.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>52.4</td>\n",
       "      <td>54.48</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>0.667</td>\n",
       "      <td>56</td>\n",
       "      <td>113</td>\n",
       "      <td>0.496</td>\n",
       "      <td>20</td>\n",
       "      <td>51</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>27.4</td>\n",
       "      <td>So</td>\n",
       "      <td>4-Jun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.334920</td>\n",
       "      <td>100.0660</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2009</td>\n",
       "      <td>3</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.631621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.078</td>\n",
       "      <td>104.017</td>\n",
       "      <td>1.880030</td>\n",
       "      <td>111.9290</td>\n",
       "      <td>0.593024</td>\n",
       "      <td>1.385490</td>\n",
       "      <td>-0.792469</td>\n",
       "      <td>-0.300196</td>\n",
       "      <td>24.5294</td>\n",
       "      <td>-0.052263</td>\n",
       "      <td>-0.247934</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>1.2647</td>\n",
       "      <td>1.9412</td>\n",
       "      <td>1.8235</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>5.9412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.94375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jesus Verdejo</td>\n",
       "      <td>South Florida</td>\n",
       "      <td>BE</td>\n",
       "      <td>27</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.2</td>\n",
       "      <td>21.8</td>\n",
       "      <td>45.7</td>\n",
       "      <td>47.98</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>45</td>\n",
       "      <td>67</td>\n",
       "      <td>0.672</td>\n",
       "      <td>67</td>\n",
       "      <td>157</td>\n",
       "      <td>0.427</td>\n",
       "      <td>50</td>\n",
       "      <td>154</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>21.5</td>\n",
       "      <td>Sr</td>\n",
       "      <td>4-Jun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.274070</td>\n",
       "      <td>104.1070</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.081662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.556</td>\n",
       "      <td>102.154</td>\n",
       "      <td>2.763870</td>\n",
       "      <td>115.0210</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>1.024770</td>\n",
       "      <td>-1.021610</td>\n",
       "      <td>0.665065</td>\n",
       "      <td>33.1852</td>\n",
       "      <td>1.548230</td>\n",
       "      <td>-0.883163</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>2.9630</td>\n",
       "      <td>1.9630</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.1852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.92680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mike Hornbuckle</td>\n",
       "      <td>Pepperdine</td>\n",
       "      <td>WCC</td>\n",
       "      <td>30</td>\n",
       "      <td>44.5</td>\n",
       "      <td>97.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.6</td>\n",
       "      <td>53.69</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>23.8</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>0.519</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>0.397</td>\n",
       "      <td>28</td>\n",
       "      <td>62</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.6</td>\n",
       "      <td>Sr</td>\n",
       "      <td>4-Jun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.552857</td>\n",
       "      <td>93.2086</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.858</td>\n",
       "      <td>106.556</td>\n",
       "      <td>1.218710</td>\n",
       "      <td>84.1698</td>\n",
       "      <td>-0.977798</td>\n",
       "      <td>-0.502574</td>\n",
       "      <td>-0.475224</td>\n",
       "      <td>-0.736233</td>\n",
       "      <td>17.9667</td>\n",
       "      <td>-0.342775</td>\n",
       "      <td>-0.393459</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>2.1333</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>4.9333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.77427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony Brown</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>BW</td>\n",
       "      <td>33</td>\n",
       "      <td>56.2</td>\n",
       "      <td>96.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.8</td>\n",
       "      <td>54.31</td>\n",
       "      <td>8.3</td>\n",
       "      <td>18.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>22.7</td>\n",
       "      <td>64</td>\n",
       "      <td>114</td>\n",
       "      <td>0.561</td>\n",
       "      <td>93</td>\n",
       "      <td>176</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.8</td>\n",
       "      <td>Sr</td>\n",
       "      <td>8-Jun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.060130</td>\n",
       "      <td>97.8554</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.052</td>\n",
       "      <td>100.724</td>\n",
       "      <td>1.992790</td>\n",
       "      <td>128.0280</td>\n",
       "      <td>-1.836060</td>\n",
       "      <td>-1.946040</td>\n",
       "      <td>0.109983</td>\n",
       "      <td>-2.353180</td>\n",
       "      <td>22.9091</td>\n",
       "      <td>-1.684860</td>\n",
       "      <td>-0.668318</td>\n",
       "      <td>1.4242</td>\n",
       "      <td>3.3030</td>\n",
       "      <td>4.7273</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>7.5758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       player_name           team conf  GP  Min_per   Ortg   usg   eFG  \\\n",
       "0    DeAndrae Ross  South Alabama   SB  26     29.5   97.3  16.6  42.5   \n",
       "1    Pooh Williams       Utah St.  WAC  34     60.9  108.3  14.9  52.4   \n",
       "2    Jesus Verdejo  South Florida   BE  27     72.0   96.2  21.8  45.7   \n",
       "3  Mike Hornbuckle     Pepperdine  WCC  30     44.5   97.7  16.0  53.6   \n",
       "4    Anthony Brown        Pacific   BW  33     56.2   96.5  22.0  52.8   \n",
       "\n",
       "   TS_per  ORB_per  DRB_per  AST_per  TO_per  FTM  FTA  FT_per  twoPM  twoPA  \\\n",
       "0   44.43      1.6      4.6     15.8    16.3   10   14   0.714     26     68   \n",
       "1   54.48      3.8      6.3     13.6    19.8   30   45   0.667     56    113   \n",
       "2   47.98      2.1      8.0     14.7    15.9   45   67   0.672     67    157   \n",
       "3   53.69      4.1      9.4     13.7    23.8   14   27   0.519     25     63   \n",
       "4   54.31      8.3     18.6      8.2    22.7   64  114   0.561     93    176   \n",
       "\n",
       "   twoP_per  TPM  TPA  TP_per  blk_per  stl_per   ftr  yr     ht  num  \\\n",
       "0     0.382   13   39   0.333      0.3      1.5  13.1  So  2-Jun  NaN   \n",
       "1     0.496   20   51   0.392      1.0      1.1  27.4  So  4-Jun  NaN   \n",
       "2     0.427   50  154   0.325      0.0      0.9  21.5  Sr  4-Jun  NaN   \n",
       "3     0.397   28   62   0.452      0.8      1.9  21.6  Sr  4-Jun  NaN   \n",
       "4     0.528    0    0   0.000      1.9      1.3  64.8  Sr  8-Jun  NaN   \n",
       "\n",
       "     porpag     adjoe  pfr  year  pid type  Rec Rank   ast/tov  rimmade  \\\n",
       "0  0.258086   89.3938  2.5  2009    2  all       NaN  1.823646      NaN   \n",
       "1  1.334920  100.0660  3.4  2009    3  all       NaN  1.631621      NaN   \n",
       "2  2.274070  104.1070  1.7  2009    5  all       NaN  1.081662      NaN   \n",
       "3  0.552857   93.2086  2.0  2009    8  all       NaN  0.942830      NaN   \n",
       "4  1.060130   97.8554  3.8  2009    9  all       NaN  0.491229      NaN   \n",
       "\n",
       "   rimmade+rimmiss  midmade  midmade+midmiss  rimmade/(rimmade+rimmiss)  \\\n",
       "0              NaN      NaN              NaN                        NaN   \n",
       "1              NaN      NaN              NaN                        NaN   \n",
       "2              NaN      NaN              NaN                        NaN   \n",
       "3              NaN      NaN              NaN                        NaN   \n",
       "4              NaN      NaN              NaN                        NaN   \n",
       "\n",
       "   midmade/(midmade+midmiss)  dunksmade  dunksmiss+dunksmade  \\\n",
       "0                        NaN        NaN                  NaN   \n",
       "1                        NaN        NaN                  NaN   \n",
       "2                        NaN        NaN                  NaN   \n",
       "3                        NaN        NaN                  NaN   \n",
       "4                        NaN        NaN                  NaN   \n",
       "\n",
       "   dunksmade/(dunksmade+dunksmiss)  pick     drtg    adrtg   dporpag  \\\n",
       "0                              NaN   NaN  108.321  108.527  0.893017   \n",
       "1                              NaN   NaN  105.078  104.017  1.880030   \n",
       "2                              NaN   NaN  107.556  102.154  2.763870   \n",
       "3                              NaN   NaN  108.858  106.556  1.218710   \n",
       "4                              NaN   NaN  101.052  100.724  1.992790   \n",
       "\n",
       "      stops       bpm      obpm      dbpm      gbpm       mp     ogbpm  \\\n",
       "0   49.9644 -4.995140 -1.623360 -3.371780 -4.723150  14.5769 -2.781990   \n",
       "1  111.9290  0.593024  1.385490 -0.792469 -0.300196  24.5294 -0.052263   \n",
       "2  115.0210  0.003161  1.024770 -1.021610  0.665065  33.1852  1.548230   \n",
       "3   84.1698 -0.977798 -0.502574 -0.475224 -0.736233  17.9667 -0.342775   \n",
       "4  128.0280 -1.836060 -1.946040  0.109983 -2.353180  22.9091 -1.684860   \n",
       "\n",
       "      dgbpm    oreb    dreb    treb     ast     stl     blk      pts  \\\n",
       "0 -1.941150  0.1923  0.6154  0.8077  1.1923  0.3462  0.0385   3.8846   \n",
       "1 -0.247934  0.6765  1.2647  1.9412  1.8235  0.4118  0.2353   5.9412   \n",
       "2 -0.883163  0.6296  2.3333  2.9630  1.9630  0.4815  0.0000  12.1852   \n",
       "3 -0.393459  0.7000  1.4333  2.1333  1.1000  0.5667  0.1333   4.9333   \n",
       "4 -0.668318  1.4242  3.3030  4.7273  0.8485  0.4545  0.3333   7.5758   \n",
       "\n",
       "  Unnamed: 64  Unnamed: 65  \n",
       "0         NaN      6.22026  \n",
       "1         NaN      3.94375  \n",
       "2         NaN     10.92680  \n",
       "3         NaN      6.77427  \n",
       "4         NaN      0.00000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Players features dataset\n",
    "df = pd.read_csv('data/CollegeBasketballPlayers2009-2021.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pick</th>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year  2009  2010  2011  2012  2013  2014  2015  2016  2017  2018  2019  2020  \\\n",
       "pick    64    62    58    56    50    45    45    45    51    47    40    35   \n",
       "\n",
       "year  2021  \n",
       "pick    25  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "picked_first_round = df[df['pick']<=30]\n",
    "picked_first_round.groupby('year').count()[['pick']].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pick'] = df['pick'].fillna(0)\n",
    "\n",
    "df = df[df['pick']<=30]\n",
    "\n",
    "df['first_round_drafted'] = np.where((df['pick']<=30) & (df['pick']>0), 1, 0)\n",
    "\n",
    "df = df.drop('pick', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_round_drafted\n",
       "0    59626\n",
       "1      623\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first_round_drafted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'Unnamed: 64' : 'role'})\n",
    "df = df.drop('Unnamed: 65', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df[df.year != 2009]\n",
    "df = df.dropna(thresh=len(df.columns) - 9)\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Rec Rank\", \"dunksmade/(dunksmade+dunksmiss)\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yr',\n",
       " 'ht',\n",
       " 'num',\n",
       " 'ast/tov',\n",
       " 'rimmade',\n",
       " 'rimmade+rimmiss',\n",
       " 'midmade',\n",
       " 'midmade+midmiss',\n",
       " 'rimmade/(rimmade+rimmiss)',\n",
       " 'midmade/(midmade+midmiss)',\n",
       " 'dunksmade',\n",
       " 'dunksmiss+dunksmade',\n",
       " 'role']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yr\n",
       "Jr      14503\n",
       "Fr      14085\n",
       "So      12758\n",
       "Sr      12489\n",
       "57.1        1\n",
       "0           1\n",
       "42.9        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.yr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['yr'].isin([\"Fr\", \"So\", \"Jr\", \"Sr\"])]\n",
    "df['yr'] = df['yr'].map({\"Fr\": 1, \"So\": 2, \"Jr\": 3, \"Sr\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ht\n",
       "7-Jun     5448\n",
       "8-Jun     5333\n",
       "4-Jun     5219\n",
       "5-Jun     5209\n",
       "6-Jun     4975\n",
       "3-Jun     4967\n",
       "2-Jun     4476\n",
       "9-Jun     3917\n",
       "1-Jun     3337\n",
       "Jun-00    2805\n",
       "10-Jun    2464\n",
       "11-May    1383\n",
       "10-May    1240\n",
       "11-Jun    1091\n",
       "Jul-00     648\n",
       "9-May      540\n",
       "8-May      215\n",
       "1-Jul      200\n",
       "7-May       88\n",
       "2-Jul       84\n",
       "3-Jul       39\n",
       "6-May       36\n",
       "-           27\n",
       "Apr-00      16\n",
       "4-Jul       12\n",
       "6-Jul        7\n",
       "5-May        6\n",
       "2-May        4\n",
       "4-May        4\n",
       "5-Jul        3\n",
       "0            1\n",
       "1-May        1\n",
       "3-May        1\n",
       "5-Apr        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ht.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/px/tjlhxsg56bg6d74d3c4cnhrc0000gn/T/ipykernel_54494/3991656175.py:6: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['ht'] = df['ht'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "def split_letters_numbers(s):\n",
    "    letters = ''.join(re.findall(\"[a-zA-Z]+\", s))\n",
    "    numbers = ''.join(re.findall(\"[0-9]+\", s))\n",
    "    return letters, numbers\n",
    "\n",
    "df['ht'] = df['ht'].fillna(method='ffill')\n",
    "\n",
    "df[['ht_month', 'ht_day']] = df['ht'].astype(str).apply(lambda x: pd.Series(split_letters_numbers(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "1.0      2548\n",
       "5.0      2415\n",
       "2.0      2384\n",
       "3.0      2379\n",
       "0.0      2183\n",
       "         ... \n",
       "99.0        2\n",
       "99          1\n",
       "4A          1\n",
       "31/24       1\n",
       "26.0        1\n",
       "Name: count, Length: 77, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number(s):\n",
    "    return re.findall(r'[A-Za-z]+|\\d+', s)[0]\n",
    "\n",
    "df['num'] = df['num'].astype(str).apply(lambda x: pd.Series(get_number(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num'] = pd.to_numeric(df['num'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "role\n",
       "Wing G        12190\n",
       "PF/C           8846\n",
       "Combo G        8812\n",
       "C              7776\n",
       "Scoring PG     5691\n",
       "Wing F         4814\n",
       "Stretch 4      3124\n",
       "Pure PG        2453\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.role.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['role'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53706 entries, 4589 to 61057\n",
      "Data columns (total 65 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   player_name                53706 non-null  object \n",
      " 1   team                       53706 non-null  object \n",
      " 2   conf                       53706 non-null  object \n",
      " 3   GP                         53706 non-null  int64  \n",
      " 4   Min_per                    53706 non-null  float64\n",
      " 5   Ortg                       53706 non-null  float64\n",
      " 6   usg                        53706 non-null  float64\n",
      " 7   eFG                        53706 non-null  float64\n",
      " 8   TS_per                     53706 non-null  float64\n",
      " 9   ORB_per                    53706 non-null  float64\n",
      " 10  DRB_per                    53706 non-null  float64\n",
      " 11  AST_per                    53706 non-null  float64\n",
      " 12  TO_per                     53706 non-null  float64\n",
      " 13  FTM                        53706 non-null  int64  \n",
      " 14  FTA                        53706 non-null  int64  \n",
      " 15  FT_per                     53706 non-null  float64\n",
      " 16  twoPM                      53706 non-null  int64  \n",
      " 17  twoPA                      53706 non-null  int64  \n",
      " 18  twoP_per                   53706 non-null  float64\n",
      " 19  TPM                        53706 non-null  int64  \n",
      " 20  TPA                        53706 non-null  int64  \n",
      " 21  TP_per                     53706 non-null  float64\n",
      " 22  blk_per                    53706 non-null  float64\n",
      " 23  stl_per                    53706 non-null  float64\n",
      " 24  ftr                        53706 non-null  float64\n",
      " 25  yr                         53706 non-null  int64  \n",
      " 26  ht                         53706 non-null  object \n",
      " 27  num                        53706 non-null  float64\n",
      " 28  porpag                     53706 non-null  float64\n",
      " 29  adjoe                      53706 non-null  float64\n",
      " 30  pfr                        53706 non-null  float64\n",
      " 31  year                       53706 non-null  int64  \n",
      " 32  pid                        53706 non-null  int64  \n",
      " 33  type                       53706 non-null  object \n",
      " 34  ast/tov                    53706 non-null  float64\n",
      " 35  rimmade                    53706 non-null  float64\n",
      " 36  rimmade+rimmiss            53706 non-null  float64\n",
      " 37  midmade                    53706 non-null  float64\n",
      " 38  midmade+midmiss            53706 non-null  float64\n",
      " 39  rimmade/(rimmade+rimmiss)  53706 non-null  float64\n",
      " 40  midmade/(midmade+midmiss)  53706 non-null  float64\n",
      " 41  dunksmade                  53706 non-null  float64\n",
      " 42  dunksmiss+dunksmade        53706 non-null  float64\n",
      " 43  drtg                       53706 non-null  float64\n",
      " 44  adrtg                      53706 non-null  float64\n",
      " 45  dporpag                    53706 non-null  float64\n",
      " 46  stops                      53706 non-null  float64\n",
      " 47  bpm                        53706 non-null  float64\n",
      " 48  obpm                       53706 non-null  float64\n",
      " 49  dbpm                       53706 non-null  float64\n",
      " 50  gbpm                       53706 non-null  float64\n",
      " 51  mp                         53706 non-null  float64\n",
      " 52  ogbpm                      53706 non-null  float64\n",
      " 53  dgbpm                      53706 non-null  float64\n",
      " 54  oreb                       53706 non-null  float64\n",
      " 55  dreb                       53706 non-null  float64\n",
      " 56  treb                       53706 non-null  float64\n",
      " 57  ast                        53706 non-null  float64\n",
      " 58  stl                        53706 non-null  float64\n",
      " 59  blk                        53706 non-null  float64\n",
      " 60  pts                        53706 non-null  float64\n",
      " 61  role                       53706 non-null  object \n",
      " 62  first_round_drafted        53706 non-null  int64  \n",
      " 63  ht_month                   53706 non-null  object \n",
      " 64  ht_day                     53706 non-null  object \n",
      "dtypes: float64(46), int64(11), object(8)\n",
      "memory usage: 27.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns) == len(numerical_cols) + len(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['player_name', 'team', 'conf', 'ht', 'type', 'role', 'ht_month', 'ht_day']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe frequency encoding for team?\n",
    "#df = df.drop(['player_name', 'team', 'conf', 'ht', 'type'], axis=1)\n",
    "df = df.drop(['player_name', 'conf', 'ht', 'type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jun', 'May', 'Jul', 'Apr', '']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ht_month.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['ht_month'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '2', '5', '4', '11', '7', '6', '10', '8', '9', '00', '1']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ht_day.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['role', 'ht_month', 'ht_day','team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yr: 4\n",
      "year: 12\n",
      "first_round_drafted: 2\n"
     ]
    }
   ],
   "source": [
    "for col in numerical_cols:\n",
    "    num_unique = df[col].nunique()\n",
    "    if num_unique <= 25:\n",
    "        print(f\"{col}: {num_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yr\n",
       "3    14465\n",
       "1    14017\n",
       "2    12732\n",
       "4    12466\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.yr.value_counts()\n",
    "#leave like this since ordinal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2021    4612\n",
       "2017    4542\n",
       "2020    4530\n",
       "2016    4516\n",
       "2019    4510\n",
       "2018    4502\n",
       "2015    4496\n",
       "2014    4462\n",
       "2010    4435\n",
       "2013    4364\n",
       "2011    4360\n",
       "2012    4351\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "bol_cols = df.select_dtypes(include=['bool']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[bol_cols] = df[bol_cols].apply(lambda x: x.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53680, 439)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_cols = [col for col in df.columns if col.startswith('year_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2021 = df[df['year']==2021]\n",
    "df_2021 = df_2021.drop('year', axis=1)\n",
    "\n",
    "#find a way to keep this data?\n",
    "df = df[df['year']!=2021]\n",
    "df = df.drop('year', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39254, 437)\n",
      "(39254,)\n",
      "(9814, 437)\n",
      "(9814,)\n",
      "(4612, 437)\n",
      "(4612,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['first_round_drafted'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "test_df = df_2021\n",
    "\n",
    "train_df[cols] = scaler.fit_transform(train_df[cols])\n",
    "val_df[cols] = scaler.transform(val_df[cols])\n",
    "test_df[cols] = scaler.transform(df_2021[cols])\n",
    "\n",
    "X_train = train_df.drop(['first_round_drafted'], axis=1)\n",
    "y_train = train_df['first_round_drafted']\n",
    "\n",
    "X_val = val_df.drop(['first_round_drafted'], axis=1)\n",
    "y_val = val_df['first_round_drafted']\n",
    "\n",
    "X_test = test_df.drop(['first_round_drafted'], axis=1)\n",
    "y_test = test_df['first_round_drafted']\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(verbosity=2, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'learning_rate': np.arange(0.001, 0.1, 0.005), \n",
    "              'max_depth': [4, 5, 6, 7, 8],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [100, 200, 300, 500],\n",
    "              'alpha': np.arange(0, 2, 0.1),\n",
    "              'lambda' : np.arange(0,2,0.1)}\n",
    "\n",
    "xgb_grid = RandomizedSearchCV(model_xgb,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = 1,\n",
    "                        verbose=3,\n",
    "                        n_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.416 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.405 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.431 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.447 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.363 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.343 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.358 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.394 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.409 total time=   4.4s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.380 total time=   4.5s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.398 total time=   4.3s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.416 total time=   4.2s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.428 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.384 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.430 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.452 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.414 total time=   4.7s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.380 total time=   4.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.420 total time=   4.9s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.426 total time=   4.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.405 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.405 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.422 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.435 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.420 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.376 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.404 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.413 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.427 total time=   2.9s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.383 total time=   2.8s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.426 total time=   2.6s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.016, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.415 total time=   4.3s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.016, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.396 total time=   4.1s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.016, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.427 total time=   3.9s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.016, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.451 total time=   3.8s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.319 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.309 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.315 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.362 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.417 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.388 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.445 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.427 total time=   3.1s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.405 total time=   3.1s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.435 total time=   3.3s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.458 total time=   3.0s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.417 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.404 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.431 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.450 total time=   2.6s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.406 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.387 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.404 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.443 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.418 total time=   3.4s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.396 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.4s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.447 total time=   3.3s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.418 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.395 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.445 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.422 total time=   3.5s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.375 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.404 total time=   3.4s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.445 total time=   3.5s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.407 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.411 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.418 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.459 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.031, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.425 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.031, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.409 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.031, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.438 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.031, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.456 total time=   2.5s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.412 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.396 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.416 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.452 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.403 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.413 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.412 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.433 total time=   2.2s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.364 total time=   2.8s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.410 total time=   2.8s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.8s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.421 total time=   4.3s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.377 total time=   4.3s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.402 total time=   4.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.429 total time=   4.3s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.414 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.388 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.410 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.434 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.419 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.393 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.430 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.441 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.401 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.409 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.386 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.442 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.432 total time=   3.3s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.398 total time=   3.2s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.2s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.455 total time=   3.2s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.430 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.446 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.413 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.386 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.402 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.427 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.379 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.371 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.389 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.422 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.416 total time=   4.3s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.395 total time=   4.4s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.427 total time=   4.3s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.449 total time=   4.5s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.387 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.366 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.387 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.400 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.438 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.158 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.165 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.157 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.187 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.392 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.418 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.427 total time=   4.5s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.393 total time=   4.3s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.427 total time=   4.4s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.438 total time=   4.5s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.4, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.374 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.4, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.361 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.4, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.375 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.4, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.422 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.392 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.433 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.454 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.402 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.380 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.404 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.431 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.8, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.8, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.404 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.8, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.8, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.440 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.422 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.403 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.433 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.457 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.9, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.403 total time=   3.8s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.9, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.381 total time=   3.9s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.9, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.419 total time=   4.0s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.9, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.441 total time=   4.1s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.410 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.377 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.418 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.423 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.411 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.449 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.470 total time=   2.6s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.358 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.334 total time=   2.5s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.346 total time=   2.4s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.379 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.061, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.404 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.061, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.412 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.061, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.412 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.061, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.436 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.021, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.370 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.021, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.357 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.021, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.373 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.021, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.081, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.081, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.377 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.081, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.405 total time=   1.9s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.081, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.429 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.399 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.407 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.417 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.436 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.419 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.365 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.408 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.425 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.295 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.290 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.293 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.392 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.367 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.394 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.432 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.396 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.373 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.413 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.436 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.424 total time=   3.1s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.396 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.451 total time=   3.3s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.367 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.348 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.370 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.403 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.403 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.417 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.443 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.353 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.390 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.416 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.394 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.401 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.443 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.385 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.361 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.377 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.405 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.373 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.359 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.377 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.420 total time=   3.9s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.387 total time=   3.8s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.429 total time=   3.9s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.9s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.046, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.400 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.046, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.389 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.046, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.402 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.046, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.443 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.076, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.390 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.076, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.383 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.076, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.416 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.076, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.428 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.414 total time=   4.2s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.385 total time=   3.9s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.411 total time=   3.8s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.438 total time=   3.8s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.412 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.404 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.413 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.453 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.367 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.353 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.365 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.394 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.334 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.369 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.343 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.329 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.378 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.427 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.400 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.450 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.408 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.390 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.434 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.407 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.388 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.406 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.3, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.455 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.091 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.089 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.091 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.101 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.442 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.394 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.440 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.445 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.426 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.389 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.426 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.445 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.406 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.401 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.449 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.391 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.378 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.394 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.410 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.293 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.281 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.290 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.276 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.271 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.273 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.318 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.281 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.277 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.280 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.324 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.420 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.389 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.402 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.443 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.410 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.393 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.419 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.449 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.421 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.409 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.433 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.462 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.1, learning_rate=0.031, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.387 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.1, learning_rate=0.031, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.362 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.1, learning_rate=0.031, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.384 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.1, learning_rate=0.031, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.407 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.422 total time=   3.8s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.391 total time=   3.5s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.427 total time=   3.5s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.445 total time=   3.7s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.395 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.444 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.419 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.397 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.434 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.433 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.096, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.408 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.096, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.398 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.096, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.423 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.096, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.446 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.423 total time=   3.2s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.392 total time=   3.3s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.438 total time=   3.4s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.464 total time=   3.3s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.353 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.361 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.405 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.392 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.405 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.437 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.419 total time=   4.2s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.389 total time=   4.1s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.406 total time=   4.1s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.416 total time=   4.1s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.413 total time=   4.1s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.373 total time=   4.2s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.407 total time=   4.3s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.424 total time=   4.2s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.378 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.369 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.369 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.425 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.399 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.386 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.408 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.438 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.421 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.384 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.416 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.431 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.437 total time=   3.5s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.386 total time=   3.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.425 total time=   3.5s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.460 total time=   3.6s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.416 total time=   4.0s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.388 total time=   4.0s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.411 total time=   4.0s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.439 total time=   3.8s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.416 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.397 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.446 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.454 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.425 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.400 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.439 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.457 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.373 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.362 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.367 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.413 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.406 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.409 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.451 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.076, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.416 total time=   3.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.076, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.399 total time=   3.5s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.076, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.422 total time=   3.3s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.076, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.446 total time=   3.2s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.046 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.045 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.045 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.053 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.412 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.409 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.413 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.453 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.382 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.402 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.418 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.391 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.371 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.400 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.419 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.006, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.259 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.006, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.265 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.006, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.262 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.006, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.306 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.426 total time=   2.9s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.395 total time=   3.1s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.439 total time=   2.9s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.120 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.116 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.119 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.134 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.411 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.403 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.452 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.393 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.424 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.444 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.403 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.382 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.424 total time=   2.8s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.428 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.404 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.446 total time=   2.9s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.449 total time=   2.9s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.407 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.400 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.427 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.443 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.407 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.385 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.433 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.040 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.043 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.040 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.049 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.218 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.211 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.215 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.242 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.409 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.469 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.379 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.373 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.377 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.424 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.428 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.456 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.420 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.408 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.419 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.468 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.416 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.390 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.416 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.436 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.416 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.400 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.448 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.400 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.370 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.405 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.427 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.425 total time=   4.2s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.386 total time=   4.2s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.411 total time=   4.1s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.430 total time=   4.5s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.426 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.392 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.422 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.438 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.190 total time=   3.3s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.186 total time=   3.4s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.188 total time=   3.3s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.213 total time=   3.6s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.344 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.387 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.123 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.117 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.123 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.136 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.391 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.412 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.420 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.395 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.408 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.437 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.425 total time=   3.4s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.390 total time=   3.5s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.422 total time=   3.4s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.451 total time=   3.4s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.417 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.427 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.457 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.011, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.5s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.011, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.390 total time=   3.7s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.011, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.417 total time=   3.5s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.011, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.445 total time=   3.7s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.091, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.417 total time=   3.0s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.091, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.398 total time=   2.8s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.091, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.413 total time=   2.8s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.091, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.461 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.410 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.386 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.402 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.428 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.416 total time=   4.3s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.392 total time=   4.5s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.429 total time=   4.5s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.445 total time=   4.4s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.194 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.189 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.188 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.223 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.427 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.397 total time=   2.9s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.428 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.459 total time=   3.0s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.011, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.396 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.011, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.379 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.011, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.396 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.011, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.429 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.422 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.406 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.435 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.458 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.046, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.400 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.046, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.375 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.046, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.398 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.046, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.428 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.362 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.337 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.362 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.390 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.398 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.382 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.396 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.433 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.399 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.423 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.421 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.427 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.418 total time=   4.1s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.400 total time=   3.9s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.409 total time=   3.9s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.419 total time=   3.9s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.386 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.367 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.388 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.428 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.426 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.399 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.426 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.442 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.412 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.390 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.435 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.413 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.438 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.387 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.371 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.387 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.404 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.378 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.391 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.419 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.091, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.422 total time=   3.5s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.091, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.399 total time=   3.4s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.091, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.418 total time=   3.5s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.091, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.449 total time=   3.5s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.402 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.382 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.401 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.436 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.431 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.396 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.438 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.423 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.375 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.409 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.416 total time=   2.8s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.283 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.278 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.281 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.325 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.379 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.355 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.376 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.401 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.413 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.398 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.427 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.452 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.417 total time=   4.5s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.380 total time=   4.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.417 total time=   4.5s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.450 total time=   4.5s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.011, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.246 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.011, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.251 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.011, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.248 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.011, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.285 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.419 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.381 total time=   2.5s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.410 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.435 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.021, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.413 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.021, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.393 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.021, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.416 total time=   2.4s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.021, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.451 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.420 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.406 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.436 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.444 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.416 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.400 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.426 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.451 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.373 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.355 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.370 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.401 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.407 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.414 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.415 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.441 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.429 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.438 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.415 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.393 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.415 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.449 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.417 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.410 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.415 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.447 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.391 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.370 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.389 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.425 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.299 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.283 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.297 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.327 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.426 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.409 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.406 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.447 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.407 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.433 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.451 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.423 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.405 total time=   2.9s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.435 total time=   2.6s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.454 total time=   2.8s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.362 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.365 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.402 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.410 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.398 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.444 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.402 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.385 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.408 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.439 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.409 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.383 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.410 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.417 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.404 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.385 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.413 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.446 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.421 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.406 total time=   2.8s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.412 total time=   2.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.443 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.426 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.394 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.412 total time=   2.8s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.076, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.427 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.425 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.383 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.9s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.432 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.396 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.422 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.447 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.424 total time=   3.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.390 total time=   3.8s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.423 total time=   3.8s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.432 total time=   3.9s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.406 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.385 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.400 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.463 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.412 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.385 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.426 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.427 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.399 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.385 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.396 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.453 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.412 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.393 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.427 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.455 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.404 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.396 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.408 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.442 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.384 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.363 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.384 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.408 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.425 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.407 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.423 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.429 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.312 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.299 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.313 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.353 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.381 total time=   2.9s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.368 total time=   2.9s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.377 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.420 total time=   3.0s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.387 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.126 total time=   2.5s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.121 total time=   2.5s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.126 total time=   2.4s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.140 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.406 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.407 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.413 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.450 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.409 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.395 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.398 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.440 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.422 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.389 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.430 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.457 total time=   2.0s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.081, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.424 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.081, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.376 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.081, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.408 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.081, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.434 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.006, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.311 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.006, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.299 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.006, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.306 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.006, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.340 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.045 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.044 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.043 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.050 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.409 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.386 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.402 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.421 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.419 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.403 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.424 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.458 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.424 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.396 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.428 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.454 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.417 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.384 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.447 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.418 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.369 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.408 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.428 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.426 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.370 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.407 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.416 total time=   2.6s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.198 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.197 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.196 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.229 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.393 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.432 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.446 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.427 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.395 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.416 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.400 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.415 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.427 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.424 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.396 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.448 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.453 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.421 total time=   2.8s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.410 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.441 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.453 total time=   2.6s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.400 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.375 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.394 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.432 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.410 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.399 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.440 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.414 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.406 total time=   1.8s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.380 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.366 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.386 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.417 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.423 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.406 total time=   2.6s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.444 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.463 total time=   3.0s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.340 total time=   2.5s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.326 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.334 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.367 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.291 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.283 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.291 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.322 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.420 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.391 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.404 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.429 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.409 total time=   4.3s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.393 total time=   4.3s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.394 total time=   4.3s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.429 total time=   4.3s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.413 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.406 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.424 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.441 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.419 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.398 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.412 total time=   2.8s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.437 total time=   2.9s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.420 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.398 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.420 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.426 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.416 total time=   3.8s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.406 total time=   3.8s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.423 total time=   3.8s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.440 total time=   3.7s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.427 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.393 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.433 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.425 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.394 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.429 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.456 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.105 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.106 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.105 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.123 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.424 total time=   3.6s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.394 total time=   3.9s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.439 total time=   4.2s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.452 total time=   4.0s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.393 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.371 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.429 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.417 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.396 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.421 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.457 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.410 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.384 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.423 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.426 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.406 total time=   2.6s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.447 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.464 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.3, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.417 total time=   3.5s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.3, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.403 total time=   3.3s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.3, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.412 total time=   3.4s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.3, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.452 total time=   3.6s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.389 total time=   1.8s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.419 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.445 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.421 total time=   4.6s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.379 total time=   4.3s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.417 total time=   4.3s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.431 total time=   4.2s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.278 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.273 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.278 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.407 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.374 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.401 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.422 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.399 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.374 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.400 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.418 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.389 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.414 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.401 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.433 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.450 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.390 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.391 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.397 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.439 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.419 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.412 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.438 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.439 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.413 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.389 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.414 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.437 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.419 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.399 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.416 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.440 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.9s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.388 total time=   3.7s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.412 total time=   3.6s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.426 total time=   3.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.430 total time=   3.2s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.414 total time=   3.3s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.438 total time=   3.2s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.453 total time=   3.2s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.046, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.420 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.046, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.394 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.046, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.427 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.046, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.436 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.373 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.366 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.375 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.409 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.414 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.412 total time=   2.6s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.418 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.1, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.460 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.194 total time=   3.6s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.189 total time=   3.8s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.193 total time=   3.6s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.215 total time=   3.7s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.392 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.400 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.414 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.391 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.428 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.447 total time=   2.0s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.417 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.395 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.430 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.453 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.421 total time=   4.6s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.396 total time=   4.7s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.395 total time=   4.4s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.418 total time=   4.5s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.113 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.111 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.112 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.128 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.402 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.376 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.397 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.435 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.403 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.407 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.419 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.462 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.417 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.396 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.432 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.450 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.349 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.332 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.341 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.381 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.412 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.379 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.403 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.415 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.396 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.398 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.391 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.443 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.1, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.420 total time=   4.3s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.1, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.379 total time=   4.3s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.1, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.420 total time=   4.4s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.1, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.428 total time=   4.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.083 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.081 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.084 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.093 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.341 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.343 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.390 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.046 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.045 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.047 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.051 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.5, learning_rate=0.066, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.426 total time=   2.9s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.5, learning_rate=0.066, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.402 total time=   3.6s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.5, learning_rate=0.066, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.428 total time=   3.2s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.5, learning_rate=0.066, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.427 total time=   3.1s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.408 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.401 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.418 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.450 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.425 total time=   3.2s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.404 total time=   3.2s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.442 total time=   3.4s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.453 total time=   3.3s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.076, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.076, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.408 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.076, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.411 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.076, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.444 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.400 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.389 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.409 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.439 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.378 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.413 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.418 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.406 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.386 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.407 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.438 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.402 total time=   5.1s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.398 total time=   5.3s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.404 total time=   5.1s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.426 total time=   5.1s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.201 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.197 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.197 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.225 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.368 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.359 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.377 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.396 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.407 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.393 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.430 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.450 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.075 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.077 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.075 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.089 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.407 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.414 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.409 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.441 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.419 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.398 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.413 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.437 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.323 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.322 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.320 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.371 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.031, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.355 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.031, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.346 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.031, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.358 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.031, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.404 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.399 total time=   2.5s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.374 total time=   2.4s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.397 total time=   2.4s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.428 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.408 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.385 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.443 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.431 total time=   4.0s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.404 total time=   4.1s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.429 total time=   4.1s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.450 total time=   3.9s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.425 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.401 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.441 total time=   2.8s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.465 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.424 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.381 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.420 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.417 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.410 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.450 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.420 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.381 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.400 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.416 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.373 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.355 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.376 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.425 total time=   4.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.375 total time=   4.3s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.402 total time=   4.4s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.421 total time=   4.4s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.422 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.398 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.423 total time=   1.9s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.453 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.428 total time=   4.7s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.387 total time=   4.6s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.420 total time=   4.2s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.455 total time=   4.7s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.418 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.391 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.426 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.453 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.393 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.369 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.387 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.422 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.413 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.392 total time=   2.8s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.413 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.429 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.066, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.405 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.066, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.393 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.066, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.066, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.441 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.415 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.393 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.426 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.451 total time=   2.0s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.384 total time=   3.1s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.365 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.376 total time=   3.3s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.416 total time=   3.3s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.021, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.423 total time=   3.3s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.021, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.395 total time=   3.3s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.021, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.426 total time=   3.3s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.021, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.450 total time=   3.2s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.410 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.386 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.402 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.424 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.380 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.428 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.435 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.424 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.384 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.408 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.436 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.424 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.391 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.400 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.440 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.0, learning_rate=0.001, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.128 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.0, learning_rate=0.001, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.127 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.0, learning_rate=0.001, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.127 total time=   1.9s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.0, learning_rate=0.001, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.145 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.420 total time=   3.6s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.389 total time=   3.6s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.416 total time=   3.6s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.443 total time=   3.6s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.290 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.280 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.290 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.322 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.091 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.088 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.090 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.001, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.102 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.091, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.417 total time=   2.9s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.091, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.397 total time=   3.1s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.091, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.400 total time=   3.0s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.091, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.430 total time=   3.0s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.399 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.438 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.452 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.428 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.392 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.403 total time=   2.6s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.438 total time=   2.5s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.426 total time=   2.9s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.401 total time=   2.9s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.433 total time=   2.9s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.454 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.364 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.352 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.359 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.405 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.417 total time=   4.2s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.383 total time=   4.4s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.419 total time=   4.3s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.440 total time=   4.5s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.418 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.395 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.408 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.424 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.409 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.419 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.461 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.308 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.286 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.301 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.006, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.332 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.419 total time=   3.7s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.402 total time=   3.4s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.416 total time=   3.6s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.432 total time=   3.6s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.410 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.388 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.396 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.438 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.408 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.443 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.396 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.455 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.396 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.391 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.398 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.421 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.409 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.427 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.466 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.414 total time=   2.8s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.383 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.410 total time=   2.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.429 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.412 total time=   4.8s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.391 total time=   4.8s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.402 total time=   4.8s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.423 total time=   5.1s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.346 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.333 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.343 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.372 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.420 total time=   3.6s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.387 total time=   3.9s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.421 total time=   4.4s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.448 total time=   4.1s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.016, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.419 total time=   2.9s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.016, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.390 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.016, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.417 total time=   3.1s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.016, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.453 total time=   3.1s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.421 total time=   3.1s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.384 total time=   3.0s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.416 total time=   2.9s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.429 total time=   3.1s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.418 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.397 total time=   3.2s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.415 total time=   3.4s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.429 total time=   4.9s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.415 total time=   2.9s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.401 total time=   2.9s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.0s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.455 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.395 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.400 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.433 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.392 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.441 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.395 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.400 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.402 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.448 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.083 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.080 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.082 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.093 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.6, learning_rate=0.021, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.416 total time=   3.4s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.6, learning_rate=0.021, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.402 total time=   2.9s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.6, learning_rate=0.021, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.425 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.6, learning_rate=0.021, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.455 total time=   3.0s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.400 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.432 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.389 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.382 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.378 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.429 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.8, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.418 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.8, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.392 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.8, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.404 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.8, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.430 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.407 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.400 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.445 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.422 total time=   4.4s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.402 total time=   4.0s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.427 total time=   4.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.438 total time=   4.0s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.417 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.393 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.422 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.443 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.412 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.378 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.407 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.440 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.423 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.400 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.424 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.448 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.428 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.385 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.444 total time=   2.6s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.054 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.052 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.053 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.060 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.418 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.384 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.413 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.429 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.419 total time=   2.9s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.380 total time=   2.9s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.418 total time=   3.0s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.430 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.419 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.383 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.409 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.433 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.411 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.398 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.452 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.417 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.412 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.436 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.455 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.422 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.409 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.431 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.447 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.295 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.285 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.292 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.326 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.056, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.388 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.056, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.373 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.056, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.384 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.056, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.434 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.407 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.395 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.414 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.440 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.172 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.172 total time=   2.8s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.171 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.198 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.419 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.382 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.9s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.426 total time=   2.0s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.414 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.402 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.450 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.394 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.425 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.455 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.418 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.384 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.403 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.434 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.418 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.399 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.417 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.438 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.401 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.381 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.395 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.424 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.422 total time=   4.4s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.378 total time=   4.2s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.415 total time=   4.2s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.423 total time=   4.5s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.383 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.379 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.384 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.432 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.416 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.394 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.418 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.457 total time=   2.6s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.400 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.373 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.424 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.417 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.412 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.384 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.396 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.431 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.357 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.345 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.374 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.397 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.425 total time=   4.6s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.389 total time=   4.4s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.421 total time=   4.3s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.046, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.431 total time=   4.5s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.091, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.423 total time=   3.5s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.091, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.399 total time=   3.5s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.091, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.405 total time=   3.5s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.091, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.428 total time=   3.7s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.418 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.394 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.427 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.457 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.399 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.368 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.398 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.424 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.047 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.047 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.046 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.053 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.433 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.399 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.442 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.392 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.378 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.391 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.438 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.398 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.427 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.446 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.415 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.400 total time=   2.8s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.421 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.442 total time=   2.6s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.425 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.397 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.423 total time=   2.8s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.452 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.418 total time=   3.4s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.389 total time=   3.2s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.416 total time=   3.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.454 total time=   3.2s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.403 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.392 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.412 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.445 total time=   2.0s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.399 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.419 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.440 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.173 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.175 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.172 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.199 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.425 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.412 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.440 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.437 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.081, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.425 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.081, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.395 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.081, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.081, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.450 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.379 total time=   3.1s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.364 total time=   2.9s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.373 total time=   3.1s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.413 total time=   3.0s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.419 total time=   4.1s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.396 total time=   4.0s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.422 total time=   4.3s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.456 total time=   4.1s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.412 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.385 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.414 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.452 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.400 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.428 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.452 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.091, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.402 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.091, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.375 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.091, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.392 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.091, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.412 total time=   2.0s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.423 total time=   4.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.387 total time=   4.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.425 total time=   4.3s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.446 total time=   4.5s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.411 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.411 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.434 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.465 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.419 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.405 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.428 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.449 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.427 total time=   3.0s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.393 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.430 total time=   3.3s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.457 total time=   3.3s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.382 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.431 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.393 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.371 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.406 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.387 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.422 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.446 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.412 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.404 total time=   1.8s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.438 total time=   1.9s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.463 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.412 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.383 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.393 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.076, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.447 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.414 total time=   2.9s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.407 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.419 total time=   3.0s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.450 total time=   3.1s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.419 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.388 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.405 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.441 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.406 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.367 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.403 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.438 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.432 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.388 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.418 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.426 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.418 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.402 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.434 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.444 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.432 total time=   4.3s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.385 total time=   4.0s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.411 total time=   4.2s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.426 total time=   4.1s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.429 total time=   2.5s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.397 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.420 total time=   2.5s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.438 total time=   2.5s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.206 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.198 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.206 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.229 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.374 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.428 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.425 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.400 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.430 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.451 total time=   2.5s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.379 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.363 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.382 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.420 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.423 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.394 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.423 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.435 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.413 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.384 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.409 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.417 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.393 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.422 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.449 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.425 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.414 total time=   2.4s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.433 total time=   2.8s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.452 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.128 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.125 total time=   2.6s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.128 total time=   2.5s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.142 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.407 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.389 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.422 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.438 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.413 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.402 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.425 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.448 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.382 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.405 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.443 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.433 total time=   3.3s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.397 total time=   3.2s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.430 total time=   3.1s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.449 total time=   3.0s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.413 total time=   3.1s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.408 total time=   3.0s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.412 total time=   3.0s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.446 total time=   3.5s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.412 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.396 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.408 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.444 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.403 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.422 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.446 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.387 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.377 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.383 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.433 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.401 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.428 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.391 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.081, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.443 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.421 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.396 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.429 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.459 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.336 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.322 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.371 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.406 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.391 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.439 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.408 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.384 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.412 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.413 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.412 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.450 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.415 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.392 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.419 total time=   2.5s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.021, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.435 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.381 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.368 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.385 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.429 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.375 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.361 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.373 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.415 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.416 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.404 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.438 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.459 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.056, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.427 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.056, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.399 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.056, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.442 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.056, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.447 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.398 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.393 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.407 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.456 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.419 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.401 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.424 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.3, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.454 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.415 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.392 total time=   2.6s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.416 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.437 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.411 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.390 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.413 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.445 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.418 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.399 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.425 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.441 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.1, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.388 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.1, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.370 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.1, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.397 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.1, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.416 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.127 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.122 total time=   2.5s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.125 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.142 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.427 total time=   4.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.392 total time=   4.2s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.431 total time=   3.9s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.429 total time=   4.2s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.342 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.335 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.387 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.413 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.400 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.414 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.438 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.411 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.400 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.405 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.446 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.413 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.390 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.403 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.418 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.195 total time=   3.1s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.193 total time=   3.1s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.190 total time=   3.3s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.220 total time=   3.1s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.061, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.409 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.061, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.390 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.061, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.406 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.061, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.428 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.415 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.377 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.397 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.427 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.066, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.410 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.066, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.399 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.066, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.415 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.066, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.437 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.437 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.418 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.418 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.459 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.427 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.395 total time=   2.5s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.425 total time=   2.5s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.438 total time=   2.5s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.413 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.401 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.427 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.451 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.425 total time=   3.6s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.385 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.444 total time=   3.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.434 total time=   4.5s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.382 total time=   4.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.418 total time=   4.4s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.435 total time=   4.8s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.391 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.366 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.396 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.426 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.418 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.372 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.411 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.451 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.412 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.390 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.414 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.445 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.389 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.376 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.427 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.397 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.375 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.393 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.425 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.325 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.308 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.323 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.359 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.419 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.404 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.429 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.452 total time=   2.2s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.092 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.091 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.091 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.103 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.394 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.406 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.408 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.439 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.425 total time=   2.5s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.406 total time=   2.9s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.432 total time=   2.4s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.450 total time=   2.6s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.420 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.382 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.409 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.441 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.417 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.389 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.411 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.445 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.427 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.393 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.428 total time=   2.5s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.440 total time=   2.5s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.423 total time=   2.8s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.377 total time=   2.8s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.415 total time=   3.0s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.436 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.416 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.396 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.421 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.456 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.410 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.368 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.407 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.416 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.419 total time=   2.9s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.391 total time=   3.0s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.423 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.443 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.426 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.394 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.414 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.428 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.417 total time=   3.3s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.389 total time=   3.2s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.414 total time=   3.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.427 total time=   3.1s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.424 total time=   2.5s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.393 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.423 total time=   2.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.421 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.394 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.394 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.394 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.441 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.412 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.410 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.410 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.447 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.384 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.373 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.373 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.430 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.411 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.379 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.413 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.438 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.376 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.355 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.382 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.399 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.397 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.380 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.401 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.432 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.088 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.086 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.088 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.098 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.416 total time=   3.7s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.400 total time=   3.8s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.435 total time=   3.6s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.457 total time=   3.4s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.001, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.040 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.001, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.042 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.001, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.039 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.001, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.048 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.424 total time=   4.2s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.400 total time=   4.0s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.428 total time=   4.1s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.447 total time=   4.1s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.364 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.343 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.362 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.397 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.362 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.355 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.388 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.368 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.354 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.371 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.405 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.425 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.402 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.417 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.442 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.405 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.386 total time=   2.6s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.414 total time=   2.5s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.440 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.418 total time=   4.4s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.385 total time=   4.4s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.415 total time=   4.2s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.445 total time=   4.3s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.401 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.401 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.418 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.424 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.411 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.380 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.394 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.434 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.415 total time=   3.0s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.388 total time=   2.9s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.408 total time=   2.8s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.425 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.401 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.383 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.400 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.434 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.362 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.343 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.358 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.401 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.421 total time=   3.4s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.400 total time=   3.4s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.417 total time=   3.6s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.441 total time=   3.5s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.422 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.394 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.423 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.436 total time=   1.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=4,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=&#x27;cuda&#x27;,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rat...\n",
       "                                        &#x27;lambda&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
       "       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]),\n",
       "                                        &#x27;learning_rate&#x27;: array([0.001, 0.006, 0.011, 0.016, 0.021, 0.026, 0.031, 0.036, 0.041,\n",
       "       0.046, 0.051, 0.056, 0.061, 0.066, 0.071, 0.076, 0.081, 0.086,\n",
       "       0.091, 0.096]),\n",
       "                                        &#x27;max_depth&#x27;: [4, 5, 6, 7, 8],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 500],\n",
       "                                        &#x27;subsample&#x27;: [0.7]},\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=4,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=&#x27;cuda&#x27;,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rat...\n",
       "                                        &#x27;lambda&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
       "       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]),\n",
       "                                        &#x27;learning_rate&#x27;: array([0.001, 0.006, 0.011, 0.016, 0.021, 0.026, 0.031, 0.036, 0.041,\n",
       "       0.046, 0.051, 0.056, 0.061, 0.066, 0.071, 0.076, 0.081, 0.086,\n",
       "       0.091, 0.096]),\n",
       "                                        &#x27;max_depth&#x27;: [4, 5, 6, 7, 8],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 500],\n",
       "                                        &#x27;subsample&#x27;: [0.7]},\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=4,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device='cuda',\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rat...\n",
       "                                        'lambda': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
       "       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]),\n",
       "                                        'learning_rate': array([0.001, 0.006, 0.011, 0.016, 0.021, 0.026, 0.031, 0.036, 0.041,\n",
       "       0.046, 0.051, 0.056, 0.061, 0.066, 0.071, 0.076, 0.081, 0.086,\n",
       "       0.091, 0.096]),\n",
       "                                        'max_depth': [4, 5, 6, 7, 8],\n",
       "                                        'min_child_weight': [1, 2, 3, 4, 5],\n",
       "                                        'n_estimators': [100, 200, 300, 500],\n",
       "                                        'subsample': [0.7]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_round_drafted\n",
       "0.0    16\n",
       "1.0    14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba = xgb_grid.predict(X_test)\n",
    "pred_proba_df = pd.DataFrame(predicted_proba)\n",
    "pred_proba_df.columns = ['pred-prob']\n",
    "df_2021 = df_2021.reset_index()\n",
    "\n",
    "merged_df = df_2021.merge(pred_proba_df, left_index=True, right_index=True)\n",
    "\n",
    "selected_by_model = merged_df.sort_values('pred-prob', ascending=False).head(30)\n",
    "selected_by_model.first_round_drafted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>Min_per</th>\n",
       "      <th>Ortg</th>\n",
       "      <th>usg</th>\n",
       "      <th>eFG</th>\n",
       "      <th>TS_per</th>\n",
       "      <th>ORB_per</th>\n",
       "      <th>DRB_per</th>\n",
       "      <th>AST_per</th>\n",
       "      <th>TO_per</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT_per</th>\n",
       "      <th>twoPM</th>\n",
       "      <th>twoPA</th>\n",
       "      <th>twoP_per</th>\n",
       "      <th>TPM</th>\n",
       "      <th>TPA</th>\n",
       "      <th>TP_per</th>\n",
       "      <th>blk_per</th>\n",
       "      <th>stl_per</th>\n",
       "      <th>ftr</th>\n",
       "      <th>yr</th>\n",
       "      <th>num</th>\n",
       "      <th>porpag</th>\n",
       "      <th>adjoe</th>\n",
       "      <th>pfr</th>\n",
       "      <th>pid</th>\n",
       "      <th>ast/tov</th>\n",
       "      <th>rimmade</th>\n",
       "      <th>rimmade+rimmiss</th>\n",
       "      <th>midmade</th>\n",
       "      <th>midmade+midmiss</th>\n",
       "      <th>rimmade/(rimmade+rimmiss)</th>\n",
       "      <th>midmade/(midmade+midmiss)</th>\n",
       "      <th>dunksmade</th>\n",
       "      <th>dunksmiss+dunksmade</th>\n",
       "      <th>drtg</th>\n",
       "      <th>adrtg</th>\n",
       "      <th>dporpag</th>\n",
       "      <th>stops</th>\n",
       "      <th>bpm</th>\n",
       "      <th>obpm</th>\n",
       "      <th>dbpm</th>\n",
       "      <th>gbpm</th>\n",
       "      <th>mp</th>\n",
       "      <th>ogbpm</th>\n",
       "      <th>dgbpm</th>\n",
       "      <th>oreb</th>\n",
       "      <th>dreb</th>\n",
       "      <th>treb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>pts</th>\n",
       "      <th>first_round_drafted</th>\n",
       "      <th>role_Combo G</th>\n",
       "      <th>role_PF/C</th>\n",
       "      <th>role_Pure PG</th>\n",
       "      <th>role_Scoring PG</th>\n",
       "      <th>role_Stretch 4</th>\n",
       "      <th>role_Wing F</th>\n",
       "      <th>role_Wing G</th>\n",
       "      <th>ht_month_Jul</th>\n",
       "      <th>ht_month_Jun</th>\n",
       "      <th>ht_month_May</th>\n",
       "      <th>ht_day_1</th>\n",
       "      <th>ht_day_10</th>\n",
       "      <th>ht_day_11</th>\n",
       "      <th>ht_day_2</th>\n",
       "      <th>ht_day_3</th>\n",
       "      <th>ht_day_4</th>\n",
       "      <th>ht_day_5</th>\n",
       "      <th>ht_day_6</th>\n",
       "      <th>ht_day_7</th>\n",
       "      <th>ht_day_8</th>\n",
       "      <th>ht_day_9</th>\n",
       "      <th>team_Air Force</th>\n",
       "      <th>team_Akron</th>\n",
       "      <th>team_Alabama</th>\n",
       "      <th>team_Alabama A&amp;M</th>\n",
       "      <th>team_Alabama St.</th>\n",
       "      <th>team_Albany</th>\n",
       "      <th>team_Alcorn St.</th>\n",
       "      <th>team_American</th>\n",
       "      <th>team_Appalachian St.</th>\n",
       "      <th>team_Arizona</th>\n",
       "      <th>team_Arizona St.</th>\n",
       "      <th>team_Arkansas</th>\n",
       "      <th>team_Arkansas Little Rock</th>\n",
       "      <th>team_Arkansas Pine Bluff</th>\n",
       "      <th>team_Arkansas St.</th>\n",
       "      <th>team_Army</th>\n",
       "      <th>team_Auburn</th>\n",
       "      <th>team_Austin Peay</th>\n",
       "      <th>team_BYU</th>\n",
       "      <th>team_Ball St.</th>\n",
       "      <th>team_Baylor</th>\n",
       "      <th>team_Bellarmine</th>\n",
       "      <th>team_Belmont</th>\n",
       "      <th>team_Bethune Cookman</th>\n",
       "      <th>team_Binghamton</th>\n",
       "      <th>team_Boise St.</th>\n",
       "      <th>team_Boston College</th>\n",
       "      <th>team_Boston University</th>\n",
       "      <th>team_Bowling Green</th>\n",
       "      <th>team_Bradley</th>\n",
       "      <th>team_Brown</th>\n",
       "      <th>team_Bryant</th>\n",
       "      <th>team_Bucknell</th>\n",
       "      <th>team_Buffalo</th>\n",
       "      <th>team_Butler</th>\n",
       "      <th>team_Cal Baptist</th>\n",
       "      <th>team_Cal Poly</th>\n",
       "      <th>team_Cal St. Bakersfield</th>\n",
       "      <th>team_Cal St. Fullerton</th>\n",
       "      <th>team_Cal St. Northridge</th>\n",
       "      <th>team_California</th>\n",
       "      <th>team_Campbell</th>\n",
       "      <th>team_Canisius</th>\n",
       "      <th>team_Centenary</th>\n",
       "      <th>team_Central Arkansas</th>\n",
       "      <th>team_Central Connecticut</th>\n",
       "      <th>team_Central Michigan</th>\n",
       "      <th>team_Charleston Southern</th>\n",
       "      <th>team_Charlotte</th>\n",
       "      <th>team_Chattanooga</th>\n",
       "      <th>team_Chicago St.</th>\n",
       "      <th>team_Cincinnati</th>\n",
       "      <th>team_Clemson</th>\n",
       "      <th>team_Cleveland St.</th>\n",
       "      <th>team_Coastal Carolina</th>\n",
       "      <th>team_Colgate</th>\n",
       "      <th>team_College of Charleston</th>\n",
       "      <th>team_Colorado</th>\n",
       "      <th>team_Colorado St.</th>\n",
       "      <th>team_Columbia</th>\n",
       "      <th>team_Connecticut</th>\n",
       "      <th>team_Coppin St.</th>\n",
       "      <th>team_Cornell</th>\n",
       "      <th>team_Creighton</th>\n",
       "      <th>team_Dartmouth</th>\n",
       "      <th>team_Davidson</th>\n",
       "      <th>team_Dayton</th>\n",
       "      <th>team_DePaul</th>\n",
       "      <th>team_Delaware</th>\n",
       "      <th>team_Delaware St.</th>\n",
       "      <th>team_Denver</th>\n",
       "      <th>team_Detroit</th>\n",
       "      <th>team_Dixie St.</th>\n",
       "      <th>team_Drake</th>\n",
       "      <th>team_Drexel</th>\n",
       "      <th>team_Duke</th>\n",
       "      <th>team_Duquesne</th>\n",
       "      <th>team_East Carolina</th>\n",
       "      <th>team_East Tennessee St.</th>\n",
       "      <th>team_Eastern Illinois</th>\n",
       "      <th>team_Eastern Kentucky</th>\n",
       "      <th>team_Eastern Michigan</th>\n",
       "      <th>team_Eastern Washington</th>\n",
       "      <th>team_Elon</th>\n",
       "      <th>team_Evansville</th>\n",
       "      <th>team_FIU</th>\n",
       "      <th>team_Fairfield</th>\n",
       "      <th>team_Fairleigh Dickinson</th>\n",
       "      <th>team_Florida</th>\n",
       "      <th>team_Florida A&amp;M</th>\n",
       "      <th>team_Florida Atlantic</th>\n",
       "      <th>team_Florida Gulf Coast</th>\n",
       "      <th>team_Florida St.</th>\n",
       "      <th>team_Fordham</th>\n",
       "      <th>team_Fort Wayne</th>\n",
       "      <th>team_Fresno St.</th>\n",
       "      <th>team_Furman</th>\n",
       "      <th>team_Gardner Webb</th>\n",
       "      <th>team_George Mason</th>\n",
       "      <th>team_George Washington</th>\n",
       "      <th>team_Georgetown</th>\n",
       "      <th>team_Georgia</th>\n",
       "      <th>team_Georgia Southern</th>\n",
       "      <th>team_Georgia St.</th>\n",
       "      <th>team_Georgia Tech</th>\n",
       "      <th>team_Gonzaga</th>\n",
       "      <th>team_Grambling St.</th>\n",
       "      <th>team_Grand Canyon</th>\n",
       "      <th>team_Green Bay</th>\n",
       "      <th>team_Hampton</th>\n",
       "      <th>team_Hartford</th>\n",
       "      <th>team_Harvard</th>\n",
       "      <th>team_Hawaii</th>\n",
       "      <th>team_High Point</th>\n",
       "      <th>team_Hofstra</th>\n",
       "      <th>team_Holy Cross</th>\n",
       "      <th>team_Houston</th>\n",
       "      <th>team_Houston Baptist</th>\n",
       "      <th>team_Howard</th>\n",
       "      <th>team_IPFW</th>\n",
       "      <th>team_IUPUI</th>\n",
       "      <th>team_Idaho</th>\n",
       "      <th>team_Idaho St.</th>\n",
       "      <th>team_Illinois</th>\n",
       "      <th>team_Illinois Chicago</th>\n",
       "      <th>team_Illinois St.</th>\n",
       "      <th>team_Incarnate Word</th>\n",
       "      <th>team_Indiana</th>\n",
       "      <th>team_Indiana St.</th>\n",
       "      <th>team_Iona</th>\n",
       "      <th>team_Iowa</th>\n",
       "      <th>team_Iowa St.</th>\n",
       "      <th>team_Jackson St.</th>\n",
       "      <th>team_Jacksonville</th>\n",
       "      <th>team_Jacksonville St.</th>\n",
       "      <th>team_James Madison</th>\n",
       "      <th>team_Kansas</th>\n",
       "      <th>team_Kansas St.</th>\n",
       "      <th>team_Kennesaw St.</th>\n",
       "      <th>team_Kent St.</th>\n",
       "      <th>team_Kentucky</th>\n",
       "      <th>team_LIU Brooklyn</th>\n",
       "      <th>team_LSU</th>\n",
       "      <th>team_La Salle</th>\n",
       "      <th>team_Lafayette</th>\n",
       "      <th>team_Lamar</th>\n",
       "      <th>team_Lehigh</th>\n",
       "      <th>team_Liberty</th>\n",
       "      <th>team_Lipscomb</th>\n",
       "      <th>team_Little Rock</th>\n",
       "      <th>team_Long Beach St.</th>\n",
       "      <th>team_Longwood</th>\n",
       "      <th>team_Louisiana Lafayette</th>\n",
       "      <th>team_Louisiana Monroe</th>\n",
       "      <th>team_Louisiana Tech</th>\n",
       "      <th>team_Louisville</th>\n",
       "      <th>team_Loyola Chicago</th>\n",
       "      <th>team_Loyola MD</th>\n",
       "      <th>team_Loyola Marymount</th>\n",
       "      <th>team_Maine</th>\n",
       "      <th>team_Manhattan</th>\n",
       "      <th>team_Marist</th>\n",
       "      <th>team_Marquette</th>\n",
       "      <th>team_Marshall</th>\n",
       "      <th>team_Maryland</th>\n",
       "      <th>team_Maryland Eastern Shore</th>\n",
       "      <th>team_Massachusetts</th>\n",
       "      <th>team_McNeese St.</th>\n",
       "      <th>team_Memphis</th>\n",
       "      <th>team_Mercer</th>\n",
       "      <th>team_Merrimack</th>\n",
       "      <th>team_Miami FL</th>\n",
       "      <th>team_Miami OH</th>\n",
       "      <th>team_Michigan</th>\n",
       "      <th>team_Michigan St.</th>\n",
       "      <th>team_Middle Tennessee</th>\n",
       "      <th>team_Milwaukee</th>\n",
       "      <th>team_Minnesota</th>\n",
       "      <th>team_Mississippi</th>\n",
       "      <th>team_Mississippi St.</th>\n",
       "      <th>team_Mississippi Valley St.</th>\n",
       "      <th>team_Missouri</th>\n",
       "      <th>team_Missouri St.</th>\n",
       "      <th>team_Monmouth</th>\n",
       "      <th>team_Montana</th>\n",
       "      <th>team_Montana St.</th>\n",
       "      <th>team_Morehead St.</th>\n",
       "      <th>team_Morgan St.</th>\n",
       "      <th>team_Mount St. Mary's</th>\n",
       "      <th>team_Murray St.</th>\n",
       "      <th>team_NJIT</th>\n",
       "      <th>team_Navy</th>\n",
       "      <th>team_Nebraska</th>\n",
       "      <th>team_Nebraska Omaha</th>\n",
       "      <th>team_Nevada</th>\n",
       "      <th>team_New Hampshire</th>\n",
       "      <th>team_New Mexico</th>\n",
       "      <th>team_New Mexico St.</th>\n",
       "      <th>team_New Orleans</th>\n",
       "      <th>team_Niagara</th>\n",
       "      <th>team_Nicholls St.</th>\n",
       "      <th>team_Norfolk St.</th>\n",
       "      <th>team_North Alabama</th>\n",
       "      <th>team_North Carolina</th>\n",
       "      <th>team_North Carolina A&amp;T</th>\n",
       "      <th>team_North Carolina Central</th>\n",
       "      <th>team_North Carolina St.</th>\n",
       "      <th>team_North Dakota</th>\n",
       "      <th>team_North Dakota St.</th>\n",
       "      <th>team_North Florida</th>\n",
       "      <th>team_North Texas</th>\n",
       "      <th>team_Northeastern</th>\n",
       "      <th>team_Northern Arizona</th>\n",
       "      <th>team_Northern Colorado</th>\n",
       "      <th>team_Northern Illinois</th>\n",
       "      <th>team_Northern Iowa</th>\n",
       "      <th>team_Northern Kentucky</th>\n",
       "      <th>team_Northwestern</th>\n",
       "      <th>team_Northwestern St.</th>\n",
       "      <th>team_Notre Dame</th>\n",
       "      <th>team_Oakland</th>\n",
       "      <th>team_Ohio</th>\n",
       "      <th>team_Ohio St.</th>\n",
       "      <th>team_Oklahoma</th>\n",
       "      <th>team_Oklahoma St.</th>\n",
       "      <th>team_Old Dominion</th>\n",
       "      <th>team_Oral Roberts</th>\n",
       "      <th>team_Oregon</th>\n",
       "      <th>team_Oregon St.</th>\n",
       "      <th>team_Pacific</th>\n",
       "      <th>team_Penn</th>\n",
       "      <th>team_Penn St.</th>\n",
       "      <th>team_Pepperdine</th>\n",
       "      <th>team_Pittsburgh</th>\n",
       "      <th>team_Portland</th>\n",
       "      <th>team_Portland St.</th>\n",
       "      <th>team_Prairie View A&amp;M</th>\n",
       "      <th>team_Presbyterian</th>\n",
       "      <th>team_Princeton</th>\n",
       "      <th>team_Providence</th>\n",
       "      <th>team_Purdue</th>\n",
       "      <th>team_Quinnipiac</th>\n",
       "      <th>team_Radford</th>\n",
       "      <th>team_Rhode Island</th>\n",
       "      <th>team_Rice</th>\n",
       "      <th>team_Richmond</th>\n",
       "      <th>team_Rider</th>\n",
       "      <th>team_Robert Morris</th>\n",
       "      <th>team_Rutgers</th>\n",
       "      <th>team_SIU Edwardsville</th>\n",
       "      <th>team_SMU</th>\n",
       "      <th>team_Sacramento St.</th>\n",
       "      <th>team_Sacred Heart</th>\n",
       "      <th>team_Saint Joseph's</th>\n",
       "      <th>team_Saint Louis</th>\n",
       "      <th>team_Saint Mary's</th>\n",
       "      <th>team_Saint Peter's</th>\n",
       "      <th>team_Sam Houston St.</th>\n",
       "      <th>team_Samford</th>\n",
       "      <th>team_San Diego</th>\n",
       "      <th>team_San Diego St.</th>\n",
       "      <th>team_San Francisco</th>\n",
       "      <th>team_San Jose St.</th>\n",
       "      <th>team_Santa Clara</th>\n",
       "      <th>team_Savannah St.</th>\n",
       "      <th>team_Seattle</th>\n",
       "      <th>team_Seton Hall</th>\n",
       "      <th>team_Siena</th>\n",
       "      <th>team_South Alabama</th>\n",
       "      <th>team_South Carolina</th>\n",
       "      <th>team_South Carolina St.</th>\n",
       "      <th>team_South Dakota</th>\n",
       "      <th>team_South Dakota St.</th>\n",
       "      <th>team_South Florida</th>\n",
       "      <th>team_Southeast Missouri St.</th>\n",
       "      <th>team_Southeastern Louisiana</th>\n",
       "      <th>team_Southern</th>\n",
       "      <th>team_Southern Illinois</th>\n",
       "      <th>team_Southern Miss</th>\n",
       "      <th>team_Southern Utah</th>\n",
       "      <th>team_St. Bonaventure</th>\n",
       "      <th>team_St. Francis NY</th>\n",
       "      <th>team_St. Francis PA</th>\n",
       "      <th>team_St. John's</th>\n",
       "      <th>team_Stanford</th>\n",
       "      <th>team_Stephen F. Austin</th>\n",
       "      <th>team_Stetson</th>\n",
       "      <th>team_Stony Brook</th>\n",
       "      <th>team_Syracuse</th>\n",
       "      <th>team_TCU</th>\n",
       "      <th>team_Tarleton St.</th>\n",
       "      <th>team_Temple</th>\n",
       "      <th>team_Tennessee</th>\n",
       "      <th>team_Tennessee Martin</th>\n",
       "      <th>team_Tennessee St.</th>\n",
       "      <th>team_Tennessee Tech</th>\n",
       "      <th>team_Texas</th>\n",
       "      <th>team_Texas A&amp;M</th>\n",
       "      <th>team_Texas A&amp;M Corpus Chris</th>\n",
       "      <th>team_Texas Southern</th>\n",
       "      <th>team_Texas St.</th>\n",
       "      <th>team_Texas Tech</th>\n",
       "      <th>team_The Citadel</th>\n",
       "      <th>team_Toledo</th>\n",
       "      <th>team_Towson</th>\n",
       "      <th>team_Troy</th>\n",
       "      <th>team_Tulane</th>\n",
       "      <th>team_Tulsa</th>\n",
       "      <th>team_UAB</th>\n",
       "      <th>team_UC Davis</th>\n",
       "      <th>team_UC Irvine</th>\n",
       "      <th>team_UC Riverside</th>\n",
       "      <th>team_UC San Diego</th>\n",
       "      <th>team_UC Santa Barbara</th>\n",
       "      <th>team_UCF</th>\n",
       "      <th>team_UCLA</th>\n",
       "      <th>team_UMBC</th>\n",
       "      <th>team_UMKC</th>\n",
       "      <th>team_UMass Lowell</th>\n",
       "      <th>team_UNC Asheville</th>\n",
       "      <th>team_UNC Greensboro</th>\n",
       "      <th>team_UNC Wilmington</th>\n",
       "      <th>team_UNLV</th>\n",
       "      <th>team_USC</th>\n",
       "      <th>team_USC Upstate</th>\n",
       "      <th>team_UT Arlington</th>\n",
       "      <th>team_UT Rio Grande Valley</th>\n",
       "      <th>team_UTEP</th>\n",
       "      <th>team_UTSA</th>\n",
       "      <th>team_Utah</th>\n",
       "      <th>team_Utah St.</th>\n",
       "      <th>team_Utah Valley</th>\n",
       "      <th>team_VCU</th>\n",
       "      <th>team_VMI</th>\n",
       "      <th>team_Valparaiso</th>\n",
       "      <th>team_Vanderbilt</th>\n",
       "      <th>team_Vermont</th>\n",
       "      <th>team_Villanova</th>\n",
       "      <th>team_Virginia</th>\n",
       "      <th>team_Virginia Tech</th>\n",
       "      <th>team_Wagner</th>\n",
       "      <th>team_Wake Forest</th>\n",
       "      <th>team_Washington</th>\n",
       "      <th>team_Washington St.</th>\n",
       "      <th>team_Weber St.</th>\n",
       "      <th>team_West Virginia</th>\n",
       "      <th>team_Western Carolina</th>\n",
       "      <th>team_Western Illinois</th>\n",
       "      <th>team_Western Kentucky</th>\n",
       "      <th>team_Western Michigan</th>\n",
       "      <th>team_Wichita St.</th>\n",
       "      <th>team_William &amp; Mary</th>\n",
       "      <th>team_Winston Salem St.</th>\n",
       "      <th>team_Winthrop</th>\n",
       "      <th>team_Wisconsin</th>\n",
       "      <th>team_Wofford</th>\n",
       "      <th>team_Wright St.</th>\n",
       "      <th>team_Wyoming</th>\n",
       "      <th>team_Xavier</th>\n",
       "      <th>team_Yale</th>\n",
       "      <th>team_Youngstown St.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>64.0</td>\n",
       "      <td>108.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.33</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>14.1</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>0.532</td>\n",
       "      <td>70</td>\n",
       "      <td>134</td>\n",
       "      <td>0.522</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.915280</td>\n",
       "      <td>104.7920</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.999909</td>\n",
       "      <td>48.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.8750</td>\n",
       "      <td>98.5761</td>\n",
       "      <td>2.636630</td>\n",
       "      <td>124.82700</td>\n",
       "      <td>2.282520</td>\n",
       "      <td>2.426980</td>\n",
       "      <td>-0.144461</td>\n",
       "      <td>1.06223</td>\n",
       "      <td>27.3125</td>\n",
       "      <td>0.78596</td>\n",
       "      <td>0.276271</td>\n",
       "      <td>0.4688</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>1.8438</td>\n",
       "      <td>2.1875</td>\n",
       "      <td>0.5938</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>8.7812</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.151246</td>\n",
       "      <td>116.4680</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.8780</td>\n",
       "      <td>101.9380</td>\n",
       "      <td>0.116247</td>\n",
       "      <td>1.58625</td>\n",
       "      <td>-3.890510</td>\n",
       "      <td>0.869061</td>\n",
       "      <td>-4.759570</td>\n",
       "      <td>1.80259</td>\n",
       "      <td>1.3636</td>\n",
       "      <td>2.31746</td>\n",
       "      <td>-0.514877</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>81.8</td>\n",
       "      <td>99.8</td>\n",
       "      <td>27.7</td>\n",
       "      <td>49.9</td>\n",
       "      <td>53.76</td>\n",
       "      <td>6.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>18.6</td>\n",
       "      <td>123</td>\n",
       "      <td>187</td>\n",
       "      <td>0.658</td>\n",
       "      <td>126</td>\n",
       "      <td>261</td>\n",
       "      <td>0.483</td>\n",
       "      <td>33</td>\n",
       "      <td>91</td>\n",
       "      <td>0.363</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>53.1</td>\n",
       "      <td>4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.701770</td>\n",
       "      <td>108.3130</td>\n",
       "      <td>4.3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>82.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>106.3010</td>\n",
       "      <td>110.6310</td>\n",
       "      <td>1.801420</td>\n",
       "      <td>168.42800</td>\n",
       "      <td>-0.441037</td>\n",
       "      <td>1.107340</td>\n",
       "      <td>-1.548380</td>\n",
       "      <td>-0.11805</td>\n",
       "      <td>32.7037</td>\n",
       "      <td>1.94935</td>\n",
       "      <td>-2.067400</td>\n",
       "      <td>2.1481</td>\n",
       "      <td>4.9259</td>\n",
       "      <td>7.0741</td>\n",
       "      <td>2.4074</td>\n",
       "      <td>0.8148</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>17.5556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>76.2</td>\n",
       "      <td>118.1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>58.8</td>\n",
       "      <td>60.93</td>\n",
       "      <td>4.7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>15.1</td>\n",
       "      <td>73</td>\n",
       "      <td>107</td>\n",
       "      <td>0.682</td>\n",
       "      <td>65</td>\n",
       "      <td>136</td>\n",
       "      <td>0.478</td>\n",
       "      <td>59</td>\n",
       "      <td>125</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.872460</td>\n",
       "      <td>111.6740</td>\n",
       "      <td>3.5</td>\n",
       "      <td>32</td>\n",
       "      <td>1.340383</td>\n",
       "      <td>47.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.3276</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>95.9093</td>\n",
       "      <td>98.0859</td>\n",
       "      <td>3.004560</td>\n",
       "      <td>215.85700</td>\n",
       "      <td>6.077490</td>\n",
       "      <td>3.665330</td>\n",
       "      <td>2.412160</td>\n",
       "      <td>5.25306</td>\n",
       "      <td>30.6857</td>\n",
       "      <td>2.91471</td>\n",
       "      <td>2.338340</td>\n",
       "      <td>1.3429</td>\n",
       "      <td>3.2286</td>\n",
       "      <td>4.5714</td>\n",
       "      <td>1.8000</td>\n",
       "      <td>1.6571</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>10.8571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>9.5</td>\n",
       "      <td>60.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>14.93</td>\n",
       "      <td>3.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>83.3</td>\n",
       "      <td>4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-0.591030</td>\n",
       "      <td>47.4843</td>\n",
       "      <td>3.9</td>\n",
       "      <td>33</td>\n",
       "      <td>5.997102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0118</td>\n",
       "      <td>101.2860</td>\n",
       "      <td>0.402609</td>\n",
       "      <td>23.56570</td>\n",
       "      <td>-4.128490</td>\n",
       "      <td>-4.707080</td>\n",
       "      <td>0.578588</td>\n",
       "      <td>-3.75119</td>\n",
       "      <td>4.6207</td>\n",
       "      <td>-4.67608</td>\n",
       "      <td>0.924890</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP  Min_per   Ortg   usg   eFG  TS_per  ORB_per  DRB_per  AST_per  TO_per  \\\n",
       "0  32     64.0  108.3  18.1  53.0   53.33      2.3      5.9     14.6    14.1   \n",
       "1  11      1.0  121.1  16.8  75.0   75.00      0.0      0.0     15.8    24.8   \n",
       "2  27     81.8   99.8  27.7  49.9   53.76      6.9     17.6     15.6    18.6   \n",
       "3  35     76.2  118.1  16.4  58.8   60.93      4.7     11.5     12.3    15.1   \n",
       "4  29      9.5   60.7   6.9   8.3   14.93      3.2     13.9      7.7     6.1   \n",
       "\n",
       "   FTM  FTA  FT_per  twoPM  twoPA  twoP_per  TPM  TPA  TP_per  blk_per  \\\n",
       "0   33   62   0.532     70    134     0.522   36  100   0.360      0.9   \n",
       "1    0    0   0.000      0      1     0.000    2    3   0.667      0.0   \n",
       "2  123  187   0.658    126    261     0.483   33   91   0.363      1.4   \n",
       "3   73  107   0.682     65    136     0.478   59  125   0.472      1.4   \n",
       "4    3   10   0.300      1     10     0.100    0    2   0.000      0.8   \n",
       "\n",
       "   stl_per   ftr  yr   num    porpag     adjoe  pfr  pid   ast/tov  rimmade  \\\n",
       "0      1.4  26.5   3   5.0  1.915280  104.7920  2.7    3  1.999909     48.0   \n",
       "1      0.0   0.0   4  14.0  0.151246  116.4680  8.0   11  1.000000      0.0   \n",
       "2      1.4  53.1   4  22.0  2.701770  108.3130  4.3   13  0.773810     82.0   \n",
       "3      3.1  41.0   4  22.0  2.872460  111.6740  3.5   32  1.340383     47.0   \n",
       "4      1.3  83.3   4  34.0 -0.591030   47.4843  3.9   33  5.997102      1.0   \n",
       "\n",
       "   rimmade+rimmiss  midmade  midmade+midmiss  rimmade/(rimmade+rimmiss)  \\\n",
       "0             75.0     22.0             59.0                     0.6400   \n",
       "1              0.0      0.0              1.0                     0.0000   \n",
       "2            134.0     44.0            127.0                     0.6119   \n",
       "3             78.0     19.0             58.0                     0.6026   \n",
       "4              7.0      0.0              3.0                     0.1429   \n",
       "\n",
       "   midmade/(midmade+midmiss)  dunksmade  dunksmiss+dunksmade      drtg  \\\n",
       "0                     0.3729        6.0                  7.0  100.8750   \n",
       "1                     0.0000        0.0                  0.0  102.8780   \n",
       "2                     0.3465        3.0                  4.0  106.3010   \n",
       "3                     0.3276       13.0                 15.0   95.9093   \n",
       "4                     0.0000        0.0                  0.0   99.0118   \n",
       "\n",
       "      adrtg   dporpag      stops       bpm      obpm      dbpm     gbpm  \\\n",
       "0   98.5761  2.636630  124.82700  2.282520  2.426980 -0.144461  1.06223   \n",
       "1  101.9380  0.116247    1.58625 -3.890510  0.869061 -4.759570  1.80259   \n",
       "2  110.6310  1.801420  168.42800 -0.441037  1.107340 -1.548380 -0.11805   \n",
       "3   98.0859  3.004560  215.85700  6.077490  3.665330  2.412160  5.25306   \n",
       "4  101.2860  0.402609   23.56570 -4.128490 -4.707080  0.578588 -3.75119   \n",
       "\n",
       "        mp    ogbpm     dgbpm    oreb    dreb    treb     ast     stl     blk  \\\n",
       "0  27.3125  0.78596  0.276271  0.4688  1.3750  1.8438  2.1875  0.5938  0.2188   \n",
       "1   1.3636  2.31746 -0.514877  0.0000  0.0000  0.0000  0.0909  0.0000  0.0000   \n",
       "2  32.7037  1.94935 -2.067400  2.1481  4.9259  7.0741  2.4074  0.8148  0.4815   \n",
       "3  30.6857  2.91471  2.338340  1.3429  3.2286  4.5714  1.8000  1.6571  0.4000   \n",
       "4   4.6207 -4.67608  0.924890  0.1379  0.5862  0.7241  0.2069  0.1034  0.0345   \n",
       "\n",
       "       pts  first_round_drafted  role_Combo G  role_PF/C  role_Pure PG  \\\n",
       "0   8.7812                    0             1          0             0   \n",
       "1   0.5455                    0             0          0             1   \n",
       "2  17.5556                    0             0          0             0   \n",
       "3  10.8571                    0             1          0             0   \n",
       "4   0.1724                    0             0          0             0   \n",
       "\n",
       "   role_Scoring PG  role_Stretch 4  role_Wing F  role_Wing G  ht_month_Jul  \\\n",
       "0                0               0            0            0             0   \n",
       "1                0               0            0            0             0   \n",
       "2                0               0            1            0             0   \n",
       "3                0               0            0            0             0   \n",
       "4                0               0            0            1             0   \n",
       "\n",
       "   ht_month_Jun  ht_month_May  ht_day_1  ht_day_10  ht_day_11  ht_day_2  \\\n",
       "0             1             0         0          0          0         0   \n",
       "1             1             0         0          0          0         1   \n",
       "2             1             0         0          0          0         0   \n",
       "3             1             0         0          0          0         0   \n",
       "4             1             0         0          0          0         0   \n",
       "\n",
       "   ht_day_3  ht_day_4  ht_day_5  ht_day_6  ht_day_7  ht_day_8  ht_day_9  \\\n",
       "0         1         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         1         0         0         0         0   \n",
       "3         1         0         0         0         0         0         0   \n",
       "4         0         1         0         0         0         0         0   \n",
       "\n",
       "   team_Air Force  team_Akron  team_Alabama  team_Alabama A&M  \\\n",
       "0               0           0             0                 0   \n",
       "1               0           0             0                 0   \n",
       "2               0           0             0                 0   \n",
       "3               0           0             0                 0   \n",
       "4               0           0             0                 0   \n",
       "\n",
       "   team_Alabama St.  team_Albany  team_Alcorn St.  team_American  \\\n",
       "0                 0            0                0              0   \n",
       "1                 0            0                0              0   \n",
       "2                 0            0                0              0   \n",
       "3                 0            0                0              0   \n",
       "4                 0            0                0              0   \n",
       "\n",
       "   team_Appalachian St.  team_Arizona  team_Arizona St.  team_Arkansas  \\\n",
       "0                     0             0                 0              0   \n",
       "1                     0             0                 0              0   \n",
       "2                     0             0                 0              0   \n",
       "3                     0             0                 0              0   \n",
       "4                     0             0                 0              0   \n",
       "\n",
       "   team_Arkansas Little Rock  team_Arkansas Pine Bluff  team_Arkansas St.  \\\n",
       "0                          0                         0                  0   \n",
       "1                          0                         0                  0   \n",
       "2                          0                         0                  0   \n",
       "3                          0                         0                  0   \n",
       "4                          0                         0                  0   \n",
       "\n",
       "   team_Army  team_Auburn  team_Austin Peay  team_BYU  team_Ball St.  \\\n",
       "0          0            0                 0         0              0   \n",
       "1          0            0                 0         0              0   \n",
       "2          0            0                 0         0              0   \n",
       "3          0            0                 0         0              0   \n",
       "4          0            0                 0         0              0   \n",
       "\n",
       "   team_Baylor  team_Bellarmine  team_Belmont  team_Bethune Cookman  \\\n",
       "0            0                0             0                     0   \n",
       "1            0                0             0                     0   \n",
       "2            0                0             0                     0   \n",
       "3            0                0             0                     0   \n",
       "4            0                0             0                     0   \n",
       "\n",
       "   team_Binghamton  team_Boise St.  team_Boston College  \\\n",
       "0                0               0                    0   \n",
       "1                0               0                    0   \n",
       "2                0               0                    0   \n",
       "3                0               0                    0   \n",
       "4                0               0                    0   \n",
       "\n",
       "   team_Boston University  team_Bowling Green  team_Bradley  team_Brown  \\\n",
       "0                       0                   0             0           0   \n",
       "1                       0                   0             0           0   \n",
       "2                       0                   0             0           0   \n",
       "3                       1                   0             0           0   \n",
       "4                       1                   0             0           0   \n",
       "\n",
       "   team_Bryant  team_Bucknell  team_Buffalo  team_Butler  team_Cal Baptist  \\\n",
       "0            0              0             0            0                 0   \n",
       "1            0              0             0            1                 0   \n",
       "2            0              0             0            0                 0   \n",
       "3            0              0             0            0                 0   \n",
       "4            0              0             0            0                 0   \n",
       "\n",
       "   team_Cal Poly  team_Cal St. Bakersfield  team_Cal St. Fullerton  \\\n",
       "0              0                         0                       0   \n",
       "1              0                         0                       0   \n",
       "2              0                         0                       0   \n",
       "3              0                         0                       0   \n",
       "4              0                         0                       0   \n",
       "\n",
       "   team_Cal St. Northridge  team_California  team_Campbell  team_Canisius  \\\n",
       "0                        0                0              0              0   \n",
       "1                        0                0              0              0   \n",
       "2                        0                0              0              0   \n",
       "3                        0                0              0              0   \n",
       "4                        0                0              0              0   \n",
       "\n",
       "   team_Centenary  team_Central Arkansas  team_Central Connecticut  \\\n",
       "0               0                      0                         0   \n",
       "1               0                      0                         0   \n",
       "2               0                      0                         0   \n",
       "3               0                      0                         0   \n",
       "4               0                      0                         0   \n",
       "\n",
       "   team_Central Michigan  team_Charleston Southern  team_Charlotte  \\\n",
       "0                      0                         0               0   \n",
       "1                      0                         0               0   \n",
       "2                      0                         0               0   \n",
       "3                      0                         0               0   \n",
       "4                      0                         0               0   \n",
       "\n",
       "   team_Chattanooga  team_Chicago St.  team_Cincinnati  team_Clemson  \\\n",
       "0                 0                 0                0             0   \n",
       "1                 0                 0                0             0   \n",
       "2                 0                 0                0             0   \n",
       "3                 0                 0                0             0   \n",
       "4                 0                 0                0             0   \n",
       "\n",
       "   team_Cleveland St.  team_Coastal Carolina  team_Colgate  \\\n",
       "0                   0                      0             0   \n",
       "1                   0                      0             0   \n",
       "2                   0                      0             0   \n",
       "3                   0                      0             0   \n",
       "4                   0                      0             0   \n",
       "\n",
       "   team_College of Charleston  team_Colorado  team_Colorado St.  \\\n",
       "0                           0              0                  0   \n",
       "1                           0              0                  0   \n",
       "2                           0              0                  0   \n",
       "3                           0              0                  0   \n",
       "4                           0              0                  0   \n",
       "\n",
       "   team_Columbia  team_Connecticut  team_Coppin St.  team_Cornell  \\\n",
       "0              0                 0                0             0   \n",
       "1              0                 0                0             0   \n",
       "2              0                 0                0             0   \n",
       "3              0                 0                0             0   \n",
       "4              0                 0                0             0   \n",
       "\n",
       "   team_Creighton  team_Dartmouth  team_Davidson  team_Dayton  team_DePaul  \\\n",
       "0               0               0              0            0            0   \n",
       "1               0               0              0            0            0   \n",
       "2               0               0              0            0            0   \n",
       "3               0               0              0            0            0   \n",
       "4               0               0              0            0            0   \n",
       "\n",
       "   team_Delaware  team_Delaware St.  team_Denver  team_Detroit  \\\n",
       "0              0                  0            0             0   \n",
       "1              0                  0            0             0   \n",
       "2              0                  0            0             0   \n",
       "3              0                  0            0             0   \n",
       "4              0                  0            0             0   \n",
       "\n",
       "   team_Dixie St.  team_Drake  team_Drexel  team_Duke  team_Duquesne  \\\n",
       "0               0           0            0          0              0   \n",
       "1               0           0            0          0              0   \n",
       "2               0           0            0          0              0   \n",
       "3               0           0            0          0              0   \n",
       "4               0           0            0          0              0   \n",
       "\n",
       "   team_East Carolina  team_East Tennessee St.  team_Eastern Illinois  \\\n",
       "0                   0                        0                      0   \n",
       "1                   0                        0                      0   \n",
       "2                   0                        0                      0   \n",
       "3                   0                        0                      0   \n",
       "4                   0                        0                      0   \n",
       "\n",
       "   team_Eastern Kentucky  team_Eastern Michigan  team_Eastern Washington  \\\n",
       "0                      0                      0                        0   \n",
       "1                      0                      0                        0   \n",
       "2                      0                      0                        0   \n",
       "3                      0                      0                        0   \n",
       "4                      0                      0                        0   \n",
       "\n",
       "   team_Elon  team_Evansville  team_FIU  team_Fairfield  \\\n",
       "0          0                0         0               0   \n",
       "1          0                0         0               0   \n",
       "2          0                0         0               0   \n",
       "3          0                0         0               0   \n",
       "4          0                0         0               0   \n",
       "\n",
       "   team_Fairleigh Dickinson  team_Florida  team_Florida A&M  \\\n",
       "0                         0             0                 0   \n",
       "1                         0             0                 0   \n",
       "2                         0             0                 0   \n",
       "3                         0             0                 0   \n",
       "4                         0             0                 0   \n",
       "\n",
       "   team_Florida Atlantic  team_Florida Gulf Coast  team_Florida St.  \\\n",
       "0                      0                        0                 0   \n",
       "1                      0                        0                 0   \n",
       "2                      0                        0                 0   \n",
       "3                      0                        0                 0   \n",
       "4                      0                        0                 0   \n",
       "\n",
       "   team_Fordham  team_Fort Wayne  team_Fresno St.  team_Furman  \\\n",
       "0             0                0                0            0   \n",
       "1             0                0                0            0   \n",
       "2             0                0                0            0   \n",
       "3             0                0                0            0   \n",
       "4             0                0                0            0   \n",
       "\n",
       "   team_Gardner Webb  team_George Mason  team_George Washington  \\\n",
       "0                  0                  0                       0   \n",
       "1                  0                  0                       0   \n",
       "2                  0                  0                       0   \n",
       "3                  0                  0                       0   \n",
       "4                  0                  0                       0   \n",
       "\n",
       "   team_Georgetown  team_Georgia  team_Georgia Southern  team_Georgia St.  \\\n",
       "0                0             0                      0                 0   \n",
       "1                0             0                      0                 0   \n",
       "2                0             0                      0                 0   \n",
       "3                0             0                      0                 0   \n",
       "4                0             0                      0                 0   \n",
       "\n",
       "   team_Georgia Tech  team_Gonzaga  team_Grambling St.  team_Grand Canyon  \\\n",
       "0                  0             0                   0                  0   \n",
       "1                  0             0                   0                  0   \n",
       "2                  0             0                   0                  0   \n",
       "3                  0             0                   0                  0   \n",
       "4                  0             0                   0                  0   \n",
       "\n",
       "   team_Green Bay  team_Hampton  team_Hartford  team_Harvard  team_Hawaii  \\\n",
       "0               0             0              0             0            0   \n",
       "1               0             0              0             0            0   \n",
       "2               0             0              0             0            0   \n",
       "3               0             0              0             0            0   \n",
       "4               0             0              0             0            0   \n",
       "\n",
       "   team_High Point  team_Hofstra  team_Holy Cross  team_Houston  \\\n",
       "0                0             0                0             0   \n",
       "1                0             0                0             0   \n",
       "2                0             0                0             0   \n",
       "3                0             0                0             0   \n",
       "4                0             0                0             0   \n",
       "\n",
       "   team_Houston Baptist  team_Howard  team_IPFW  team_IUPUI  team_Idaho  \\\n",
       "0                     0            0          0           0           0   \n",
       "1                     0            0          0           0           0   \n",
       "2                     0            0          0           0           0   \n",
       "3                     0            0          0           0           0   \n",
       "4                     0            0          0           0           0   \n",
       "\n",
       "   team_Idaho St.  team_Illinois  team_Illinois Chicago  team_Illinois St.  \\\n",
       "0               0              0                      0                  0   \n",
       "1               0              0                      0                  0   \n",
       "2               0              0                      0                  0   \n",
       "3               0              0                      0                  0   \n",
       "4               0              0                      0                  0   \n",
       "\n",
       "   team_Incarnate Word  team_Indiana  team_Indiana St.  team_Iona  team_Iowa  \\\n",
       "0                    0             0                 0          0          0   \n",
       "1                    0             0                 0          0          0   \n",
       "2                    0             0                 0          0          0   \n",
       "3                    0             0                 0          0          0   \n",
       "4                    0             0                 0          0          0   \n",
       "\n",
       "   team_Iowa St.  team_Jackson St.  team_Jacksonville  team_Jacksonville St.  \\\n",
       "0              0                 0                  0                      0   \n",
       "1              0                 0                  0                      0   \n",
       "2              0                 0                  0                      0   \n",
       "3              0                 0                  0                      0   \n",
       "4              0                 0                  0                      0   \n",
       "\n",
       "   team_James Madison  team_Kansas  team_Kansas St.  team_Kennesaw St.  \\\n",
       "0                   0            0                0                  0   \n",
       "1                   0            0                0                  0   \n",
       "2                   0            0                0                  0   \n",
       "3                   0            0                0                  0   \n",
       "4                   0            0                0                  0   \n",
       "\n",
       "   team_Kent St.  team_Kentucky  team_LIU Brooklyn  team_LSU  team_La Salle  \\\n",
       "0              0              0                  0         0              0   \n",
       "1              0              0                  0         0              0   \n",
       "2              0              0                  0         0              0   \n",
       "3              0              0                  0         0              0   \n",
       "4              0              0                  0         0              0   \n",
       "\n",
       "   team_Lafayette  team_Lamar  team_Lehigh  team_Liberty  team_Lipscomb  \\\n",
       "0               0           0            0             0              0   \n",
       "1               0           0            0             0              0   \n",
       "2               0           0            0             0              0   \n",
       "3               0           0            0             0              0   \n",
       "4               0           0            0             0              0   \n",
       "\n",
       "   team_Little Rock  team_Long Beach St.  team_Longwood  \\\n",
       "0                 0                    0              0   \n",
       "1                 0                    0              0   \n",
       "2                 0                    0              1   \n",
       "3                 0                    0              0   \n",
       "4                 0                    0              0   \n",
       "\n",
       "   team_Louisiana Lafayette  team_Louisiana Monroe  team_Louisiana Tech  \\\n",
       "0                         0                      0                    0   \n",
       "1                         0                      0                    0   \n",
       "2                         0                      0                    0   \n",
       "3                         0                      0                    0   \n",
       "4                         0                      0                    0   \n",
       "\n",
       "   team_Louisville  team_Loyola Chicago  team_Loyola MD  \\\n",
       "0                0                    0               0   \n",
       "1                0                    0               0   \n",
       "2                0                    0               0   \n",
       "3                0                    0               0   \n",
       "4                0                    0               0   \n",
       "\n",
       "   team_Loyola Marymount  team_Maine  team_Manhattan  team_Marist  \\\n",
       "0                      0           0               0            0   \n",
       "1                      0           0               0            0   \n",
       "2                      0           0               0            0   \n",
       "3                      0           0               0            0   \n",
       "4                      0           0               0            0   \n",
       "\n",
       "   team_Marquette  team_Marshall  team_Maryland  team_Maryland Eastern Shore  \\\n",
       "0               0              0              0                            0   \n",
       "1               0              0              0                            0   \n",
       "2               0              0              0                            0   \n",
       "3               0              0              0                            0   \n",
       "4               0              0              0                            0   \n",
       "\n",
       "   team_Massachusetts  team_McNeese St.  team_Memphis  team_Mercer  \\\n",
       "0                   0                 0             0            0   \n",
       "1                   0                 0             0            0   \n",
       "2                   0                 0             0            0   \n",
       "3                   0                 0             0            0   \n",
       "4                   0                 0             0            0   \n",
       "\n",
       "   team_Merrimack  team_Miami FL  team_Miami OH  team_Michigan  \\\n",
       "0               0              0              0              0   \n",
       "1               0              0              0              0   \n",
       "2               0              0              0              0   \n",
       "3               0              0              0              0   \n",
       "4               0              0              0              0   \n",
       "\n",
       "   team_Michigan St.  team_Middle Tennessee  team_Milwaukee  team_Minnesota  \\\n",
       "0                  0                      0               0               0   \n",
       "1                  0                      0               0               0   \n",
       "2                  0                      0               0               0   \n",
       "3                  0                      0               0               0   \n",
       "4                  0                      0               0               0   \n",
       "\n",
       "   team_Mississippi  team_Mississippi St.  team_Mississippi Valley St.  \\\n",
       "0                 0                     0                            0   \n",
       "1                 0                     0                            0   \n",
       "2                 0                     0                            0   \n",
       "3                 0                     0                            0   \n",
       "4                 0                     0                            0   \n",
       "\n",
       "   team_Missouri  team_Missouri St.  team_Monmouth  team_Montana  \\\n",
       "0              0                  0              0             0   \n",
       "1              0                  0              0             0   \n",
       "2              0                  0              0             0   \n",
       "3              0                  0              0             0   \n",
       "4              0                  0              0             0   \n",
       "\n",
       "   team_Montana St.  team_Morehead St.  team_Morgan St.  \\\n",
       "0                 0                  0                0   \n",
       "1                 0                  0                0   \n",
       "2                 0                  0                0   \n",
       "3                 0                  0                0   \n",
       "4                 0                  0                0   \n",
       "\n",
       "   team_Mount St. Mary's  team_Murray St.  team_NJIT  team_Navy  \\\n",
       "0                      0                0          0          0   \n",
       "1                      0                0          0          0   \n",
       "2                      0                0          0          0   \n",
       "3                      0                0          0          0   \n",
       "4                      0                0          0          0   \n",
       "\n",
       "   team_Nebraska  team_Nebraska Omaha  team_Nevada  team_New Hampshire  \\\n",
       "0              0                    0            0                   0   \n",
       "1              0                    0            0                   0   \n",
       "2              0                    0            0                   0   \n",
       "3              0                    0            0                   0   \n",
       "4              0                    0            0                   0   \n",
       "\n",
       "   team_New Mexico  team_New Mexico St.  team_New Orleans  team_Niagara  \\\n",
       "0                0                    0                 0             0   \n",
       "1                0                    0                 0             0   \n",
       "2                0                    0                 0             0   \n",
       "3                0                    0                 0             0   \n",
       "4                0                    0                 0             0   \n",
       "\n",
       "   team_Nicholls St.  team_Norfolk St.  team_North Alabama  \\\n",
       "0                  0                 0                   0   \n",
       "1                  0                 0                   0   \n",
       "2                  0                 0                   0   \n",
       "3                  0                 0                   0   \n",
       "4                  0                 0                   0   \n",
       "\n",
       "   team_North Carolina  team_North Carolina A&T  team_North Carolina Central  \\\n",
       "0                    0                        0                            0   \n",
       "1                    0                        0                            0   \n",
       "2                    0                        0                            0   \n",
       "3                    0                        0                            0   \n",
       "4                    0                        0                            0   \n",
       "\n",
       "   team_North Carolina St.  team_North Dakota  team_North Dakota St.  \\\n",
       "0                        0                  0                      0   \n",
       "1                        0                  0                      0   \n",
       "2                        0                  0                      0   \n",
       "3                        0                  0                      0   \n",
       "4                        0                  0                      0   \n",
       "\n",
       "   team_North Florida  team_North Texas  team_Northeastern  \\\n",
       "0                   0                 0                  0   \n",
       "1                   0                 0                  0   \n",
       "2                   0                 0                  0   \n",
       "3                   0                 0                  0   \n",
       "4                   0                 0                  0   \n",
       "\n",
       "   team_Northern Arizona  team_Northern Colorado  team_Northern Illinois  \\\n",
       "0                      0                       0                       0   \n",
       "1                      0                       0                       0   \n",
       "2                      0                       0                       0   \n",
       "3                      0                       0                       0   \n",
       "4                      0                       0                       0   \n",
       "\n",
       "   team_Northern Iowa  team_Northern Kentucky  team_Northwestern  \\\n",
       "0                   0                       0                  0   \n",
       "1                   0                       0                  0   \n",
       "2                   0                       0                  0   \n",
       "3                   0                       0                  0   \n",
       "4                   0                       0                  0   \n",
       "\n",
       "   team_Northwestern St.  team_Notre Dame  team_Oakland  team_Ohio  \\\n",
       "0                      0                0             0          0   \n",
       "1                      0                0             0          0   \n",
       "2                      0                0             0          0   \n",
       "3                      0                0             0          0   \n",
       "4                      0                0             0          0   \n",
       "\n",
       "   team_Ohio St.  team_Oklahoma  team_Oklahoma St.  team_Old Dominion  \\\n",
       "0              0              0                  0                  0   \n",
       "1              0              0                  0                  0   \n",
       "2              0              0                  0                  0   \n",
       "3              0              0                  0                  0   \n",
       "4              0              0                  0                  0   \n",
       "\n",
       "   team_Oral Roberts  team_Oregon  team_Oregon St.  team_Pacific  team_Penn  \\\n",
       "0                  0            0                0             0          0   \n",
       "1                  0            0                0             0          0   \n",
       "2                  0            0                0             0          0   \n",
       "3                  0            0                0             0          0   \n",
       "4                  0            0                0             0          0   \n",
       "\n",
       "   team_Penn St.  team_Pepperdine  team_Pittsburgh  team_Portland  \\\n",
       "0              0                0                0              0   \n",
       "1              0                0                0              0   \n",
       "2              0                0                0              0   \n",
       "3              0                0                0              0   \n",
       "4              0                0                0              0   \n",
       "\n",
       "   team_Portland St.  team_Prairie View A&M  team_Presbyterian  \\\n",
       "0                  0                      0                  0   \n",
       "1                  0                      0                  0   \n",
       "2                  0                      0                  0   \n",
       "3                  0                      0                  0   \n",
       "4                  0                      0                  0   \n",
       "\n",
       "   team_Princeton  team_Providence  team_Purdue  team_Quinnipiac  \\\n",
       "0               0                0            0                0   \n",
       "1               0                0            0                0   \n",
       "2               0                0            0                0   \n",
       "3               0                0            0                0   \n",
       "4               0                0            0                0   \n",
       "\n",
       "   team_Radford  team_Rhode Island  team_Rice  team_Richmond  team_Rider  \\\n",
       "0             0                  0          0              0           0   \n",
       "1             0                  0          0              0           0   \n",
       "2             0                  0          0              0           0   \n",
       "3             0                  0          0              0           0   \n",
       "4             0                  0          0              0           0   \n",
       "\n",
       "   team_Robert Morris  team_Rutgers  team_SIU Edwardsville  team_SMU  \\\n",
       "0                   0             0                      0         0   \n",
       "1                   0             0                      0         0   \n",
       "2                   0             0                      0         0   \n",
       "3                   0             0                      0         0   \n",
       "4                   0             0                      0         0   \n",
       "\n",
       "   team_Sacramento St.  team_Sacred Heart  team_Saint Joseph's  \\\n",
       "0                    0                  0                    0   \n",
       "1                    0                  0                    0   \n",
       "2                    0                  0                    0   \n",
       "3                    0                  0                    0   \n",
       "4                    0                  0                    0   \n",
       "\n",
       "   team_Saint Louis  team_Saint Mary's  team_Saint Peter's  \\\n",
       "0                 0                  0                   0   \n",
       "1                 0                  0                   0   \n",
       "2                 0                  0                   0   \n",
       "3                 0                  0                   0   \n",
       "4                 0                  0                   0   \n",
       "\n",
       "   team_Sam Houston St.  team_Samford  team_San Diego  team_San Diego St.  \\\n",
       "0                     0             0               0                   0   \n",
       "1                     0             0               0                   0   \n",
       "2                     0             0               0                   0   \n",
       "3                     0             0               0                   0   \n",
       "4                     0             0               0                   0   \n",
       "\n",
       "   team_San Francisco  team_San Jose St.  team_Santa Clara  team_Savannah St.  \\\n",
       "0                   0                  0                 0                  0   \n",
       "1                   0                  0                 0                  0   \n",
       "2                   0                  0                 0                  0   \n",
       "3                   0                  0                 0                  0   \n",
       "4                   0                  0                 0                  0   \n",
       "\n",
       "   team_Seattle  team_Seton Hall  team_Siena  team_South Alabama  \\\n",
       "0             0                0           0                   0   \n",
       "1             0                0           0                   0   \n",
       "2             0                0           0                   0   \n",
       "3             0                0           0                   0   \n",
       "4             0                0           0                   0   \n",
       "\n",
       "   team_South Carolina  team_South Carolina St.  team_South Dakota  \\\n",
       "0                    0                        0                  0   \n",
       "1                    0                        0                  0   \n",
       "2                    0                        0                  0   \n",
       "3                    0                        0                  0   \n",
       "4                    0                        0                  0   \n",
       "\n",
       "   team_South Dakota St.  team_South Florida  team_Southeast Missouri St.  \\\n",
       "0                      0                   0                            0   \n",
       "1                      0                   0                            0   \n",
       "2                      0                   0                            0   \n",
       "3                      0                   0                            0   \n",
       "4                      0                   0                            0   \n",
       "\n",
       "   team_Southeastern Louisiana  team_Southern  team_Southern Illinois  \\\n",
       "0                            0              0                       0   \n",
       "1                            0              0                       0   \n",
       "2                            0              0                       0   \n",
       "3                            0              0                       0   \n",
       "4                            0              0                       0   \n",
       "\n",
       "   team_Southern Miss  team_Southern Utah  team_St. Bonaventure  \\\n",
       "0                   0                   0                     0   \n",
       "1                   0                   0                     0   \n",
       "2                   0                   0                     0   \n",
       "3                   0                   0                     0   \n",
       "4                   0                   0                     0   \n",
       "\n",
       "   team_St. Francis NY  team_St. Francis PA  team_St. John's  team_Stanford  \\\n",
       "0                    0                    0                0              0   \n",
       "1                    0                    0                0              0   \n",
       "2                    0                    0                0              0   \n",
       "3                    0                    0                0              0   \n",
       "4                    0                    0                0              0   \n",
       "\n",
       "   team_Stephen F. Austin  team_Stetson  team_Stony Brook  team_Syracuse  \\\n",
       "0                       0             0                 0              0   \n",
       "1                       0             0                 0              0   \n",
       "2                       0             0                 0              0   \n",
       "3                       0             0                 0              0   \n",
       "4                       0             0                 0              0   \n",
       "\n",
       "   team_TCU  team_Tarleton St.  team_Temple  team_Tennessee  \\\n",
       "0         0                  0            0               0   \n",
       "1         0                  0            0               0   \n",
       "2         0                  0            0               0   \n",
       "3         0                  0            0               0   \n",
       "4         0                  0            0               0   \n",
       "\n",
       "   team_Tennessee Martin  team_Tennessee St.  team_Tennessee Tech  team_Texas  \\\n",
       "0                      0                   0                    0           0   \n",
       "1                      0                   0                    0           0   \n",
       "2                      0                   0                    0           0   \n",
       "3                      0                   0                    0           0   \n",
       "4                      0                   0                    0           0   \n",
       "\n",
       "   team_Texas A&M  team_Texas A&M Corpus Chris  team_Texas Southern  \\\n",
       "0               0                            0                    0   \n",
       "1               0                            0                    0   \n",
       "2               0                            0                    0   \n",
       "3               0                            0                    0   \n",
       "4               0                            0                    0   \n",
       "\n",
       "   team_Texas St.  team_Texas Tech  team_The Citadel  team_Toledo  \\\n",
       "0               0                0                 0            0   \n",
       "1               0                0                 0            0   \n",
       "2               0                0                 0            0   \n",
       "3               0                0                 0            0   \n",
       "4               0                0                 0            0   \n",
       "\n",
       "   team_Towson  team_Troy  team_Tulane  team_Tulsa  team_UAB  team_UC Davis  \\\n",
       "0            0          0            0           0         0              0   \n",
       "1            0          0            0           0         0              0   \n",
       "2            0          0            0           0         0              0   \n",
       "3            0          0            0           0         0              0   \n",
       "4            0          0            0           0         0              0   \n",
       "\n",
       "   team_UC Irvine  team_UC Riverside  team_UC San Diego  \\\n",
       "0               0                  0                  0   \n",
       "1               0                  0                  0   \n",
       "2               0                  0                  0   \n",
       "3               0                  0                  0   \n",
       "4               0                  0                  0   \n",
       "\n",
       "   team_UC Santa Barbara  team_UCF  team_UCLA  team_UMBC  team_UMKC  \\\n",
       "0                      0         0          0          0          0   \n",
       "1                      0         0          0          0          0   \n",
       "2                      0         0          0          0          0   \n",
       "3                      0         0          0          0          0   \n",
       "4                      0         0          0          0          0   \n",
       "\n",
       "   team_UMass Lowell  team_UNC Asheville  team_UNC Greensboro  \\\n",
       "0                  0                   0                    0   \n",
       "1                  0                   0                    0   \n",
       "2                  0                   0                    0   \n",
       "3                  0                   0                    0   \n",
       "4                  0                   0                    0   \n",
       "\n",
       "   team_UNC Wilmington  team_UNLV  team_USC  team_USC Upstate  \\\n",
       "0                    0          0         0                 0   \n",
       "1                    0          0         0                 0   \n",
       "2                    0          0         0                 0   \n",
       "3                    0          0         0                 0   \n",
       "4                    0          0         0                 0   \n",
       "\n",
       "   team_UT Arlington  team_UT Rio Grande Valley  team_UTEP  team_UTSA  \\\n",
       "0                  0                          0          0          0   \n",
       "1                  0                          0          0          0   \n",
       "2                  0                          0          0          0   \n",
       "3                  0                          0          0          0   \n",
       "4                  0                          0          0          0   \n",
       "\n",
       "   team_Utah  team_Utah St.  team_Utah Valley  team_VCU  team_VMI  \\\n",
       "0          0              1                 0         0         0   \n",
       "1          0              0                 0         0         0   \n",
       "2          0              0                 0         0         0   \n",
       "3          0              0                 0         0         0   \n",
       "4          0              0                 0         0         0   \n",
       "\n",
       "   team_Valparaiso  team_Vanderbilt  team_Vermont  team_Villanova  \\\n",
       "0                0                0             0               0   \n",
       "1                0                0             0               0   \n",
       "2                0                0             0               0   \n",
       "3                0                0             0               0   \n",
       "4                0                0             0               0   \n",
       "\n",
       "   team_Virginia  team_Virginia Tech  team_Wagner  team_Wake Forest  \\\n",
       "0              0                   0            0                 0   \n",
       "1              0                   0            0                 0   \n",
       "2              0                   0            0                 0   \n",
       "3              0                   0            0                 0   \n",
       "4              0                   0            0                 0   \n",
       "\n",
       "   team_Washington  team_Washington St.  team_Weber St.  team_West Virginia  \\\n",
       "0                0                    0               0                   0   \n",
       "1                0                    0               0                   0   \n",
       "2                0                    0               0                   0   \n",
       "3                0                    0               0                   0   \n",
       "4                0                    0               0                   0   \n",
       "\n",
       "   team_Western Carolina  team_Western Illinois  team_Western Kentucky  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   team_Western Michigan  team_Wichita St.  team_William & Mary  \\\n",
       "0                      0                 0                    0   \n",
       "1                      0                 0                    0   \n",
       "2                      0                 0                    0   \n",
       "3                      0                 0                    0   \n",
       "4                      0                 0                    0   \n",
       "\n",
       "   team_Winston Salem St.  team_Winthrop  team_Wisconsin  team_Wofford  \\\n",
       "0                       0              0               0             0   \n",
       "1                       0              0               0             0   \n",
       "2                       0              0               0             0   \n",
       "3                       0              0               0             0   \n",
       "4                       0              0               0             0   \n",
       "\n",
       "   team_Wright St.  team_Wyoming  team_Xavier  team_Yale  team_Youngstown St.  \n",
       "0                0             0            0          0                    0  \n",
       "1                0             0            0          0                    0  \n",
       "2                0             0            0          0                    0  \n",
       "3                0             0            0          0                    0  \n",
       "4                0             0            0          0                    0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Players features dataset\n",
    "df = pd.read_csv('../df_postprocessing_unscaled.csv')\n",
    "df2021 = pd.read_csv('../df_2021_postprocessing_unscaled.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39824, 437)\n",
      "(39824,)\n",
      "(9957, 437)\n",
      "(9957,)\n",
      "(4612, 439)\n",
      "(4612,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['first_round_drafted'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "test_df = df_2021\n",
    "\n",
    "train_df[cols] = scaler.fit_transform(train_df[cols])\n",
    "val_df[cols] = scaler.transform(val_df[cols])\n",
    "test_df[cols] = scaler.transform(df_2021[cols])\n",
    "\n",
    "X_train = train_df.drop(['first_round_drafted'], axis=1)\n",
    "y_train = train_df['first_round_drafted']\n",
    "\n",
    "X_val = val_df.drop(['first_round_drafted'], axis=1)\n",
    "y_val = val_df['first_round_drafted']\n",
    "\n",
    "X_test = test_df.drop(['first_round_drafted'], axis=1)\n",
    "y_test = test_df['first_round_drafted']\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop([\"level_0\", \"index\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb2 = xgb.XGBRegressor(verbosity=2, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'learning_rate': np.arange(0.001, 0.1, 0.005), \n",
    "              'max_depth': [4, 5, 6, 7, 8],\n",
    "              'min_child_weight': [1, 2, 3, 4, 5],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [100, 200, 300, 500],\n",
    "              'alpha': np.arange(0, 2, 0.1),\n",
    "              'lambda' : np.arange(0,2,0.1)}\n",
    "\n",
    "xgb_grid2 = RandomizedSearchCV(model_xgb2,\n",
    "                        parameters,\n",
    "                        cv = 4,\n",
    "                        n_jobs = 1,\n",
    "                        verbose=3,\n",
    "                        n_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.344 total time=   2.9s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.379 total time=   2.8s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.276 total time=   2.6s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.361 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.360 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.279 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.324 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.379 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.277 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.347 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.313 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.368 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.260 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.337 total time=   2.2s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.132 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.142 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.103 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.122 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.287 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.330 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.203 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.096, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.318 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.373 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.276 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.349 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.341 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.379 total time=   2.4s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.251 total time=   2.4s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.342 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.343 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.388 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.273 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.343 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.347 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.389 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.265 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.356 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.333 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.359 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.250 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.296 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.351 total time=   2.8s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.372 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.267 total time=   3.0s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.333 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.340 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.360 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.270 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.320 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.356 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.265 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.340 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.325 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.355 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.252 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.309 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.8, learning_rate=0.091, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.324 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.8, learning_rate=0.091, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.328 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.8, learning_rate=0.091, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.247 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.8, learning_rate=0.091, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.301 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.362 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.262 total time=   1.9s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.339 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.335 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.375 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.269 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.8, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.344 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.337 total time=   3.6s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.367 total time=   3.6s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.268 total time=   3.5s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.330 total time=   3.4s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.316 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.244 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.315 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.118 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.126 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.094 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.108 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.344 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.388 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.264 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.315 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.365 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.246 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.358 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.270 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.345 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.385 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.273 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.358 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.066, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.346 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.066, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.364 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.066, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.273 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.066, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.344 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.324 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.359 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.260 total time=   2.5s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.338 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.330 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.365 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.266 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.331 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.319 total time=   3.9s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.342 total time=   3.8s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.260 total time=   3.9s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.323 total time=   3.9s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.317 total time=   2.9s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.328 total time=   2.9s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.246 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.324 total time=   3.0s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.338 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.377 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.264 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.331 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.335 total time=   4.1s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.377 total time=   3.9s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.266 total time=   3.8s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.352 total time=   3.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.325 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.351 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.235 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.314 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.253 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.305 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.081, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.329 total time=   3.6s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.081, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.335 total time=   3.8s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.081, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.247 total time=   3.6s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.081, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.316 total time=   3.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.365 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.265 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.347 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.366 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.271 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.346 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.339 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.376 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.259 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.353 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.331 total time=   3.1s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.358 total time=   2.9s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.267 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.346 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.321 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.348 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.245 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.325 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.011, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.345 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.011, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.381 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.011, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.277 total time=   2.5s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.011, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.356 total time=   2.6s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.081, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.332 total time=   3.4s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.081, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.341 total time=   3.4s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.081, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.255 total time=   3.3s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.081, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.302 total time=   3.5s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.327 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.375 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.272 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.324 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.339 total time=   3.7s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.361 total time=   3.8s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.256 total time=   3.7s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.334 total time=   3.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.335 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.367 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.263 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.334 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.341 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.372 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.274 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.325 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.319 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.365 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.268 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.076, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.351 total time=   0.5s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.348 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.371 total time=   2.8s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.258 total time=   3.1s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.325 total time=   3.1s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.081, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.336 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.081, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.361 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.081, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.240 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.081, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.337 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.332 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.355 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.242 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.4, learning_rate=0.046, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.318 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.311 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.346 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.233 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.303 total time=   4.4s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.340 total time=   4.4s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.211 total time=   4.1s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.289 total time=   4.3s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.325 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.349 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.253 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.313 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.337 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.335 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.229 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.314 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.325 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.378 total time=   2.4s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.255 total time=   2.5s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.051000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.330 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.373 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.267 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.1, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.353 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.297 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.336 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.231 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.335 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.312 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.360 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.274 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.084 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.092 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.067 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.077 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.342 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.364 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.278 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.328 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.347 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.391 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.269 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.345 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.266 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.290 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.224 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.256 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.344 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.386 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.276 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.347 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.270 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.380 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.266 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.331 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.006, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.295 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.006, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.315 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.006, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.240 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.006, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.289 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.368 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.258 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.021, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.347 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.347 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.377 total time=   2.4s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.262 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.340 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.343 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.241 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.344 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.361 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.270 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.351 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.250 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.319 total time=   3.6s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.357 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.251 total time=   3.3s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.321 total time=   3.5s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.268 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.354 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.258 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.346 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.347 total time=   3.2s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.357 total time=   3.3s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.266 total time=   3.2s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.333 total time=   3.3s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.338 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.262 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.308 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.328 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.323 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.238 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.304 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.330 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.360 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.268 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.327 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.006, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.194 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.006, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.204 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.006, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.157 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.006, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.178 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.330 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.361 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.243 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.316 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.329 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.369 total time=   2.5s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.271 total time=   2.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.051000000000000004, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.335 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.345 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.346 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.246 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.336 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.323 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.328 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.207 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.326 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.309 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.328 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.223 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.310 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.081, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.328 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.081, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.339 total time=   1.8s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.081, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.215 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.081, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.317 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.323 total time=   3.8s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.324 total time=   3.9s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.230 total time=   3.7s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.313 total time=   3.7s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.313 total time=   3.6s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.332 total time=   3.4s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.248 total time=   3.5s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.322 total time=   3.5s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.324 total time=   3.0s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.375 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.260 total time=   3.0s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.331 total time=   3.1s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.320 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.340 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.245 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.331 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.351 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.266 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.322 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.352 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.269 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.343 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.340 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.378 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.265 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.353 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.190 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.210 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.158 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.006, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.178 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.364 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.272 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.328 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.346 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.379 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.248 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.346 total time=   2.2s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.327 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.387 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.259 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.336 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.303 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.207 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.324 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.314 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.359 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.255 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.341 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.176 total time=   3.4s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.191 total time=   3.3s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.139 total time=   3.4s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.164 total time=   3.3s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.267 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.316 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.320 total time=   3.5s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.380 total time=   3.5s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.246 total time=   3.5s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.332 total time=   3.5s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.313 total time=   3.9s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.331 total time=   3.8s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.246 total time=   3.8s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.305 total time=   3.9s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.330 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.354 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.224 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.061, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.311 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.346 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.385 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.278 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.355 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.323 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.348 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.248 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.335 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.336 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.367 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.277 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.361 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.268 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.267 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.295 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.224 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.253 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.364 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.251 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.344 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.266 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.0, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.0, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.377 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.0, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.275 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.0, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.347 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.324 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.349 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.249 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=8, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.319 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.352 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.379 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.263 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.337 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.376 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.275 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.324 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.345 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.375 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.259 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.330 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.318 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.322 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.257 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.336 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.377 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.254 total time=   2.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.335 total time=   2.6s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.320 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.369 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.273 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.352 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.358 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.255 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.066, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.322 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.085 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.089 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.068 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.077 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.346 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.390 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.264 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.056, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.342 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.324 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.355 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.272 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.325 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.338 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.370 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.275 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.352 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.323 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.351 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.228 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.327 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.006, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.273 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.006, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.288 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.006, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.221 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.006, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.258 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.056, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.339 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.056, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.336 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.056, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.256 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.056, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.329 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.255 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.279 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.212 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.250 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.317 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.335 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.231 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.061, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.303 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.319 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.323 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.209 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.076, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.302 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.343 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.382 total time=   2.6s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.261 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.021, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.345 total time=   2.8s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.325 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.343 total time=   0.5s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.269 total time=   0.5s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.318 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.334 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.372 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.276 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.334 total time=   3.4s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.372 total time=   3.5s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.264 total time=   3.4s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.351 total time=   3.4s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.323 total time=   3.3s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.337 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.224 total time=   3.6s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.324 total time=   3.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.255 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.276 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.216 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.241 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.324 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.347 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.246 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.332 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.056, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.056, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.349 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.056, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.269 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.056, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.334 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.326 total time=   4.0s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.362 total time=   4.1s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.250 total time=   3.9s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.332 total time=   3.9s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.350 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.385 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.265 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.348 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.021, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.334 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.021, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.375 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.021, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.271 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.021, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.343 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.365 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.278 total time=   0.5s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.347 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.347 total time=   2.5s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.386 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.264 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.343 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.336 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.374 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.246 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.355 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.375 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.269 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.352 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.325 total time=   0.5s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.5s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.263 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.031, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.324 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.360 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.254 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.323 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.361 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.255 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.318 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.182 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.195 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.145 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.171 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.326 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.351 total time=   2.8s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.236 total time=   2.8s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.339 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.324 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.257 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.325 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.328 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.364 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.266 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.334 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.246 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.342 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.360 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.273 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.269 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.302 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.225 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.264 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.085 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.094 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.068 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.078 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.011, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.343 total time=   3.1s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.011, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.374 total time=   3.3s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.011, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.272 total time=   3.0s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.011, max_depth=8, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.353 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.256 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.321 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.318 total time=   3.4s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.338 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.261 total time=   3.3s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.319 total time=   3.3s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.336 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.366 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.258 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.342 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.324 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.265 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.325 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.323 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.360 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.247 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.334 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.339 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.377 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.271 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.346 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.336 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.361 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.262 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.323 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.346 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.239 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.9, learning_rate=0.066, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.341 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.315 total time=   2.8s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.354 total time=   3.3s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.259 total time=   3.0s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.350 total time=   3.0s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.085 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.094 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.069 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.8, learning_rate=0.001, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.079 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.199 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.215 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.167 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.189 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.328 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.253 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.329 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.326 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.354 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.269 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.327 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.339 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.371 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.268 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.341 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.366 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.253 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.354 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.343 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.380 total time=   2.8s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.276 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.357 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.324 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.348 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.243 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.318 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.311 total time=   3.1s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.378 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.263 total time=   3.1s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.330 total time=   3.2s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.326 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.366 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.277 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.336 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.337 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.358 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.268 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.334 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.380 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.270 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.046, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.355 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.322 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.352 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.244 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.319 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.325 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.371 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.261 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.056, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.328 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.327 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.364 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.271 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.325 total time=   3.2s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.334 total time=   3.2s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.251 total time=   3.2s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.081, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.321 total time=   3.2s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.322 total time=   0.5s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.361 total time=   0.5s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.257 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.006, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.188 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.006, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.208 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.006, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.159 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.006, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.178 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.339 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.367 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.266 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.350 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.330 total time=   2.9s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.329 total time=   2.9s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.231 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.312 total time=   2.8s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.084 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.090 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.068 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.001, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.076 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.323 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.378 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.260 total time=   1.9s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.021, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.345 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.330 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.348 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.254 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.0, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.319 total time=   3.4s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.353 total time=   3.6s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.246 total time=   3.4s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.325 total time=   3.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.320 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.372 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.267 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.327 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.332 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.257 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.1, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.081, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.354 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.081, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.366 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.081, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.239 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.1, learning_rate=0.081, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.314 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.335 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.249 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.006, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.307 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.307 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.347 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.224 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.320 total time=   2.2s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.324 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.361 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.246 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.343 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.373 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.277 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.338 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.187 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.207 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.158 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.177 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.321 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.361 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.254 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.334 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.335 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.360 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.234 total time=   1.7s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.348 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.341 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.386 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.264 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.356 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.326 total time=   3.6s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.350 total time=   3.5s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.250 total time=   3.6s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.300 total time=   3.5s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.316 total time=   0.5s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.5s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.249 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.301 total time=   0.5s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.294 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.351 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.223 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.327 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.328 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.354 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.257 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.061, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.332 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.327 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.353 total time=   0.5s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.272 total time=   0.5s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.8, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.327 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.361 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.242 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.337 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.361 total time=   0.5s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.258 total time=   0.5s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.345 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.381 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.259 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.347 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.320 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.357 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.235 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.076, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.334 total time=   2.0s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.337 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.365 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.249 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.8, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.339 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.330 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.356 total time=   0.5s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.265 total time=   0.5s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.346 total time=   0.5s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.312 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.327 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.242 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.321 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.335 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.376 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.262 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.339 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.381 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.273 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.348 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.4, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.321 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.4, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.356 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.4, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.257 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.4, learning_rate=0.036000000000000004, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.340 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.359 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.253 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.336 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.350 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.272 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.091, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.320 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.325 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.360 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.236 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.345 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.256 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.358 total time=   0.5s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.282 total time=   0.5s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.341 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.340 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.373 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.279 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.344 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.344 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.379 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.268 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.350 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.293 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.316 total time=   0.5s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.239 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.016, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.285 total time=   0.5s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.304 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.344 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.250 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.046, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.330 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.306 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.348 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.228 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.324 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.048 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.052 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.040 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.045 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.345 total time=   3.4s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.371 total time=   3.5s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.252 total time=   3.4s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.343 total time=   3.3s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.327 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.377 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.278 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.0, learning_rate=0.041, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.351 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.319 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.233 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.8, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.323 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.325 total time=   3.5s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.337 total time=   3.5s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.229 total time=   3.4s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.066, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.323 total time=   3.4s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.327 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.373 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.233 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.336 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.328 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.357 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.268 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.5, learning_rate=0.006, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.340 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.261 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.5, learning_rate=0.081, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.112 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.119 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.091 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.102 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.334 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.268 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.344 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.386 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.268 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.061, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.348 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.319 total time=   3.4s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.331 total time=   3.6s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.244 total time=   3.5s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.335 total time=   3.5s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.096, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.315 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.096, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.337 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.096, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.243 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.096, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.319 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.265 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.290 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.219 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.006, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.252 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.301 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.341 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.235 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.315 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.333 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.354 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.227 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.325 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.338 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.346 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.249 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.167 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.177 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.136 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.001, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.154 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.095 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.103 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.076 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.001, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.088 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.336 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.381 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.275 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.311 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.340 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.253 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.006, max_depth=7, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.310 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.330 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.337 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.234 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.8, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.327 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.081, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.321 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.081, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.369 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.081, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.278 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.1, learning_rate=0.081, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.352 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.338 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.356 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.263 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.066, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.329 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.066, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.066, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.262 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.066, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.343 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.337 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.379 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.278 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.041, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.350 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.314 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.342 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.259 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.312 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.269 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.294 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.223 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.006, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.261 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.361 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.230 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.333 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.329 total time=   3.6s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.342 total time=   3.7s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.250 total time=   3.6s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.5, learning_rate=0.056, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.345 total time=   3.7s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.5s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.344 total time=   0.5s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.255 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.0, learning_rate=0.07100000000000001, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.5s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.331 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.356 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.266 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.316 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.273 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.292 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.224 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.262 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.335 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.372 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.266 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.046, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.324 total time=   2.6s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.333 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.371 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.234 total time=   2.4s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.339 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.346 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.387 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.267 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.041, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.346 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.343 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.377 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.263 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.046, max_depth=6, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.326 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.344 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.376 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.279 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.8, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.353 total time=   2.0s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.324 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.362 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.263 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.343 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.343 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.382 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.276 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.343 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.045 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.049 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.036 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.041 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.336 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.366 total time=   2.4s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.231 total time=   2.4s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.5, learning_rate=0.091, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.350 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.280 total time=   0.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.046, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.344 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.336 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.370 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.250 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.350 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.339 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.385 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.262 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.344 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.317 total time=   3.3s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.370 total time=   3.3s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.254 total time=   3.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.328 total time=   3.4s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.348 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.384 total time=   2.1s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.269 total time=   2.1s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.4, learning_rate=0.026000000000000002, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.353 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.362 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.260 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.0, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.335 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.336 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.370 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.270 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.5, learning_rate=0.016, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.350 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.364 total time=   0.5s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.267 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.6, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.351 total time=   0.5s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.8, learning_rate=0.081, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.305 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.8, learning_rate=0.081, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.327 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.8, learning_rate=0.081, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.235 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.8, learning_rate=0.081, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.329 total time=   2.2s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.319 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.358 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.252 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.319 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.283 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.346 total time=   1.9s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.199 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.310 total time=   2.0s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.332 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.358 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.267 total time=   2.0s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.330 total time=   2.0s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.348 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.374 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.276 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.352 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.341 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.354 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.266 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.343 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.001, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.046 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.001, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.049 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.001, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.037 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.001, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.041 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.006, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.263 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.006, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.281 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.006, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.214 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.006, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.251 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.374 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.263 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.334 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.366 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.284 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.341 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.086 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.091 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.068 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.078 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.318 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.344 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.262 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.315 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.188 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.207 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.158 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.006, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.176 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.354 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.381 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.275 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.4, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.327 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.366 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.236 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.5s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.274 total time=   0.5s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.327 total time=   0.5s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.288 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.343 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.225 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.096, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.315 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.342 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.375 total time=   1.8s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.275 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.5, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.351 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.341 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.382 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.273 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.342 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.325 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.339 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.252 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.332 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.323 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.352 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.267 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.011, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.325 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.341 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.366 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.262 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.031, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.347 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.321 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.354 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.266 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=6, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.320 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.364 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.271 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.336 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.351 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.257 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.308 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.317 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.226 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.9, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.311 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.334 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.374 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.276 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.346 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.333 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.374 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.268 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.352 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.366 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.272 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.326 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.056, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.316 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.056, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.359 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.056, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.257 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.056, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.331 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.346 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.381 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.276 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.345 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.3, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.3, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.365 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.3, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.267 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.3, learning_rate=0.081, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.334 total time=   2.4s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.372 total time=   2.4s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.249 total time=   2.5s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.348 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.337 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.378 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.271 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.348 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.368 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.272 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=6, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.331 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.338 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.364 total time=   2.4s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.255 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.329 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.335 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.361 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.248 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.021, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.339 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.310 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.346 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.257 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.316 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.293 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.316 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.244 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.1, learning_rate=0.016, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.285 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.341 total time=   3.2s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.366 total time=   3.5s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.263 total time=   3.2s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.329 total time=   3.3s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.335 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.237 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.337 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.340 total time=   1.6s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.382 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.270 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.6, learning_rate=0.041, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.342 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.299 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.339 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.229 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.091, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.313 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.331 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.355 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.238 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.326 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.091, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.301 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.091, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.327 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.091, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.182 total time=   1.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.091, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.296 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.334 total time=   3.9s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.377 total time=   3.5s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.255 total time=   3.5s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.036000000000000004, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.345 total time=   4.0s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.319 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.359 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.275 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.096, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.350 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.316 total time=   2.0s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.361 total time=   2.0s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.254 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.066, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.324 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.297 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.244 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.288 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.329 total time=   3.5s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.373 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.254 total time=   3.8s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.339 total time=   3.6s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.324 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.348 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.248 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.334 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.346 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.378 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.260 total time=   2.5s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.357 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.378 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.263 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.031, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.344 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.348 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.240 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.326 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.111 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.117 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.091 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.102 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.327 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.368 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.276 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.341 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.045 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.049 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.036 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.040 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.269 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.310 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.189 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.310 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.318 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.346 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.260 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.0, learning_rate=0.066, max_depth=8, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.331 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.368 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.246 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.091, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.354 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.318 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.359 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.243 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.327 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.329 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.331 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.229 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.066, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.326 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.329 total time=   2.8s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.363 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.237 total time=   3.1s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.328 total time=   3.5s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.310 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.247 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.299 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.5, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.326 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.5, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.365 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.5, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.273 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.5, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.346 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.347 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.363 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.276 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.319 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.339 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.378 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.278 total time=   2.5s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.5, learning_rate=0.011, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.352 total time=   2.4s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.1, learning_rate=0.066, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.338 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.1, learning_rate=0.066, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.364 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.1, learning_rate=0.066, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.278 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.1, learning_rate=0.066, max_depth=7, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.341 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.6, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.341 total time=   2.4s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.6, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.385 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.6, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.262 total time=   2.5s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.6, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.348 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.021, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.347 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.021, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.367 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.021, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.268 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.021, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.001, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.121 total time=   2.5s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.001, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.134 total time=   2.4s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.001, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.098 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.001, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.114 total time=   2.4s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.345 total time=   3.0s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.372 total time=   2.8s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.249 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.041, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.338 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.305 total time=   3.2s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.371 total time=   3.0s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.244 total time=   3.1s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.330 total time=   3.0s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.006, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.309 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.006, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.342 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.006, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.249 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.006, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.313 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.342 total time=   2.8s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.369 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.255 total time=   2.5s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.4, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.354 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.353 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.268 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.0, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.335 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.081, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.081, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.340 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.081, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.249 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.081, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.083 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.090 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.067 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.076 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.367 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.271 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.342 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.333 total time=   3.6s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.362 total time=   3.9s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.261 total time=   3.9s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.061, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.327 total time=   3.9s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.336 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.365 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.266 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.339 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.343 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.373 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.273 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.031, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.339 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.326 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.356 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.253 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.031, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.319 total time=   0.5s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.349 total time=   0.5s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.246 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.374 total time=   1.6s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.272 total time=   1.5s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.016, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.357 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.319 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.343 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.249 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.1, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.323 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.330 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.239 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.0, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.322 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.241 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.313 total time=   1.5s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.329 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.375 total time=   2.8s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.253 total time=   2.8s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.328 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.323 total time=   3.8s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.368 total time=   3.6s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.250 total time=   3.5s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.6, learning_rate=0.056, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.329 total time=   3.5s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.321 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.350 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.253 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=8, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.316 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.331 total time=   1.5s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.379 total time=   1.5s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.271 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.021, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.371 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.257 total time=   1.5s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.355 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.170 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.183 total time=   2.2s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.138 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.158 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.323 total time=   2.9s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.352 total time=   2.9s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.221 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.346 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.339 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.383 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.262 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.026000000000000002, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.346 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.342 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.382 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.271 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.041, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.357 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.050 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.055 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.041 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.046 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.303 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.333 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.180 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.081, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.295 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.350 total time=   3.0s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.388 total time=   3.0s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.265 total time=   2.9s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.350 total time=   3.0s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.324 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.343 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.258 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.330 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.322 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.345 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.237 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.081, max_depth=5, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.326 total time=   3.4s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.365 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.247 total time=   3.3s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.6, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.320 total time=   3.3s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.336 total time=   3.5s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.370 total time=   3.5s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.262 total time=   3.5s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.031, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.344 total time=   3.5s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.328 total time=   1.7s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.370 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.265 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.344 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.9, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.344 total time=   1.6s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.9, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.343 total time=   1.7s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.9, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.258 total time=   1.7s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.9, learning_rate=0.076, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.342 total time=   1.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.325 total time=   0.5s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.349 total time=   0.5s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.253 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.091, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.5s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.298 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.242 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.016, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.296 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.354 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.258 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.339 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.096, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.316 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.096, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.358 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.096, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.230 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.096, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.318 total time=   2.2s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.340 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.358 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.229 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.324 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.353 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.379 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.254 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.353 total time=   1.0s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.324 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.362 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.263 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.066, max_depth=4, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.328 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.016, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.335 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.016, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.362 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.016, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.274 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.016, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.031, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.031, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.373 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.031, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.274 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.031, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.347 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.343 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.364 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.263 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.016, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.344 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.349 total time=   2.9s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.386 total time=   2.9s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.275 total time=   2.9s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.360 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.340 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.370 total time=   2.6s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.259 total time=   2.6s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.330 total time=   2.7s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.273 total time=   1.4s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.302 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.225 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.006, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.270 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.335 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.382 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.280 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=4, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.350 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.306 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.330 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.248 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.300 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.360 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.267 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.5, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.331 total time=   0.5s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.358 total time=   0.5s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.277 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.061, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.6s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.183 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.197 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.145 total time=   2.8s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.001, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.170 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.1s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.347 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.252 total time=   1.1s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.051000000000000004, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.329 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.9s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.353 total time=   0.9s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.250 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=8, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.368 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.244 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.331 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.330 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.364 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.272 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.3, learning_rate=0.011, max_depth=5, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.327 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.362 total time=   2.8s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.254 total time=   2.8s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.08600000000000001, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.323 total time=   2.8s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.339 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.370 total time=   1.2s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.267 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.9, learning_rate=0.031, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.330 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.364 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.274 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.021, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.334 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.324 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.365 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.261 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.091, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.336 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.299 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.344 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.208 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.0, learning_rate=0.07100000000000001, max_depth=5, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.310 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.334 total time=   1.9s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.367 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.235 total time=   1.9s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=4, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.330 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.311 total time=   3.3s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.343 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.228 total time=   3.3s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.5, learning_rate=0.096, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.324 total time=   3.2s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.340 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.240 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.366 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.260 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.096, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.351 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.312 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.339 total time=   1.0s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.259 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.011, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.309 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.325 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.341 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.264 total time=   0.8s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=0.5, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.352 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.061, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.322 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.061, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.348 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.061, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.242 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.2, learning_rate=0.061, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.333 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.337 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.349 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.241 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=0.4, learning_rate=0.056, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.320 total time=   2.1s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.323 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.237 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.096, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.316 total time=   1.6s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.046, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.333 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.046, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.374 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.046, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.257 total time=   2.3s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.046, max_depth=5, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.349 total time=   2.3s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.314 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.374 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.237 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.349 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.333 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.366 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.277 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.330 total time=   0.9s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.307 total time=   3.1s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.344 total time=   3.1s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.247 total time=   3.1s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.091, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.337 total time=   3.2s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.340 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.361 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.279 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.332 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.375 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.250 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=1.6, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.346 total time=   1.9s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.344 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.359 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.261 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.061, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.333 total time=   1.7s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.337 total time=   1.0s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.384 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.273 total time=   1.0s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.046, max_depth=5, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.358 total time=   1.0s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.347 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.375 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.275 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=1.8, learning_rate=0.031, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.348 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.333 total time=   3.2s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.382 total time=   3.0s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.271 total time=   3.1s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.348 total time=   3.2s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.332 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.355 total time=   2.1s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.274 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.322 total time=   2.1s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.319 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.362 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.257 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.096, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.349 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.334 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.370 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.249 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.4, learning_rate=0.091, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.317 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.300 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.304 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.192 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.4, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.284 total time=   1.1s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.315 total time=   3.3s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.356 total time=   3.3s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.243 total time=   3.4s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.076, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.336 total time=   3.2s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.328 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.363 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.270 total time=   2.6s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.006, max_depth=7, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.340 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.321 total time=   3.2s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.325 total time=   3.2s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.221 total time=   3.1s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.091, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.294 total time=   3.2s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.337 total time=   2.2s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.355 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.234 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=8, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.318 total time=   2.2s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.340 total time=   2.6s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.347 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.246 total time=   2.4s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.2, learning_rate=0.07100000000000001, max_depth=8, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.328 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.045 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.048 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.037 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.9, learning_rate=0.001, max_depth=4, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.040 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.378 total time=   1.4s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.278 total time=   1.4s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.046, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.349 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.330 total time=   1.8s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.361 total time=   1.8s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.253 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.051000000000000004, max_depth=7, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.334 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.031, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.342 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.031, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.381 total time=   1.1s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.031, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.277 total time=   1.1s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.5, learning_rate=0.031, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.328 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.364 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.263 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.051000000000000004, max_depth=4, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.332 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.288 total time=   3.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.310 total time=   3.1s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.200 total time=   3.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.1, learning_rate=0.076, max_depth=8, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.306 total time=   3.0s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.344 total time=   2.1s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.375 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.272 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.016, max_depth=7, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.348 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.342 total time=   2.7s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.379 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.272 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=7, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.356 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.360 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.261 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.9, learning_rate=0.046, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.336 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.330 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.356 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.275 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.8, learning_rate=0.041, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.340 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.1, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.275 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.1, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.299 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.1, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.224 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.1, learning_rate=0.011, max_depth=7, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.266 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.274 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.294 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.225 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=8, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.261 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.331 total time=   2.0s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.377 total time=   2.0s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.269 total time=   2.0s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.346 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.325 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.352 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.262 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.011, max_depth=8, min_child_weight=2, n_estimators=200, subsample=0.7;, score=0.328 total time=   1.4s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.315 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.354 total time=   1.1s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.236 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=0.0, learning_rate=0.081, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.320 total time=   0.8s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.331 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.358 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.257 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.07100000000000001, max_depth=6, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.332 total time=   1.1s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.331 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.8s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.263 total time=   0.8s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.056, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.323 total time=   1.0s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.356 total time=   1.0s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.255 total time=   0.9s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.076, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.333 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.338 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.357 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.279 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.061, max_depth=5, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.006, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.322 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.006, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.345 total time=   1.8s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.006, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.263 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.2, learning_rate=0.006, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.327 total time=   1.9s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.339 total time=   2.2s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.372 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.272 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.011, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.348 total time=   2.3s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.011, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.341 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.011, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.380 total time=   2.3s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.011, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.272 total time=   2.3s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.5, learning_rate=0.011, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.356 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.341 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.364 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.264 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.091, max_depth=7, min_child_weight=2, n_estimators=100, subsample=0.7;, score=0.331 total time=   0.8s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.332 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.363 total time=   1.6s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.273 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=0.1, learning_rate=0.056, max_depth=8, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.308 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.337 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.374 total time=   3.0s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.261 total time=   3.0s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=0.8, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.346 total time=   2.9s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.328 total time=   0.5s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.342 total time=   0.5s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.243 total time=   0.5s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.6, learning_rate=0.096, max_depth=4, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.326 total time=   0.5s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.325 total time=   0.5s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.347 total time=   0.5s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.270 total time=   0.5s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=4, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.330 total time=   0.5s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.346 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.369 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.258 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.2, learning_rate=0.036000000000000004, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.329 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.8s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.348 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.249 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.2, learning_rate=0.031, max_depth=8, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.347 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.325 total time=   2.7s\n",
      "[CV 2/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.340 total time=   2.7s\n",
      "[CV 3/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.242 total time=   2.7s\n",
      "[CV 4/4] END alpha=0.1, colsample_bytree=0.7, lambda=0.5, learning_rate=0.061, max_depth=7, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.315 total time=   2.7s\n",
      "[CV 1/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.081, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.081, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.335 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.081, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.235 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.0, colsample_bytree=0.7, lambda=0.9, learning_rate=0.081, max_depth=7, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.314 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.122 total time=   1.3s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.129 total time=   1.4s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.097 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.6, learning_rate=0.001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.112 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.355 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.383 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.264 total time=   2.6s\n",
      "[CV 4/4] END alpha=1.6, colsample_bytree=0.7, lambda=0.4, learning_rate=0.031, max_depth=6, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.351 total time=   2.6s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.343 total time=   2.9s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.374 total time=   2.7s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.261 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.5, learning_rate=0.041, max_depth=6, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.343 total time=   2.9s\n",
      "[CV 1/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.084 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.091 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.067 total time=   1.3s\n",
      "[CV 4/4] END alpha=1.7000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.001, max_depth=8, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.077 total time=   1.3s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.362 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.278 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.4000000000000001, learning_rate=0.056, max_depth=6, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.338 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.343 total time=   3.3s\n",
      "[CV 2/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.385 total time=   3.4s\n",
      "[CV 3/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.274 total time=   3.3s\n",
      "[CV 4/4] END alpha=1.9000000000000001, colsample_bytree=0.7, lambda=0.0, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=500, subsample=0.7;, score=0.350 total time=   3.4s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.346 total time=   1.3s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.374 total time=   1.3s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.268 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=1, n_estimators=200, subsample=0.7;, score=0.351 total time=   1.3s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.334 total time=   0.6s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.366 total time=   0.6s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.275 total time=   0.6s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.5, learning_rate=0.041, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7;, score=0.337 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.338 total time=   1.2s\n",
      "[CV 2/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.372 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.273 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.8, colsample_bytree=0.7, lambda=1.0, learning_rate=0.021, max_depth=7, min_child_weight=4, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.269 total time=   0.7s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.289 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.223 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.6000000000000001, learning_rate=0.011, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.262 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.347 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.377 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.263 total time=   1.6s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.041, max_depth=6, min_child_weight=4, n_estimators=300, subsample=0.7;, score=0.340 total time=   1.5s\n",
      "[CV 1/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.312 total time=   2.5s\n",
      "[CV 2/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.347 total time=   2.5s\n",
      "[CV 3/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.258 total time=   2.5s\n",
      "[CV 4/4] END alpha=0.4, colsample_bytree=0.7, lambda=1.7000000000000002, learning_rate=0.061, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.327 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.096, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.324 total time=   3.0s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.096, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.353 total time=   3.0s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.096, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.246 total time=   2.9s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.5, learning_rate=0.096, max_depth=6, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.340 total time=   2.8s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.076, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.329 total time=   2.5s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.076, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.365 total time=   2.5s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.076, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.239 total time=   2.4s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=1.1, learning_rate=0.076, max_depth=5, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.343 total time=   2.5s\n",
      "[CV 1/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.324 total time=   3.6s\n",
      "[CV 2/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.335 total time=   3.6s\n",
      "[CV 3/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.227 total time=   3.5s\n",
      "[CV 4/4] END alpha=0.8, colsample_bytree=0.7, lambda=1.3, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.325 total time=   3.7s\n",
      "[CV 1/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.056, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.342 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.056, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.367 total time=   0.9s\n",
      "[CV 3/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.056, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.261 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.2000000000000002, colsample_bytree=0.7, lambda=0.2, learning_rate=0.056, max_depth=4, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.334 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.307 total time=   1.5s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.368 total time=   1.5s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.240 total time=   1.4s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.08600000000000001, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7;, score=0.338 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.342 total time=   1.7s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.374 total time=   1.7s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.270 total time=   1.6s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.1, learning_rate=0.016, max_depth=6, min_child_weight=2, n_estimators=300, subsample=0.7;, score=0.357 total time=   1.6s\n",
      "[CV 1/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.345 total time=   1.2s\n",
      "[CV 2/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.370 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.266 total time=   1.2s\n",
      "[CV 4/4] END alpha=0.7000000000000001, colsample_bytree=0.7, lambda=0.7000000000000001, learning_rate=0.026000000000000002, max_depth=7, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.348 total time=   1.2s\n",
      "[CV 1/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.041, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.335 total time=   2.3s\n",
      "[CV 2/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.041, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.373 total time=   2.3s\n",
      "[CV 3/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.041, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.254 total time=   2.2s\n",
      "[CV 4/4] END alpha=1.3, colsample_bytree=0.7, lambda=0.2, learning_rate=0.041, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.335 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.321 total time=   0.9s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.364 total time=   0.8s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.269 total time=   0.9s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=1.9000000000000001, learning_rate=0.046, max_depth=8, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.339 total time=   0.9s\n",
      "[CV 1/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.193 total time=   2.8s\n",
      "[CV 2/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.207 total time=   3.1s\n",
      "[CV 3/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.152 total time=   3.1s\n",
      "[CV 4/4] END alpha=0.30000000000000004, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.001, max_depth=8, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.178 total time=   3.2s\n",
      "[CV 1/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.340 total time=   1.4s\n",
      "[CV 2/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.368 total time=   1.3s\n",
      "[CV 3/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.264 total time=   1.3s\n",
      "[CV 4/4] END alpha=0.2, colsample_bytree=0.7, lambda=1.3, learning_rate=0.016, max_depth=8, min_child_weight=3, n_estimators=200, subsample=0.7;, score=0.349 total time=   1.4s\n",
      "[CV 1/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.340 total time=   1.1s\n",
      "[CV 2/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.376 total time=   1.2s\n",
      "[CV 3/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.274 total time=   1.2s\n",
      "[CV 4/4] END alpha=1.5, colsample_bytree=0.7, lambda=0.2, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=3, n_estimators=300, subsample=0.7;, score=0.341 total time=   1.2s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.318 total time=   2.3s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.349 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.230 total time=   2.2s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=1.6, learning_rate=0.076, max_depth=8, min_child_weight=1, n_estimators=300, subsample=0.7;, score=0.331 total time=   2.2s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.344 total time=   1.8s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.385 total time=   1.9s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.268 total time=   1.8s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.2000000000000002, learning_rate=0.026000000000000002, max_depth=4, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.341 total time=   1.8s\n",
      "[CV 1/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.333 total time=   2.6s\n",
      "[CV 2/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.362 total time=   2.6s\n",
      "[CV 3/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.247 total time=   2.7s\n",
      "[CV 4/4] END alpha=1.4000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.056, max_depth=6, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.331 total time=   2.6s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.333 total time=   0.6s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.367 total time=   0.6s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.256 total time=   0.6s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.0, learning_rate=0.091, max_depth=5, min_child_weight=3, n_estimators=100, subsample=0.7;, score=0.340 total time=   0.6s\n",
      "[CV 1/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.8s\n",
      "[CV 2/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.363 total time=   0.7s\n",
      "[CV 3/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.264 total time=   0.7s\n",
      "[CV 4/4] END alpha=1.0, colsample_bytree=0.7, lambda=0.5, learning_rate=0.096, max_depth=6, min_child_weight=1, n_estimators=100, subsample=0.7;, score=0.330 total time=   0.7s\n",
      "[CV 1/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.326 total time=   3.2s\n",
      "[CV 2/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.338 total time=   3.2s\n",
      "[CV 3/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.236 total time=   3.1s\n",
      "[CV 4/4] END alpha=1.1, colsample_bytree=0.7, lambda=0.30000000000000004, learning_rate=0.08600000000000001, max_depth=7, min_child_weight=1, n_estimators=500, subsample=0.7;, score=0.333 total time=   3.2s\n",
      "[CV 1/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.326 total time=   1.9s\n",
      "[CV 2/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.337 total time=   1.8s\n",
      "[CV 3/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.212 total time=   1.8s\n",
      "[CV 4/4] END alpha=0.5, colsample_bytree=0.7, lambda=0.1, learning_rate=0.096, max_depth=4, min_child_weight=2, n_estimators=500, subsample=0.7;, score=0.309 total time=   1.8s\n",
      "[CV 1/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.329 total time=   0.7s\n",
      "[CV 2/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.345 total time=   0.7s\n",
      "[CV 3/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.272 total time=   0.7s\n",
      "[CV 4/4] END alpha=0.9, colsample_bytree=0.7, lambda=0.9, learning_rate=0.056, max_depth=7, min_child_weight=4, n_estimators=100, subsample=0.7;, score=0.325 total time=   0.7s\n",
      "[CV 1/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.341 total time=   2.1s\n",
      "[CV 2/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.368 total time=   2.2s\n",
      "[CV 3/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.251 total time=   2.1s\n",
      "[CV 4/4] END alpha=0.6000000000000001, colsample_bytree=0.7, lambda=1.8, learning_rate=0.036000000000000004, max_depth=5, min_child_weight=4, n_estimators=500, subsample=0.7;, score=0.338 total time=   2.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=4,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=&#x27;cuda&#x27;,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rat...\n",
       "                                        &#x27;lambda&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
       "       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]),\n",
       "                                        &#x27;learning_rate&#x27;: array([0.001, 0.006, 0.011, 0.016, 0.021, 0.026, 0.031, 0.036, 0.041,\n",
       "       0.046, 0.051, 0.056, 0.061, 0.066, 0.071, 0.076, 0.081, 0.086,\n",
       "       0.091, 0.096]),\n",
       "                                        &#x27;max_depth&#x27;: [4, 5, 6, 7, 8],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 500],\n",
       "                                        &#x27;subsample&#x27;: [0.7]},\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=4,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=&#x27;cuda&#x27;,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rat...\n",
       "                                        &#x27;lambda&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
       "       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]),\n",
       "                                        &#x27;learning_rate&#x27;: array([0.001, 0.006, 0.011, 0.016, 0.021, 0.026, 0.031, 0.036, 0.041,\n",
       "       0.046, 0.051, 0.056, 0.061, 0.066, 0.071, 0.076, 0.081, 0.086,\n",
       "       0.091, 0.096]),\n",
       "                                        &#x27;max_depth&#x27;: [4, 5, 6, 7, 8],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 500],\n",
       "                                        &#x27;subsample&#x27;: [0.7]},\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=4,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device='cuda',\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rat...\n",
       "                                        'lambda': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
       "       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]),\n",
       "                                        'learning_rate': array([0.001, 0.006, 0.011, 0.016, 0.021, 0.026, 0.031, 0.036, 0.041,\n",
       "       0.046, 0.051, 0.056, 0.061, 0.066, 0.071, 0.076, 0.081, 0.086,\n",
       "       0.091, 0.096]),\n",
       "                                        'max_depth': [4, 5, 6, 7, 8],\n",
       "                                        'min_child_weight': [1, 2, 3, 4, 5],\n",
       "                                        'n_estimators': [100, 200, 300, 500],\n",
       "                                        'subsample': [0.7]},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_round_drafted\n",
       "0.0    29\n",
       "1.0     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba2 = xgb_grid2.predict(X_test)\n",
    "pred_proba_df2 = pd.DataFrame(predicted_proba2)\n",
    "pred_proba_df2.columns = ['pred-prob']\n",
    "df_2021 = df_2021.reset_index(drop=True)\n",
    "\n",
    "merged_df2 = df_2021.merge(pred_proba_df2, left_index=True, right_index=True)\n",
    "\n",
    "selected_by_model = merged_df2.sort_values('pred-prob', ascending=False).head(30)\n",
    "selected_by_model.first_round_drafted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb3 = xgb.XGBRegressor(verbosity=2, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_round_drafted\n",
       "0.0    29\n",
       "1.0     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba3 = model_xgb3.predict(X_test)\n",
    "pred_proba_df3 = pd.DataFrame(predicted_proba3)\n",
    "pred_proba_df3.columns = ['pred-prob']\n",
    "df_2021 = df_2021.reset_index(drop=True)\n",
    "\n",
    "merged_df3 = df_2021.merge(pred_proba_df3, left_index=True, right_index=True)\n",
    "\n",
    "selected_by_model = merged_df3.sort_values('pred-prob', ascending=False).head(30)\n",
    "selected_by_model.first_round_drafted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca.fit(X_train)\n",
    "X_train_reduced = pca.transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_log = OrderedModel(y_train,\n",
    "                        X_train_reduced,\n",
    "                        distr='logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.022427\n",
      "         Iterations: 244\n",
      "         Function evaluations: 250\n",
      "         Gradient evaluations: 250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>first_round_drafted</td> <th>  Log-Likelihood:    </th> <td> -893.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>     <th>  AIC:               </th> <td>   1888.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td>  <th>  BIC:               </th> <td>   2327.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 14 Nov 2023</td>   <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>19:43:22</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td> 39824</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td> 39773</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    50</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>      <td>    2.9890</td> <td>    0.371</td> <td>    8.064</td> <td> 0.000</td> <td>    2.263</td> <td>    3.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>      <td>    0.5398</td> <td>    0.193</td> <td>    2.797</td> <td> 0.005</td> <td>    0.162</td> <td>    0.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>      <td>   -0.9167</td> <td>    0.240</td> <td>   -3.826</td> <td> 0.000</td> <td>   -1.386</td> <td>   -0.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>      <td>   -0.1778</td> <td>    0.238</td> <td>   -0.748</td> <td> 0.454</td> <td>   -0.643</td> <td>    0.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>      <td>    1.9611</td> <td>    0.278</td> <td>    7.060</td> <td> 0.000</td> <td>    1.417</td> <td>    2.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>      <td>   -1.2947</td> <td>    0.214</td> <td>   -6.039</td> <td> 0.000</td> <td>   -1.715</td> <td>   -0.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>      <td>    0.2056</td> <td>    0.299</td> <td>    0.687</td> <td> 0.492</td> <td>   -0.381</td> <td>    0.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>      <td>   -0.3866</td> <td>    0.225</td> <td>   -1.721</td> <td> 0.085</td> <td>   -0.827</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>      <td>   -0.3190</td> <td>    0.234</td> <td>   -1.361</td> <td> 0.174</td> <td>   -0.778</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>     <td>    0.5169</td> <td>    0.196</td> <td>    2.637</td> <td> 0.008</td> <td>    0.133</td> <td>    0.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>     <td>    0.3038</td> <td>    0.261</td> <td>    1.166</td> <td> 0.244</td> <td>   -0.207</td> <td>    0.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>     <td>    0.7501</td> <td>    0.273</td> <td>    2.743</td> <td> 0.006</td> <td>    0.214</td> <td>    1.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>     <td>   -0.3426</td> <td>    0.358</td> <td>   -0.957</td> <td> 0.339</td> <td>   -1.044</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>     <td>    0.2107</td> <td>    0.485</td> <td>    0.435</td> <td> 0.664</td> <td>   -0.739</td> <td>    1.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>     <td>   -0.3603</td> <td>    0.301</td> <td>   -1.199</td> <td> 0.231</td> <td>   -0.950</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>     <td>    0.7202</td> <td>    0.301</td> <td>    2.395</td> <td> 0.017</td> <td>    0.131</td> <td>    1.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>     <td>    0.4911</td> <td>    0.359</td> <td>    1.369</td> <td> 0.171</td> <td>   -0.212</td> <td>    1.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>     <td>   -0.5532</td> <td>    0.338</td> <td>   -1.638</td> <td> 0.101</td> <td>   -1.215</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>     <td>    0.6828</td> <td>    0.528</td> <td>    1.294</td> <td> 0.196</td> <td>   -0.351</td> <td>    1.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>     <td>    1.6186</td> <td>    0.390</td> <td>    4.154</td> <td> 0.000</td> <td>    0.855</td> <td>    2.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>     <td>    1.0926</td> <td>    0.768</td> <td>    1.423</td> <td> 0.155</td> <td>   -0.413</td> <td>    2.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>     <td>    1.2598</td> <td>    0.391</td> <td>    3.225</td> <td> 0.001</td> <td>    0.494</td> <td>    2.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>     <td>   -0.4482</td> <td>    0.435</td> <td>   -1.031</td> <td> 0.303</td> <td>   -1.301</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>     <td>    0.1657</td> <td>    0.963</td> <td>    0.172</td> <td> 0.863</td> <td>   -1.721</td> <td>    2.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>     <td>    2.8549</td> <td>    0.648</td> <td>    4.409</td> <td> 0.000</td> <td>    1.586</td> <td>    4.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>     <td>    2.8044</td> <td>    0.972</td> <td>    2.884</td> <td> 0.004</td> <td>    0.899</td> <td>    4.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>     <td>    4.4885</td> <td>    0.585</td> <td>    7.674</td> <td> 0.000</td> <td>    3.342</td> <td>    5.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>     <td>    0.3805</td> <td>    0.520</td> <td>    0.732</td> <td> 0.464</td> <td>   -0.638</td> <td>    1.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>     <td>   -4.0011</td> <td>    0.589</td> <td>   -6.794</td> <td> 0.000</td> <td>   -5.155</td> <td>   -2.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>     <td>   -2.4451</td> <td>    1.117</td> <td>   -2.190</td> <td> 0.029</td> <td>   -4.634</td> <td>   -0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>     <td>   -2.8809</td> <td>    1.311</td> <td>   -2.198</td> <td> 0.028</td> <td>   -5.450</td> <td>   -0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>     <td>  -10.6287</td> <td>    0.868</td> <td>  -12.251</td> <td> 0.000</td> <td>  -12.329</td> <td>   -8.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>     <td>    5.8319</td> <td>    0.952</td> <td>    6.124</td> <td> 0.000</td> <td>    3.965</td> <td>    7.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>     <td>    4.6374</td> <td>    1.527</td> <td>    3.038</td> <td> 0.002</td> <td>    1.645</td> <td>    7.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>     <td>   -0.5878</td> <td>    1.276</td> <td>   -0.461</td> <td> 0.645</td> <td>   -3.088</td> <td>    1.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>     <td>   -3.1863</td> <td>    1.111</td> <td>   -2.869</td> <td> 0.004</td> <td>   -5.363</td> <td>   -1.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>     <td>    1.5808</td> <td>    0.953</td> <td>    1.659</td> <td> 0.097</td> <td>   -0.287</td> <td>    3.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>     <td>   -5.8312</td> <td>    1.031</td> <td>   -5.654</td> <td> 0.000</td> <td>   -7.853</td> <td>   -3.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>     <td>   -0.5551</td> <td>    1.059</td> <td>   -0.524</td> <td> 0.600</td> <td>   -2.631</td> <td>    1.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>     <td>   -0.8218</td> <td>    1.107</td> <td>   -0.742</td> <td> 0.458</td> <td>   -2.992</td> <td>    1.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>     <td>    1.4272</td> <td>    1.466</td> <td>    0.974</td> <td> 0.330</td> <td>   -1.446</td> <td>    4.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>     <td>    1.1001</td> <td>    1.315</td> <td>    0.836</td> <td> 0.403</td> <td>   -1.477</td> <td>    3.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>     <td>    1.3126</td> <td>    1.198</td> <td>    1.096</td> <td> 0.273</td> <td>   -1.035</td> <td>    3.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>     <td>   -0.3874</td> <td>    1.372</td> <td>   -0.282</td> <td> 0.778</td> <td>   -3.077</td> <td>    2.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>     <td>   -0.3308</td> <td>    1.152</td> <td>   -0.287</td> <td> 0.774</td> <td>   -2.588</td> <td>    1.927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>     <td>   -0.3255</td> <td>    1.301</td> <td>   -0.250</td> <td> 0.802</td> <td>   -2.876</td> <td>    2.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>     <td>   -1.5311</td> <td>    1.188</td> <td>   -1.289</td> <td> 0.198</td> <td>   -3.860</td> <td>    0.798</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>     <td>    2.7700</td> <td>    1.222</td> <td>    2.267</td> <td> 0.023</td> <td>    0.375</td> <td>    5.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>     <td>    0.7458</td> <td>    1.098</td> <td>    0.679</td> <td> 0.497</td> <td>   -1.407</td> <td>    2.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>     <td>    0.4570</td> <td>    1.252</td> <td>    0.365</td> <td> 0.715</td> <td>   -1.998</td> <td>    2.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.0/1.0</th> <td>    9.2303</td> <td>    0.330</td> <td>   27.934</td> <td> 0.000</td> <td>    8.583</td> <td>    9.878</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    & first\\_round\\_drafted & \\textbf{  Log-Likelihood:    } &   -893.15   \\\\\n",
       "\\textbf{Model:}            &      OrderedModel     & \\textbf{  AIC:               } &     1888.   \\\\\n",
       "\\textbf{Method:}           &   Maximum Likelihood  & \\textbf{  BIC:               } &     2327.   \\\\\n",
       "\\textbf{Date:}             &    Tue, 14 Nov 2023   & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}             &        19:43:22       & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Observations:} &          39824        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Df Residuals:}     &          39773        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Df Model:}         &             50        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                 & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{x1}      &       2.9890  &        0.371     &     8.064  &         0.000        &        2.263    &        3.716     \\\\\n",
       "\\textbf{x2}      &       0.5398  &        0.193     &     2.797  &         0.005        &        0.162    &        0.918     \\\\\n",
       "\\textbf{x3}      &      -0.9167  &        0.240     &    -3.826  &         0.000        &       -1.386    &       -0.447     \\\\\n",
       "\\textbf{x4}      &      -0.1778  &        0.238     &    -0.748  &         0.454        &       -0.643    &        0.288     \\\\\n",
       "\\textbf{x5}      &       1.9611  &        0.278     &     7.060  &         0.000        &        1.417    &        2.506     \\\\\n",
       "\\textbf{x6}      &      -1.2947  &        0.214     &    -6.039  &         0.000        &       -1.715    &       -0.875     \\\\\n",
       "\\textbf{x7}      &       0.2056  &        0.299     &     0.687  &         0.492        &       -0.381    &        0.792     \\\\\n",
       "\\textbf{x8}      &      -0.3866  &        0.225     &    -1.721  &         0.085        &       -0.827    &        0.054     \\\\\n",
       "\\textbf{x9}      &      -0.3190  &        0.234     &    -1.361  &         0.174        &       -0.778    &        0.140     \\\\\n",
       "\\textbf{x10}     &       0.5169  &        0.196     &     2.637  &         0.008        &        0.133    &        0.901     \\\\\n",
       "\\textbf{x11}     &       0.3038  &        0.261     &     1.166  &         0.244        &       -0.207    &        0.815     \\\\\n",
       "\\textbf{x12}     &       0.7501  &        0.273     &     2.743  &         0.006        &        0.214    &        1.286     \\\\\n",
       "\\textbf{x13}     &      -0.3426  &        0.358     &    -0.957  &         0.339        &       -1.044    &        0.359     \\\\\n",
       "\\textbf{x14}     &       0.2107  &        0.485     &     0.435  &         0.664        &       -0.739    &        1.161     \\\\\n",
       "\\textbf{x15}     &      -0.3603  &        0.301     &    -1.199  &         0.231        &       -0.950    &        0.229     \\\\\n",
       "\\textbf{x16}     &       0.7202  &        0.301     &     2.395  &         0.017        &        0.131    &        1.310     \\\\\n",
       "\\textbf{x17}     &       0.4911  &        0.359     &     1.369  &         0.171        &       -0.212    &        1.194     \\\\\n",
       "\\textbf{x18}     &      -0.5532  &        0.338     &    -1.638  &         0.101        &       -1.215    &        0.109     \\\\\n",
       "\\textbf{x19}     &       0.6828  &        0.528     &     1.294  &         0.196        &       -0.351    &        1.717     \\\\\n",
       "\\textbf{x20}     &       1.6186  &        0.390     &     4.154  &         0.000        &        0.855    &        2.382     \\\\\n",
       "\\textbf{x21}     &       1.0926  &        0.768     &     1.423  &         0.155        &       -0.413    &        2.598     \\\\\n",
       "\\textbf{x22}     &       1.2598  &        0.391     &     3.225  &         0.001        &        0.494    &        2.026     \\\\\n",
       "\\textbf{x23}     &      -0.4482  &        0.435     &    -1.031  &         0.303        &       -1.301    &        0.404     \\\\\n",
       "\\textbf{x24}     &       0.1657  &        0.963     &     0.172  &         0.863        &       -1.721    &        2.053     \\\\\n",
       "\\textbf{x25}     &       2.8549  &        0.648     &     4.409  &         0.000        &        1.586    &        4.124     \\\\\n",
       "\\textbf{x26}     &       2.8044  &        0.972     &     2.884  &         0.004        &        0.899    &        4.710     \\\\\n",
       "\\textbf{x27}     &       4.4885  &        0.585     &     7.674  &         0.000        &        3.342    &        5.635     \\\\\n",
       "\\textbf{x28}     &       0.3805  &        0.520     &     0.732  &         0.464        &       -0.638    &        1.399     \\\\\n",
       "\\textbf{x29}     &      -4.0011  &        0.589     &    -6.794  &         0.000        &       -5.155    &       -2.847     \\\\\n",
       "\\textbf{x30}     &      -2.4451  &        1.117     &    -2.190  &         0.029        &       -4.634    &       -0.256     \\\\\n",
       "\\textbf{x31}     &      -2.8809  &        1.311     &    -2.198  &         0.028        &       -5.450    &       -0.312     \\\\\n",
       "\\textbf{x32}     &     -10.6287  &        0.868     &   -12.251  &         0.000        &      -12.329    &       -8.928     \\\\\n",
       "\\textbf{x33}     &       5.8319  &        0.952     &     6.124  &         0.000        &        3.965    &        7.698     \\\\\n",
       "\\textbf{x34}     &       4.6374  &        1.527     &     3.038  &         0.002        &        1.645    &        7.629     \\\\\n",
       "\\textbf{x35}     &      -0.5878  &        1.276     &    -0.461  &         0.645        &       -3.088    &        1.913     \\\\\n",
       "\\textbf{x36}     &      -3.1863  &        1.111     &    -2.869  &         0.004        &       -5.363    &       -1.010     \\\\\n",
       "\\textbf{x37}     &       1.5808  &        0.953     &     1.659  &         0.097        &       -0.287    &        3.449     \\\\\n",
       "\\textbf{x38}     &      -5.8312  &        1.031     &    -5.654  &         0.000        &       -7.853    &       -3.810     \\\\\n",
       "\\textbf{x39}     &      -0.5551  &        1.059     &    -0.524  &         0.600        &       -2.631    &        1.521     \\\\\n",
       "\\textbf{x40}     &      -0.8218  &        1.107     &    -0.742  &         0.458        &       -2.992    &        1.348     \\\\\n",
       "\\textbf{x41}     &       1.4272  &        1.466     &     0.974  &         0.330        &       -1.446    &        4.300     \\\\\n",
       "\\textbf{x42}     &       1.1001  &        1.315     &     0.836  &         0.403        &       -1.477    &        3.678     \\\\\n",
       "\\textbf{x43}     &       1.3126  &        1.198     &     1.096  &         0.273        &       -1.035    &        3.660     \\\\\n",
       "\\textbf{x44}     &      -0.3874  &        1.372     &    -0.282  &         0.778        &       -3.077    &        2.302     \\\\\n",
       "\\textbf{x45}     &      -0.3308  &        1.152     &    -0.287  &         0.774        &       -2.588    &        1.927     \\\\\n",
       "\\textbf{x46}     &      -0.3255  &        1.301     &    -0.250  &         0.802        &       -2.876    &        2.225     \\\\\n",
       "\\textbf{x47}     &      -1.5311  &        1.188     &    -1.289  &         0.198        &       -3.860    &        0.798     \\\\\n",
       "\\textbf{x48}     &       2.7700  &        1.222     &     2.267  &         0.023        &        0.375    &        5.165     \\\\\n",
       "\\textbf{x49}     &       0.7458  &        1.098     &     0.679  &         0.497        &       -1.407    &        2.899     \\\\\n",
       "\\textbf{x50}     &       0.4570  &        1.252     &     0.365  &         0.715        &       -1.998    &        2.912     \\\\\n",
       "\\textbf{0.0/1.0} &       9.2303  &        0.330     &    27.934  &         0.000        &        8.583    &        9.878     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OrderedModel Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              OrderedModel Results                             \n",
       "===============================================================================\n",
       "Dep. Variable:     first_round_drafted   Log-Likelihood:                -893.15\n",
       "Model:                    OrderedModel   AIC:                             1888.\n",
       "Method:             Maximum Likelihood   BIC:                             2327.\n",
       "Date:                 Tue, 14 Nov 2023                                         \n",
       "Time:                         19:43:22                                         \n",
       "No. Observations:                39824                                         \n",
       "Df Residuals:                    39773                                         \n",
       "Df Model:                           50                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             2.9890      0.371      8.064      0.000       2.263       3.716\n",
       "x2             0.5398      0.193      2.797      0.005       0.162       0.918\n",
       "x3            -0.9167      0.240     -3.826      0.000      -1.386      -0.447\n",
       "x4            -0.1778      0.238     -0.748      0.454      -0.643       0.288\n",
       "x5             1.9611      0.278      7.060      0.000       1.417       2.506\n",
       "x6            -1.2947      0.214     -6.039      0.000      -1.715      -0.875\n",
       "x7             0.2056      0.299      0.687      0.492      -0.381       0.792\n",
       "x8            -0.3866      0.225     -1.721      0.085      -0.827       0.054\n",
       "x9            -0.3190      0.234     -1.361      0.174      -0.778       0.140\n",
       "x10            0.5169      0.196      2.637      0.008       0.133       0.901\n",
       "x11            0.3038      0.261      1.166      0.244      -0.207       0.815\n",
       "x12            0.7501      0.273      2.743      0.006       0.214       1.286\n",
       "x13           -0.3426      0.358     -0.957      0.339      -1.044       0.359\n",
       "x14            0.2107      0.485      0.435      0.664      -0.739       1.161\n",
       "x15           -0.3603      0.301     -1.199      0.231      -0.950       0.229\n",
       "x16            0.7202      0.301      2.395      0.017       0.131       1.310\n",
       "x17            0.4911      0.359      1.369      0.171      -0.212       1.194\n",
       "x18           -0.5532      0.338     -1.638      0.101      -1.215       0.109\n",
       "x19            0.6828      0.528      1.294      0.196      -0.351       1.717\n",
       "x20            1.6186      0.390      4.154      0.000       0.855       2.382\n",
       "x21            1.0926      0.768      1.423      0.155      -0.413       2.598\n",
       "x22            1.2598      0.391      3.225      0.001       0.494       2.026\n",
       "x23           -0.4482      0.435     -1.031      0.303      -1.301       0.404\n",
       "x24            0.1657      0.963      0.172      0.863      -1.721       2.053\n",
       "x25            2.8549      0.648      4.409      0.000       1.586       4.124\n",
       "x26            2.8044      0.972      2.884      0.004       0.899       4.710\n",
       "x27            4.4885      0.585      7.674      0.000       3.342       5.635\n",
       "x28            0.3805      0.520      0.732      0.464      -0.638       1.399\n",
       "x29           -4.0011      0.589     -6.794      0.000      -5.155      -2.847\n",
       "x30           -2.4451      1.117     -2.190      0.029      -4.634      -0.256\n",
       "x31           -2.8809      1.311     -2.198      0.028      -5.450      -0.312\n",
       "x32          -10.6287      0.868    -12.251      0.000     -12.329      -8.928\n",
       "x33            5.8319      0.952      6.124      0.000       3.965       7.698\n",
       "x34            4.6374      1.527      3.038      0.002       1.645       7.629\n",
       "x35           -0.5878      1.276     -0.461      0.645      -3.088       1.913\n",
       "x36           -3.1863      1.111     -2.869      0.004      -5.363      -1.010\n",
       "x37            1.5808      0.953      1.659      0.097      -0.287       3.449\n",
       "x38           -5.8312      1.031     -5.654      0.000      -7.853      -3.810\n",
       "x39           -0.5551      1.059     -0.524      0.600      -2.631       1.521\n",
       "x40           -0.8218      1.107     -0.742      0.458      -2.992       1.348\n",
       "x41            1.4272      1.466      0.974      0.330      -1.446       4.300\n",
       "x42            1.1001      1.315      0.836      0.403      -1.477       3.678\n",
       "x43            1.3126      1.198      1.096      0.273      -1.035       3.660\n",
       "x44           -0.3874      1.372     -0.282      0.778      -3.077       2.302\n",
       "x45           -0.3308      1.152     -0.287      0.774      -2.588       1.927\n",
       "x46           -0.3255      1.301     -0.250      0.802      -2.876       2.225\n",
       "x47           -1.5311      1.188     -1.289      0.198      -3.860       0.798\n",
       "x48            2.7700      1.222      2.267      0.023       0.375       5.165\n",
       "x49            0.7458      1.098      0.679      0.497      -1.407       2.899\n",
       "x50            0.4570      1.252      0.365      0.715      -1.998       2.912\n",
       "0.0/1.0        9.2303      0.330     27.934      0.000       8.583       9.878\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_log = mod_log.fit(method='bfgs')\n",
    "res_log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.08773324e-06, 1.06488542e-05, 1.22626907e-04, ...,\n",
       "       1.45387674e-05, 1.45460737e-04, 6.94169754e-05])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = res_log.model.predict(res_log.params, exog=X_test_reduced)[:,1]\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_round_drafted\n",
       "0.0    28\n",
       "1.0     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_df4 = pd.DataFrame(predicted)\n",
    "pred_proba_df4.columns = ['pred-prob']\n",
    "df_2021 = df_2021.reset_index(drop=True)\n",
    "\n",
    "merged_df4 = df_2021.merge(pred_proba_df4, left_index=True, right_index=True)\n",
    "\n",
    "selected_by_model = merged_df4.sort_values('pred-prob', ascending=False).head(30)\n",
    "selected_by_model.first_round_drafted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valentinpinon/anaconda3/lib/python3.11/site-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Maximum number of iterations has been exceeded.\n",
      "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 0.017213\n",
      "         Iterations: 500\n",
      "         Function evaluations: 504\n",
      "         Gradient evaluations: 504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valentinpinon/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n",
      "/Users/valentinpinon/anaconda3/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>first_round_drafted</td> <th>  Log-Likelihood:    </th> <td> -685.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>     <th>  AIC:               </th> <td>   2247.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td>  <th>  BIC:               </th> <td>   6010.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Tue, 14 Nov 2023</td>   <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>20:56:07</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td> 39824</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td> 39386</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>   437</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GP</th>                          <td>    4.6420</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Min_per</th>                     <td>   -2.1438</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ortg</th>                        <td>   -2.3653</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>usg</th>                         <td>    5.7988</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>eFG</th>                         <td>   -3.3507</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TS_per</th>                      <td>   -3.9790</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ORB_per</th>                     <td>   -1.0846</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DRB_per</th>                     <td>   -1.1190</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AST_per</th>                     <td>  -16.7016</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TO_per</th>                      <td>    9.6715</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FTM</th>                         <td>   -5.5817</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FTA</th>                         <td>    4.5557</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FT_per</th>                      <td>    1.6140</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>twoPM</th>                       <td>    0.6514</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>twoPA</th>                       <td>   -0.3448</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>twoP_per</th>                    <td>   -4.3279</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TPM</th>                         <td>    9.8135</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TPA</th>                         <td>   -5.6538</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TP_per</th>                      <td>   -0.9567</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blk_per</th>                     <td>   -1.2475</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stl_per</th>                     <td>   -1.9993</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ftr</th>                         <td>    0.5964</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr</th>                          <td>   -1.3372</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>num</th>                         <td>   -1.1840</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>porpag</th>                      <td>   20.3214</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adjoe</th>                       <td>    1.7309</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pfr</th>                         <td>   -2.3797</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pid</th>                         <td>   -0.4384</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ast/tov</th>                     <td>   -2.3596</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rimmade</th>                     <td>    2.4792</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rimmade+rimmiss</th>             <td>   -1.3704</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>midmade</th>                     <td>   -0.0410</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>midmade+midmiss</th>             <td>    1.2930</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rimmade/(rimmade+rimmiss)</th>   <td>    2.9569</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>midmade/(midmade+midmiss)</th>   <td>    2.5957</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dunksmade</th>                   <td>   -0.2887</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dunksmiss+dunksmade</th>         <td>    4.5466</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drtg</th>                        <td>   -6.3299</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adrtg</th>                       <td>   -7.3482</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dporpag</th>                     <td>    7.6611</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stops</th>                       <td>   -8.2015</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bpm</th>                         <td>   -1.0401</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>obpm</th>                        <td>   -0.0729</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dbpm</th>                        <td>   -2.3034</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gbpm</th>                        <td>   -1.4030</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mp</th>                          <td>   -4.1627</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ogbpm</th>                       <td>    0.4580</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dgbpm</th>                       <td>   -3.9976</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oreb</th>                        <td>   -1.3439</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dreb</th>                        <td>    3.6782</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treb</th>                        <td>    2.3989</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ast</th>                         <td>   13.0460</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stl</th>                         <td>    3.9959</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>blk</th>                         <td>    5.6171</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pts</th>                         <td>   -0.9033</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>role_Combo G</th>                <td>    2.0136</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>role_PF/C</th>                   <td>    0.3074</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>role_Pure PG</th>                <td>    1.7997</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>role_Scoring PG</th>             <td>    1.9622</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>role_Stretch 4</th>              <td>    1.1610</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>role_Wing F</th>                 <td>    0.9416</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>role_Wing G</th>                 <td>    1.5323</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_month_Jul</th>                <td>    1.6541</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_month_Jun</th>                <td>   -2.1671</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_month_May</th>                <td>   -6.7640</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_1</th>                    <td>    0.7317</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_10</th>                   <td>    4.0454</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_11</th>                   <td>    4.2569</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_2</th>                    <td>    0.9443</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_3</th>                    <td>    1.8138</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_4</th>                    <td>    2.1692</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_5</th>                    <td>    2.2184</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_6</th>                    <td>    3.1480</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_7</th>                    <td>    3.1201</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_8</th>                    <td>    2.9078</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ht_day_9</th>                    <td>    3.5693</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Air Force</th>              <td>   -0.6446</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Akron</th>                  <td>   -2.5191</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Alabama</th>                <td>    1.9822</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Alabama A&M</th>            <td>   -0.2175</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Alabama St.</th>            <td>   -0.1764</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Albany</th>                 <td>   -0.8675</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Alcorn St.</th>             <td>   -0.1703</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_American</th>               <td>   -1.6898</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Appalachian St.</th>        <td>   -0.8321</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Arizona</th>                <td>    4.5428</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Arizona St.</th>            <td>    2.8673</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Arkansas</th>               <td>    2.2595</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Arkansas Little Rock</th>   <td>   -0.4775</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Arkansas Pine Bluff</th>    <td>   -0.4494</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Arkansas St.</th>           <td>   -0.5287</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Army</th>                   <td>   -0.8000</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Auburn</th>                 <td>    3.0370</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Austin Peay</th>            <td>   -2.0237</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_BYU</th>                    <td>   -0.0830</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Ball St.</th>               <td>   -1.0339</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Baylor</th>                 <td>    3.0729</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Bellarmine</th>             <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Belmont</th>                <td>    1.4941</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Bethune Cookman</th>        <td>   -0.3668</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Binghamton</th>             <td>   -0.5061</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Boise St.</th>              <td>    2.7880</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Boston College</th>         <td>    3.4847</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Boston University</th>      <td>   -2.0559</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Bowling Green</th>          <td>    4.3443</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Bradley</th>                <td>   -1.6675</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Brown</th>                  <td>   -0.6759</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Bryant</th>                 <td>   -0.5106</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Bucknell</th>               <td>   -4.3815</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Buffalo</th>                <td>   -3.8884</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Butler</th>                 <td>    3.0599</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Cal Baptist</th>            <td>   -0.3562</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Cal Poly</th>               <td>   -0.3470</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Cal St. Bakersfield</th>    <td>   -0.3897</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Cal St. Fullerton</th>      <td>   -0.8610</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Cal St. Northridge</th>     <td>   -4.9673</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_California</th>             <td>    4.1117</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Campbell</th>               <td>   -1.6650</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Canisius</th>               <td>   -1.7780</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Centenary</th>              <td>   -0.0188</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Central Arkansas</th>       <td>   -0.5279</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Central Connecticut</th>    <td>   -3.1637</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Central Michigan</th>       <td>   -0.8671</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Charleston Southern</th>    <td>   -0.6593</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Charlotte</th>              <td>   -1.0190</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Chattanooga</th>            <td>   -1.8445</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Chicago St.</th>            <td>   -0.1686</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Cincinnati</th>             <td>    1.4819</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Clemson</th>                <td>    2.2638</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Cleveland St.</th>          <td>    4.0736</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Coastal Carolina</th>       <td>   -1.1694</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Colgate</th>                <td>   -1.3008</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_College of Charleston</th>  <td>    4.0212</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Colorado</th>               <td>    4.1498</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Colorado St.</th>           <td>    3.3349</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Columbia</th>               <td>   -0.9980</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Connecticut</th>            <td>    3.0308</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Coppin St.</th>             <td>   -0.2473</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Cornell</th>                <td>   -2.2127</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Creighton</th>              <td>    2.6561</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Dartmouth</th>              <td>   -0.4341</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Davidson</th>               <td>   -4.7332</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Dayton</th>                 <td>    2.9324</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_DePaul</th>                 <td>   -1.5304</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Delaware</th>               <td>   -1.8520</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Delaware St.</th>           <td>   -0.6421</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Denver</th>                 <td>   -2.0404</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Detroit</th>                <td>    4.1260</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Dixie St.</th>              <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Drake</th>                  <td>   -0.8036</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Drexel</th>                 <td>   -1.9042</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Duke</th>                   <td>    3.3559</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Duquesne</th>               <td>   -4.5708</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_East Carolina</th>          <td>   -0.9645</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_East Tennessee St.</th>     <td>   -1.8583</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Eastern Illinois</th>       <td>   -0.2561</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Eastern Kentucky</th>       <td>   -3.0108</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Eastern Michigan</th>       <td>   -1.8767</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Eastern Washington</th>     <td>    4.2031</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Elon</th>                   <td>   -0.7282</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Evansville</th>             <td>   -4.7173</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_FIU</th>                    <td>   -0.9508</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Fairfield</th>              <td>   -2.0044</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Fairleigh Dickinson</th>    <td>   -0.3290</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Florida</th>                <td>    3.0144</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Florida A&M</th>            <td>   -0.4043</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Florida Atlantic</th>       <td>   -1.6036</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Florida Gulf Coast</th>     <td>   -1.4572</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Florida St.</th>            <td>    4.5830</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Fordham</th>                <td>   -1.1035</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Fort Wayne</th>             <td>   -1.7447</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Fresno St.</th>             <td>    2.9763</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Furman</th>                 <td>   -0.8244</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Gardner Webb</th>           <td>   -0.7284</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_George Mason</th>           <td>   -1.7119</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_George Washington</th>      <td>   -2.3131</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Georgetown</th>             <td>    0.8144</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Georgia</th>                <td>    2.1559</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Georgia Southern</th>       <td>   -1.3959</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Georgia St.</th>            <td>   -4.9266</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Georgia Tech</th>           <td>    3.3122</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Gonzaga</th>                <td>    2.5125</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Grambling St.</th>          <td>   -0.2497</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Grand Canyon</th>           <td>   -0.6573</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Green Bay</th>              <td>    3.6114</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Hampton</th>                <td>   -1.3445</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Hartford</th>               <td>   -0.7479</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Harvard</th>                <td>   -2.5650</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Hawaii</th>                 <td>   -1.9040</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_High Point</th>             <td>   -1.3860</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Hofstra</th>                <td>    3.0553</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Holy Cross</th>             <td>   -0.4916</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Houston</th>                <td>    2.4092</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Houston Baptist</th>        <td>   -0.5558</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Howard</th>                 <td>   -0.8456</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_IPFW</th>                   <td>   -0.8910</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_IUPUI</th>                  <td>   -1.9115</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Idaho</th>                  <td>   -0.7657</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Idaho St.</th>              <td>   -0.3545</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Illinois</th>               <td>    1.3916</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Illinois Chicago</th>       <td>   -1.5030</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Illinois St.</th>           <td>   -3.8705</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Incarnate Word</th>         <td>   -0.1890</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Indiana</th>                <td>    2.8259</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Indiana St.</th>            <td>   -0.7938</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Iona</th>                   <td>   -4.9339</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Iowa</th>                   <td>    0.6138</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Iowa St.</th>               <td>    3.1237</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Jackson St.</th>            <td>   -0.4806</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Jacksonville</th>           <td>   -0.7400</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Jacksonville St.</th>       <td>   -0.4733</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_James Madison</th>          <td>   -4.6688</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Kansas</th>                 <td>    3.1775</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Kansas St.</th>             <td>   -6.3273</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Kennesaw St.</th>           <td>   -0.3849</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Kent St.</th>               <td>   -1.5827</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Kentucky</th>               <td>    5.8335</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_LIU Brooklyn</th>           <td>   -1.2535</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_LSU</th>                    <td>    4.5069</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_La Salle</th>               <td>   -3.1954</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Lafayette</th>              <td>   -0.4847</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Lamar</th>                  <td>   -0.3427</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Lehigh</th>                 <td>   -6.3645</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Liberty</th>                <td>   -1.8599</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Lipscomb</th>               <td>   -1.9018</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Little Rock</th>            <td>   -0.8540</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Long Beach St.</th>         <td>   -1.2728</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Longwood</th>               <td>   -0.3367</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Louisiana Lafayette</th>    <td>   -3.6512</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Louisiana Monroe</th>       <td>   -1.5662</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Louisiana Tech</th>         <td>   -3.1011</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Louisville</th>             <td>    3.4235</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Loyola Chicago</th>         <td>   -1.8842</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Loyola MD</th>              <td>   -1.5555</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Loyola Marymount</th>       <td>   -1.2707</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Maine</th>                  <td>   -0.4314</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Manhattan</th>              <td>   -1.3019</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Marist</th>                 <td>   -0.4559</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Marquette</th>              <td>    3.6039</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Marshall</th>               <td>    1.5605</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Maryland</th>               <td>    4.3040</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Maryland Eastern Shore</th> <td>   -0.2184</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Massachusetts</th>          <td>    4.2171</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_McNeese St.</th>            <td>   -0.7157</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Memphis</th>                <td>    2.4741</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Mercer</th>                 <td>   -1.3611</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Merrimack</th>              <td>   -0.0344</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Miami FL</th>               <td>    4.4224</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Miami OH</th>               <td>   -0.6315</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Michigan</th>               <td>    3.2820</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Michigan St.</th>           <td>    2.4449</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Middle Tennessee</th>       <td>   -2.4854</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Milwaukee</th>              <td>   -0.5077</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Minnesota</th>              <td>    0.7601</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Mississippi</th>            <td>   -3.2639</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Mississippi St.</th>        <td>    3.4323</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Mississippi Valley St.</th> <td>   -0.2481</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Missouri</th>               <td>    4.3988</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Missouri St.</th>           <td>    4.5064</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Monmouth</th>               <td>   -0.6634</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Montana</th>                <td>   -2.3492</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Montana St.</th>            <td>   -0.4650</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Morehead St.</th>           <td>    1.6594</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Morgan St.</th>             <td>   -0.8181</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Mount St. Mary's</th>       <td>   -0.4949</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Murray St.</th>             <td>    3.6875</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_NJIT</th>                   <td>   -0.5952</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Navy</th>                   <td>   -0.4754</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Nebraska</th>               <td>    2.1036</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Nebraska Omaha</th>         <td>   -0.3974</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Nevada</th>                 <td>    2.7194</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_New Hampshire</th>          <td>   -0.5279</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_New Mexico</th>             <td>    2.9661</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_New Mexico St.</th>         <td>    1.5328</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_New Orleans</th>            <td>   -0.3360</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Niagara</th>                <td>   -1.1409</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Nicholls St.</th>           <td>   -0.5442</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Norfolk St.</th>            <td>    3.9780</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_North Alabama</th>          <td>   -0.0268</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_North Carolina</th>         <td>    3.4490</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_North Carolina A&T</th>     <td>   -0.9066</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_North Carolina Central</th> <td>   -0.8736</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_North Carolina St.</th>     <td>    2.0196</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_North Dakota</th>           <td>   -0.9689</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_North Dakota St.</th>       <td>   -2.3104</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_North Florida</th>          <td>   -0.7136</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_North Texas</th>            <td>    4.8309</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Northeastern</th>           <td>   -3.1168</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Northern Arizona</th>       <td>   -0.3447</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Northern Colorado</th>      <td>   -2.9040</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Northern Illinois</th>      <td>   -0.7512</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Northern Iowa</th>          <td>   -2.7208</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Northern Kentucky</th>      <td>   -1.3150</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Northwestern</th>           <td>   -5.6405</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Northwestern St.</th>       <td>   -1.3253</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Notre Dame</th>             <td>    2.9522</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Oakland</th>                <td>    2.3677</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Ohio</th>                   <td>   -3.0371</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Ohio St.</th>               <td>    2.3078</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Oklahoma</th>               <td>    3.9814</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Oklahoma St.</th>           <td>    3.8176</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Old Dominion</th>           <td>   -3.0648</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Oral Roberts</th>           <td>   -1.6029</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Oregon</th>                 <td>    3.5682</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Oregon St.</th>             <td>    1.6525</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Pacific</th>                <td>   -0.6034</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Penn</th>                   <td>   -1.9611</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Penn St.</th>               <td>    0.8473</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Pepperdine</th>             <td>   -2.0229</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Pittsburgh</th>             <td>    2.9666</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Portland</th>               <td>   -0.7020</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Portland St.</th>           <td>   -0.3765</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Prairie View A&M</th>       <td>   -0.3011</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Presbyterian</th>           <td>   -0.4899</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Princeton</th>              <td>   -2.3369</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Providence</th>             <td>    2.1611</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Purdue</th>                 <td>    2.2307</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Quinnipiac</th>             <td>   -1.0506</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Radford</th>                <td>   -2.6162</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Rhode Island</th>           <td>   -2.5776</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Rice</th>                   <td>   -1.6574</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Richmond</th>               <td>    2.0528</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Rider</th>                  <td>   -0.7746</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Robert Morris</th>          <td>   -1.3765</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Rutgers</th>                <td>    3.9639</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_SIU Edwardsville</th>       <td>   -0.2538</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_SMU</th>                    <td>    2.4351</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Sacramento St.</th>         <td>   -0.4662</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Sacred Heart</th>           <td>   -0.5615</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Saint Joseph's</th>         <td>    1.9778</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Saint Louis</th>            <td>   -3.5671</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Saint Mary's</th>           <td>   -6.7987</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Saint Peter's</th>          <td>   -0.6416</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Sam Houston St.</th>        <td>   -0.4798</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Samford</th>                <td>   -0.4311</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_San Diego</th>              <td>   -2.2121</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_San Diego St.</th>          <td>    4.0329</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_San Francisco</th>          <td>   -1.3929</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_San Jose St.</th>           <td>   -1.9442</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Santa Clara</th>            <td>   -2.3898</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Savannah St.</th>           <td>   -0.3043</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Seattle</th>                <td>   -0.9197</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Seton Hall</th>             <td>    1.2768</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Siena</th>                  <td>   -1.7737</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_South Alabama</th>          <td>   -0.8885</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_South Carolina</th>         <td>    2.2311</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_South Carolina St.</th>     <td>   -0.1495</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_South Dakota</th>           <td>   -1.6490</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_South Dakota St.</th>       <td>    2.2624</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_South Florida</th>          <td>   -1.6755</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Southeast Missouri St.</th> <td>   -0.5439</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Southeastern Louisiana</th> <td>   -1.0275</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Southern</th>               <td>   -1.1942</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Southern Illinois</th>      <td>   -0.9616</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Southern Miss</th>          <td>   -2.3130</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Southern Utah</th>          <td>   -0.3012</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_St. Bonaventure</th>        <td>    2.5636</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_St. Francis NY</th>         <td>   -0.4440</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_St. Francis PA</th>         <td>   -0.6320</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_St. John's</th>             <td>    2.2013</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Stanford</th>               <td>    4.5773</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Stephen F. Austin</th>      <td>   -4.8989</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Stetson</th>                <td>   -0.3672</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Stony Brook</th>            <td>   -4.0936</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Syracuse</th>               <td>    3.4620</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_TCU</th>                    <td>    2.0216</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Tarleton St.</th>           <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Temple</th>                 <td>    2.4501</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Tennessee</th>              <td>    4.2137</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Tennessee Martin</th>       <td>   -0.2952</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Tennessee St.</th>          <td>   -0.9391</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Tennessee Tech</th>         <td>   -0.4358</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Texas</th>                  <td>    4.1334</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Texas A&M</th>              <td>   -5.3300</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Texas A&M Corpus Chris</th> <td>   -2.8188</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Texas Southern</th>         <td>   -2.3490</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Texas St.</th>              <td>   -1.3019</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Texas Tech</th>             <td>    3.6328</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_The Citadel</th>            <td>   -0.2421</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Toledo</th>                 <td>   -2.1299</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Towson</th>                 <td>   -1.0201</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Troy</th>                   <td>   -0.5486</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Tulane</th>                 <td>   -1.2180</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Tulsa</th>                  <td>    2.7450</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UAB</th>                    <td>   -3.5571</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UC Davis</th>               <td>   -2.0572</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UC Irvine</th>              <td>   -5.8041</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UC Riverside</th>           <td>   -0.4628</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UC San Diego</th>           <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UC Santa Barbara</th>       <td>    2.4961</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UCF</th>                    <td>   -9.7422</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UCLA</th>                   <td>    4.3008</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UMBC</th>                   <td>   -0.6975</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UMKC</th>                   <td>   -0.3872</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UMass Lowell</th>           <td>   -0.2582</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UNC Asheville</th>          <td>   -1.1013</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UNC Greensboro</th>         <td>   -1.5339</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UNC Wilmington</th>         <td>   -0.9676</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UNLV</th>                   <td>    0.5744</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_USC</th>                    <td>    2.8529</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_USC Upstate</th>            <td>   -1.4095</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UT Arlington</th>           <td>    3.6709</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UT Rio Grande Valley</th>   <td>   -0.4003</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UTEP</th>                   <td>    3.5101</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_UTSA</th>                   <td>   -0.7450</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Utah</th>                   <td>    3.1768</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Utah St.</th>               <td>    2.7896</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Utah Valley</th>            <td>   -0.7691</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_VCU</th>                    <td>    2.2337</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_VMI</th>                    <td>   -0.9119</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Valparaiso</th>             <td>    1.8765</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Vanderbilt</th>             <td>    4.2071</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Vermont</th>                <td>   -6.2479</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Villanova</th>              <td>    2.8918</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Virginia</th>               <td>    3.7716</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Virginia Tech</th>          <td>    2.4768</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Wagner</th>                 <td>   -0.5700</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Wake Forest</th>            <td>    2.6031</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Washington</th>             <td>    4.3090</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Washington St.</th>         <td>    0.6532</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Weber St.</th>              <td>    3.5561</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_West Virginia</th>          <td>    2.7738</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Western Carolina</th>       <td>   -0.5709</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Western Illinois</th>       <td>   -1.2674</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Western Kentucky</th>       <td>    2.5592</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Western Michigan</th>       <td>   -2.1992</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Wichita St.</th>            <td>    3.1715</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_William & Mary</th>         <td>    3.4010</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Winston Salem St.</th>      <td>   -0.0255</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Winthrop</th>               <td>   -1.5291</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Wisconsin</th>              <td>    0.0422</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Wofford</th>                <td>   -1.9523</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Wright St.</th>             <td>   -1.5615</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Wyoming</th>                <td>    2.7601</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Xavier</th>                 <td>    3.0310</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Yale</th>                   <td>    2.8697</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team_Youngstown St.</th>         <td>   -1.3588</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.0/1.0</th>                     <td>   11.8852</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                & first\\_round\\_drafted & \\textbf{  Log-Likelihood:    } &   -685.49   \\\\\n",
       "\\textbf{Model:}                        &      OrderedModel     & \\textbf{  AIC:               } &     2247.   \\\\\n",
       "\\textbf{Method:}                       &   Maximum Likelihood  & \\textbf{  BIC:               } &     6010.   \\\\\n",
       "\\textbf{Date:}                         &    Tue, 14 Nov 2023   & \\textbf{                     } &             \\\\\n",
       "\\textbf{Time:}                         &        20:56:07       & \\textbf{                     } &             \\\\\n",
       "\\textbf{No. Observations:}             &          39824        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Df Residuals:}                 &          39386        & \\textbf{                     } &             \\\\\n",
       "\\textbf{Df Model:}                     &            437        & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                       & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{GP}                            &       4.6420  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{Min\\_per}                      &      -2.1438  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{Ortg}                          &      -2.3653  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{usg}                           &       5.7988  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{eFG}                           &      -3.3507  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{TS\\_per}                       &      -3.9790  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ORB\\_per}                      &      -1.0846  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{DRB\\_per}                      &      -1.1190  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{AST\\_per}                      &     -16.7016  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{TO\\_per}                       &       9.6715  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{FTM}                           &      -5.5817  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{FTA}                           &       4.5557  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{FT\\_per}                       &       1.6140  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{twoPM}                         &       0.6514  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{twoPA}                         &      -0.3448  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{twoP\\_per}                     &      -4.3279  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{TPM}                           &       9.8135  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{TPA}                           &      -5.6538  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{TP\\_per}                       &      -0.9567  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{blk\\_per}                      &      -1.2475  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{stl\\_per}                      &      -1.9993  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ftr}                           &       0.5964  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{yr}                            &      -1.3372  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{num}                           &      -1.1840  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{porpag}                        &      20.3214  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{adjoe}                         &       1.7309  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{pfr}                           &      -2.3797  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{pid}                           &      -0.4384  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ast/tov}                       &      -2.3596  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{rimmade}                       &       2.4792  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{rimmade+rimmiss}               &      -1.3704  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{midmade}                       &      -0.0410  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{midmade+midmiss}               &       1.2930  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{rimmade/(rimmade+rimmiss)}     &       2.9569  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{midmade/(midmade+midmiss)}     &       2.5957  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{dunksmade}                     &      -0.2887  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{dunksmiss+dunksmade}           &       4.5466  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{drtg}                          &      -6.3299  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{adrtg}                         &      -7.3482  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{dporpag}                       &       7.6611  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{stops}                         &      -8.2015  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{bpm}                           &      -1.0401  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{obpm}                          &      -0.0729  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{dbpm}                          &      -2.3034  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{gbpm}                          &      -1.4030  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{mp}                            &      -4.1627  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ogbpm}                         &       0.4580  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{dgbpm}                         &      -3.9976  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{oreb}                          &      -1.3439  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{dreb}                          &       3.6782  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{treb}                          &       2.3989  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ast}                           &      13.0460  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{stl}                           &       3.9959  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{blk}                           &       5.6171  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{pts}                           &      -0.9033  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{role\\_Combo G}                 &       2.0136  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{role\\_PF/C}                    &       0.3074  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{role\\_Pure PG}                 &       1.7997  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{role\\_Scoring PG}              &       1.9622  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{role\\_Stretch 4}               &       1.1610  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{role\\_Wing F}                  &       0.9416  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{role\\_Wing G}                  &       1.5323  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_month\\_Jul}                &       1.6541  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_month\\_Jun}                &      -2.1671  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_month\\_May}                &      -6.7640  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_1}                    &       0.7317  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_10}                   &       4.0454  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_11}                   &       4.2569  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_2}                    &       0.9443  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_3}                    &       1.8138  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_4}                    &       2.1692  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_5}                    &       2.2184  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_6}                    &       3.1480  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_7}                    &       3.1201  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_8}                    &       2.9078  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{ht\\_day\\_9}                    &       3.5693  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Air Force}               &      -0.6446  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Akron}                   &      -2.5191  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Alabama}                 &       1.9822  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Alabama A\\&M}            &      -0.2175  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Alabama St.}             &      -0.1764  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Albany}                  &      -0.8675  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Alcorn St.}              &      -0.1703  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_American}                &      -1.6898  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Appalachian St.}         &      -0.8321  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Arizona}                 &       4.5428  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Arizona St.}             &       2.8673  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Arkansas}                &       2.2595  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Arkansas Little Rock}    &      -0.4775  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Arkansas Pine Bluff}     &      -0.4494  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Arkansas St.}            &      -0.5287  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Army}                    &      -0.8000  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Auburn}                  &       3.0370  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Austin Peay}             &      -2.0237  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_BYU}                     &      -0.0830  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Ball St.}                &      -1.0339  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Baylor}                  &       3.0729  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Bellarmine}              &            0  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Belmont}                 &       1.4941  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Bethune Cookman}         &      -0.3668  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Binghamton}              &      -0.5061  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Boise St.}               &       2.7880  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Boston College}          &       3.4847  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Boston University}       &      -2.0559  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Bowling Green}           &       4.3443  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Bradley}                 &      -1.6675  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Brown}                   &      -0.6759  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Bryant}                  &      -0.5106  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Bucknell}                &      -4.3815  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Buffalo}                 &      -3.8884  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Butler}                  &       3.0599  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Cal Baptist}             &      -0.3562  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Cal Poly}                &      -0.3470  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Cal St. Bakersfield}     &      -0.3897  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Cal St. Fullerton}       &      -0.8610  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Cal St. Northridge}      &      -4.9673  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_California}              &       4.1117  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Campbell}                &      -1.6650  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Canisius}                &      -1.7780  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Centenary}               &      -0.0188  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Central Arkansas}        &      -0.5279  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Central Connecticut}     &      -3.1637  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Central Michigan}        &      -0.8671  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Charleston Southern}     &      -0.6593  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Charlotte}               &      -1.0190  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Chattanooga}             &      -1.8445  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Chicago St.}             &      -0.1686  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Cincinnati}              &       1.4819  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Clemson}                 &       2.2638  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Cleveland St.}           &       4.0736  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Coastal Carolina}        &      -1.1694  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Colgate}                 &      -1.3008  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_College of Charleston}   &       4.0212  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Colorado}                &       4.1498  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Colorado St.}            &       3.3349  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Columbia}                &      -0.9980  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Connecticut}             &       3.0308  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Coppin St.}              &      -0.2473  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Cornell}                 &      -2.2127  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Creighton}               &       2.6561  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Dartmouth}               &      -0.4341  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Davidson}                &      -4.7332  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Dayton}                  &       2.9324  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_DePaul}                  &      -1.5304  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Delaware}                &      -1.8520  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Delaware St.}            &      -0.6421  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Denver}                  &      -2.0404  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Detroit}                 &       4.1260  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Dixie St.}               &            0  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Drake}                   &      -0.8036  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Drexel}                  &      -1.9042  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Duke}                    &       3.3559  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Duquesne}                &      -4.5708  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_East Carolina}           &      -0.9645  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_East Tennessee St.}      &      -1.8583  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Eastern Illinois}        &      -0.2561  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Eastern Kentucky}        &      -3.0108  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Eastern Michigan}        &      -1.8767  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Eastern Washington}      &       4.2031  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Elon}                    &      -0.7282  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Evansville}              &      -4.7173  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_FIU}                     &      -0.9508  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Fairfield}               &      -2.0044  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Fairleigh Dickinson}     &      -0.3290  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Florida}                 &       3.0144  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Florida A\\&M}            &      -0.4043  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Florida Atlantic}        &      -1.6036  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Florida Gulf Coast}      &      -1.4572  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Florida St.}             &       4.5830  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Fordham}                 &      -1.1035  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Fort Wayne}              &      -1.7447  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Fresno St.}              &       2.9763  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Furman}                  &      -0.8244  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Gardner Webb}            &      -0.7284  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_George Mason}            &      -1.7119  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_George Washington}       &      -2.3131  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Georgetown}              &       0.8144  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Georgia}                 &       2.1559  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Georgia Southern}        &      -1.3959  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Georgia St.}             &      -4.9266  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Georgia Tech}            &       3.3122  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Gonzaga}                 &       2.5125  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Grambling St.}           &      -0.2497  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Grand Canyon}            &      -0.6573  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Green Bay}               &       3.6114  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Hampton}                 &      -1.3445  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Hartford}                &      -0.7479  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Harvard}                 &      -2.5650  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Hawaii}                  &      -1.9040  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_High Point}              &      -1.3860  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Hofstra}                 &       3.0553  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Holy Cross}              &      -0.4916  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Houston}                 &       2.4092  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Houston Baptist}         &      -0.5558  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Howard}                  &      -0.8456  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_IPFW}                    &      -0.8910  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_IUPUI}                   &      -1.9115  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Idaho}                   &      -0.7657  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Idaho St.}               &      -0.3545  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Illinois}                &       1.3916  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Illinois Chicago}        &      -1.5030  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Illinois St.}            &      -3.8705  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Incarnate Word}          &      -0.1890  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Indiana}                 &       2.8259  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Indiana St.}             &      -0.7938  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Iona}                    &      -4.9339  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Iowa}                    &       0.6138  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Iowa St.}                &       3.1237  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Jackson St.}             &      -0.4806  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Jacksonville}            &      -0.7400  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Jacksonville St.}        &      -0.4733  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_James Madison}           &      -4.6688  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Kansas}                  &       3.1775  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Kansas St.}              &      -6.3273  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Kennesaw St.}            &      -0.3849  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Kent St.}                &      -1.5827  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Kentucky}                &       5.8335  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_LIU Brooklyn}            &      -1.2535  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_LSU}                     &       4.5069  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_La Salle}                &      -3.1954  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Lafayette}               &      -0.4847  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Lamar}                   &      -0.3427  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Lehigh}                  &      -6.3645  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Liberty}                 &      -1.8599  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Lipscomb}                &      -1.9018  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Little Rock}             &      -0.8540  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Long Beach St.}          &      -1.2728  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Longwood}                &      -0.3367  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Louisiana Lafayette}     &      -3.6512  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Louisiana Monroe}        &      -1.5662  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Louisiana Tech}          &      -3.1011  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Louisville}              &       3.4235  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Loyola Chicago}          &      -1.8842  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Loyola MD}               &      -1.5555  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Loyola Marymount}        &      -1.2707  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Maine}                   &      -0.4314  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Manhattan}               &      -1.3019  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Marist}                  &      -0.4559  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Marquette}               &       3.6039  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Marshall}                &       1.5605  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Maryland}                &       4.3040  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Maryland Eastern Shore}  &      -0.2184  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Massachusetts}           &       4.2171  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_McNeese St.}             &      -0.7157  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Memphis}                 &       2.4741  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Mercer}                  &      -1.3611  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Merrimack}               &      -0.0344  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Miami FL}                &       4.4224  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Miami OH}                &      -0.6315  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Michigan}                &       3.2820  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Michigan St.}            &       2.4449  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Middle Tennessee}        &      -2.4854  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Milwaukee}               &      -0.5077  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Minnesota}               &       0.7601  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Mississippi}             &      -3.2639  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Mississippi St.}         &       3.4323  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Mississippi Valley St.}  &      -0.2481  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Missouri}                &       4.3988  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Missouri St.}            &       4.5064  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Monmouth}                &      -0.6634  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Montana}                 &      -2.3492  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Montana St.}             &      -0.4650  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Morehead St.}            &       1.6594  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Morgan St.}              &      -0.8181  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Mount St. Mary's}        &      -0.4949  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Murray St.}              &       3.6875  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_NJIT}                    &      -0.5952  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Navy}                    &      -0.4754  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Nebraska}                &       2.1036  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Nebraska Omaha}          &      -0.3974  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Nevada}                  &       2.7194  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_New Hampshire}           &      -0.5279  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_New Mexico}              &       2.9661  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_New Mexico St.}          &       1.5328  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_New Orleans}             &      -0.3360  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Niagara}                 &      -1.1409  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Nicholls St.}            &      -0.5442  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Norfolk St.}             &       3.9780  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_North Alabama}           &      -0.0268  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_North Carolina}          &       3.4490  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_North Carolina A\\&T}     &      -0.9066  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_North Carolina Central}  &      -0.8736  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_North Carolina St.}      &       2.0196  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_North Dakota}            &      -0.9689  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_North Dakota St.}        &      -2.3104  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_North Florida}           &      -0.7136  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_North Texas}             &       4.8309  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Northeastern}            &      -3.1168  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Northern Arizona}        &      -0.3447  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Northern Colorado}       &      -2.9040  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Northern Illinois}       &      -0.7512  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Northern Iowa}           &      -2.7208  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Northern Kentucky}       &      -1.3150  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Northwestern}            &      -5.6405  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Northwestern St.}        &      -1.3253  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Notre Dame}              &       2.9522  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Oakland}                 &       2.3677  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Ohio}                    &      -3.0371  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Ohio St.}                &       2.3078  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Oklahoma}                &       3.9814  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Oklahoma St.}            &       3.8176  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Old Dominion}            &      -3.0648  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Oral Roberts}            &      -1.6029  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Oregon}                  &       3.5682  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Oregon St.}              &       1.6525  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Pacific}                 &      -0.6034  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Penn}                    &      -1.9611  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Penn St.}                &       0.8473  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Pepperdine}              &      -2.0229  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Pittsburgh}              &       2.9666  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Portland}                &      -0.7020  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Portland St.}            &      -0.3765  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Prairie View A\\&M}       &      -0.3011  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Presbyterian}            &      -0.4899  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Princeton}               &      -2.3369  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Providence}              &       2.1611  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Purdue}                  &       2.2307  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Quinnipiac}              &      -1.0506  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Radford}                 &      -2.6162  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Rhode Island}            &      -2.5776  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Rice}                    &      -1.6574  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Richmond}                &       2.0528  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Rider}                   &      -0.7746  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Robert Morris}           &      -1.3765  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Rutgers}                 &       3.9639  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_SIU Edwardsville}        &      -0.2538  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_SMU}                     &       2.4351  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Sacramento St.}          &      -0.4662  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Sacred Heart}            &      -0.5615  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Saint Joseph's}          &       1.9778  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Saint Louis}             &      -3.5671  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Saint Mary's}            &      -6.7987  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Saint Peter's}           &      -0.6416  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Sam Houston St.}         &      -0.4798  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Samford}                 &      -0.4311  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_San Diego}               &      -2.2121  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_San Diego St.}           &       4.0329  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_San Francisco}           &      -1.3929  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_San Jose St.}            &      -1.9442  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Santa Clara}             &      -2.3898  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Savannah St.}            &      -0.3043  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Seattle}                 &      -0.9197  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Seton Hall}              &       1.2768  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Siena}                   &      -1.7737  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_South Alabama}           &      -0.8885  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_South Carolina}          &       2.2311  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_South Carolina St.}      &      -0.1495  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_South Dakota}            &      -1.6490  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_South Dakota St.}        &       2.2624  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_South Florida}           &      -1.6755  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Southeast Missouri St.}  &      -0.5439  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Southeastern Louisiana}  &      -1.0275  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Southern}                &      -1.1942  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Southern Illinois}       &      -0.9616  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Southern Miss}           &      -2.3130  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Southern Utah}           &      -0.3012  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_St. Bonaventure}         &       2.5636  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_St. Francis NY}          &      -0.4440  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_St. Francis PA}          &      -0.6320  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_St. John's}              &       2.2013  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Stanford}                &       4.5773  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Stephen F. Austin}       &      -4.8989  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Stetson}                 &      -0.3672  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Stony Brook}             &      -4.0936  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Syracuse}                &       3.4620  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_TCU}                     &       2.0216  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Tarleton St.}            &            0  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Temple}                  &       2.4501  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Tennessee}               &       4.2137  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Tennessee Martin}        &      -0.2952  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Tennessee St.}           &      -0.9391  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Tennessee Tech}          &      -0.4358  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Texas}                   &       4.1334  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Texas A\\&M}              &      -5.3300  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Texas A\\&M Corpus Chris} &      -2.8188  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Texas Southern}          &      -2.3490  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Texas St.}               &      -1.3019  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Texas Tech}              &       3.6328  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_The Citadel}             &      -0.2421  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Toledo}                  &      -2.1299  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Towson}                  &      -1.0201  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Troy}                    &      -0.5486  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Tulane}                  &      -1.2180  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Tulsa}                   &       2.7450  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UAB}                     &      -3.5571  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UC Davis}                &      -2.0572  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UC Irvine}               &      -5.8041  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UC Riverside}            &      -0.4628  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UC San Diego}            &            0  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UC Santa Barbara}        &       2.4961  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UCF}                     &      -9.7422  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UCLA}                    &       4.3008  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UMBC}                    &      -0.6975  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UMKC}                    &      -0.3872  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UMass Lowell}            &      -0.2582  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UNC Asheville}           &      -1.1013  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UNC Greensboro}          &      -1.5339  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UNC Wilmington}          &      -0.9676  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UNLV}                    &       0.5744  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_USC}                     &       2.8529  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_USC Upstate}             &      -1.4095  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UT Arlington}            &       3.6709  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UT Rio Grande Valley}    &      -0.4003  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UTEP}                    &       3.5101  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_UTSA}                    &      -0.7450  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Utah}                    &       3.1768  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Utah St.}                &       2.7896  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Utah Valley}             &      -0.7691  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_VCU}                     &       2.2337  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_VMI}                     &      -0.9119  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Valparaiso}              &       1.8765  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Vanderbilt}              &       4.2071  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Vermont}                 &      -6.2479  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Villanova}               &       2.8918  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Virginia}                &       3.7716  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Virginia Tech}           &       2.4768  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Wagner}                  &      -0.5700  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Wake Forest}             &       2.6031  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Washington}              &       4.3090  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Washington St.}          &       0.6532  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Weber St.}               &       3.5561  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_West Virginia}           &       2.7738  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Western Carolina}        &      -0.5709  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Western Illinois}        &      -1.2674  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Western Kentucky}        &       2.5592  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Western Michigan}        &      -2.1992  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Wichita St.}             &       3.1715  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_William \\& Mary}         &       3.4010  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Winston Salem St.}       &      -0.0255  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Winthrop}                &      -1.5291  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Wisconsin}               &       0.0422  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Wofford}                 &      -1.9523  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Wright St.}              &      -1.5615  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Wyoming}                 &       2.7601  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Xavier}                  &       3.0310  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Yale}                    &       2.8697  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{team\\_Youngstown St.}          &      -1.3588  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{0.0/1.0}                       &      11.8852  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OrderedModel Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              OrderedModel Results                             \n",
       "===============================================================================\n",
       "Dep. Variable:     first_round_drafted   Log-Likelihood:                -685.49\n",
       "Model:                    OrderedModel   AIC:                             2247.\n",
       "Method:             Maximum Likelihood   BIC:                             6010.\n",
       "Date:                 Tue, 14 Nov 2023                                         \n",
       "Time:                         20:56:07                                         \n",
       "No. Observations:                39824                                         \n",
       "Df Residuals:                    39386                                         \n",
       "Df Model:                          437                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "GP                              4.6420        nan        nan        nan         nan         nan\n",
       "Min_per                        -2.1438        nan        nan        nan         nan         nan\n",
       "Ortg                           -2.3653        nan        nan        nan         nan         nan\n",
       "usg                             5.7988        nan        nan        nan         nan         nan\n",
       "eFG                            -3.3507        nan        nan        nan         nan         nan\n",
       "TS_per                         -3.9790        nan        nan        nan         nan         nan\n",
       "ORB_per                        -1.0846        nan        nan        nan         nan         nan\n",
       "DRB_per                        -1.1190        nan        nan        nan         nan         nan\n",
       "AST_per                       -16.7016        nan        nan        nan         nan         nan\n",
       "TO_per                          9.6715        nan        nan        nan         nan         nan\n",
       "FTM                            -5.5817        nan        nan        nan         nan         nan\n",
       "FTA                             4.5557        nan        nan        nan         nan         nan\n",
       "FT_per                          1.6140        nan        nan        nan         nan         nan\n",
       "twoPM                           0.6514        nan        nan        nan         nan         nan\n",
       "twoPA                          -0.3448        nan        nan        nan         nan         nan\n",
       "twoP_per                       -4.3279        nan        nan        nan         nan         nan\n",
       "TPM                             9.8135        nan        nan        nan         nan         nan\n",
       "TPA                            -5.6538        nan        nan        nan         nan         nan\n",
       "TP_per                         -0.9567        nan        nan        nan         nan         nan\n",
       "blk_per                        -1.2475        nan        nan        nan         nan         nan\n",
       "stl_per                        -1.9993        nan        nan        nan         nan         nan\n",
       "ftr                             0.5964        nan        nan        nan         nan         nan\n",
       "yr                             -1.3372        nan        nan        nan         nan         nan\n",
       "num                            -1.1840        nan        nan        nan         nan         nan\n",
       "porpag                         20.3214        nan        nan        nan         nan         nan\n",
       "adjoe                           1.7309        nan        nan        nan         nan         nan\n",
       "pfr                            -2.3797        nan        nan        nan         nan         nan\n",
       "pid                            -0.4384        nan        nan        nan         nan         nan\n",
       "ast/tov                        -2.3596        nan        nan        nan         nan         nan\n",
       "rimmade                         2.4792        nan        nan        nan         nan         nan\n",
       "rimmade+rimmiss                -1.3704        nan        nan        nan         nan         nan\n",
       "midmade                        -0.0410        nan        nan        nan         nan         nan\n",
       "midmade+midmiss                 1.2930        nan        nan        nan         nan         nan\n",
       "rimmade/(rimmade+rimmiss)       2.9569        nan        nan        nan         nan         nan\n",
       "midmade/(midmade+midmiss)       2.5957        nan        nan        nan         nan         nan\n",
       "dunksmade                      -0.2887        nan        nan        nan         nan         nan\n",
       "dunksmiss+dunksmade             4.5466        nan        nan        nan         nan         nan\n",
       "drtg                           -6.3299        nan        nan        nan         nan         nan\n",
       "adrtg                          -7.3482        nan        nan        nan         nan         nan\n",
       "dporpag                         7.6611        nan        nan        nan         nan         nan\n",
       "stops                          -8.2015        nan        nan        nan         nan         nan\n",
       "bpm                            -1.0401        nan        nan        nan         nan         nan\n",
       "obpm                           -0.0729        nan        nan        nan         nan         nan\n",
       "dbpm                           -2.3034        nan        nan        nan         nan         nan\n",
       "gbpm                           -1.4030        nan        nan        nan         nan         nan\n",
       "mp                             -4.1627        nan        nan        nan         nan         nan\n",
       "ogbpm                           0.4580        nan        nan        nan         nan         nan\n",
       "dgbpm                          -3.9976        nan        nan        nan         nan         nan\n",
       "oreb                           -1.3439        nan        nan        nan         nan         nan\n",
       "dreb                            3.6782        nan        nan        nan         nan         nan\n",
       "treb                            2.3989        nan        nan        nan         nan         nan\n",
       "ast                            13.0460        nan        nan        nan         nan         nan\n",
       "stl                             3.9959        nan        nan        nan         nan         nan\n",
       "blk                             5.6171        nan        nan        nan         nan         nan\n",
       "pts                            -0.9033        nan        nan        nan         nan         nan\n",
       "role_Combo G                    2.0136        nan        nan        nan         nan         nan\n",
       "role_PF/C                       0.3074        nan        nan        nan         nan         nan\n",
       "role_Pure PG                    1.7997        nan        nan        nan         nan         nan\n",
       "role_Scoring PG                 1.9622        nan        nan        nan         nan         nan\n",
       "role_Stretch 4                  1.1610        nan        nan        nan         nan         nan\n",
       "role_Wing F                     0.9416        nan        nan        nan         nan         nan\n",
       "role_Wing G                     1.5323        nan        nan        nan         nan         nan\n",
       "ht_month_Jul                    1.6541        nan        nan        nan         nan         nan\n",
       "ht_month_Jun                   -2.1671        nan        nan        nan         nan         nan\n",
       "ht_month_May                   -6.7640        nan        nan        nan         nan         nan\n",
       "ht_day_1                        0.7317        nan        nan        nan         nan         nan\n",
       "ht_day_10                       4.0454        nan        nan        nan         nan         nan\n",
       "ht_day_11                       4.2569        nan        nan        nan         nan         nan\n",
       "ht_day_2                        0.9443        nan        nan        nan         nan         nan\n",
       "ht_day_3                        1.8138        nan        nan        nan         nan         nan\n",
       "ht_day_4                        2.1692        nan        nan        nan         nan         nan\n",
       "ht_day_5                        2.2184        nan        nan        nan         nan         nan\n",
       "ht_day_6                        3.1480        nan        nan        nan         nan         nan\n",
       "ht_day_7                        3.1201        nan        nan        nan         nan         nan\n",
       "ht_day_8                        2.9078        nan        nan        nan         nan         nan\n",
       "ht_day_9                        3.5693        nan        nan        nan         nan         nan\n",
       "team_Air Force                 -0.6446        nan        nan        nan         nan         nan\n",
       "team_Akron                     -2.5191        nan        nan        nan         nan         nan\n",
       "team_Alabama                    1.9822        nan        nan        nan         nan         nan\n",
       "team_Alabama A&M               -0.2175        nan        nan        nan         nan         nan\n",
       "team_Alabama St.               -0.1764        nan        nan        nan         nan         nan\n",
       "team_Albany                    -0.8675        nan        nan        nan         nan         nan\n",
       "team_Alcorn St.                -0.1703        nan        nan        nan         nan         nan\n",
       "team_American                  -1.6898        nan        nan        nan         nan         nan\n",
       "team_Appalachian St.           -0.8321        nan        nan        nan         nan         nan\n",
       "team_Arizona                    4.5428        nan        nan        nan         nan         nan\n",
       "team_Arizona St.                2.8673        nan        nan        nan         nan         nan\n",
       "team_Arkansas                   2.2595        nan        nan        nan         nan         nan\n",
       "team_Arkansas Little Rock      -0.4775        nan        nan        nan         nan         nan\n",
       "team_Arkansas Pine Bluff       -0.4494        nan        nan        nan         nan         nan\n",
       "team_Arkansas St.              -0.5287        nan        nan        nan         nan         nan\n",
       "team_Army                      -0.8000        nan        nan        nan         nan         nan\n",
       "team_Auburn                     3.0370        nan        nan        nan         nan         nan\n",
       "team_Austin Peay               -2.0237        nan        nan        nan         nan         nan\n",
       "team_BYU                       -0.0830        nan        nan        nan         nan         nan\n",
       "team_Ball St.                  -1.0339        nan        nan        nan         nan         nan\n",
       "team_Baylor                     3.0729        nan        nan        nan         nan         nan\n",
       "team_Bellarmine                      0        nan        nan        nan         nan         nan\n",
       "team_Belmont                    1.4941        nan        nan        nan         nan         nan\n",
       "team_Bethune Cookman           -0.3668        nan        nan        nan         nan         nan\n",
       "team_Binghamton                -0.5061        nan        nan        nan         nan         nan\n",
       "team_Boise St.                  2.7880        nan        nan        nan         nan         nan\n",
       "team_Boston College             3.4847        nan        nan        nan         nan         nan\n",
       "team_Boston University         -2.0559        nan        nan        nan         nan         nan\n",
       "team_Bowling Green              4.3443        nan        nan        nan         nan         nan\n",
       "team_Bradley                   -1.6675        nan        nan        nan         nan         nan\n",
       "team_Brown                     -0.6759        nan        nan        nan         nan         nan\n",
       "team_Bryant                    -0.5106        nan        nan        nan         nan         nan\n",
       "team_Bucknell                  -4.3815        nan        nan        nan         nan         nan\n",
       "team_Buffalo                   -3.8884        nan        nan        nan         nan         nan\n",
       "team_Butler                     3.0599        nan        nan        nan         nan         nan\n",
       "team_Cal Baptist               -0.3562        nan        nan        nan         nan         nan\n",
       "team_Cal Poly                  -0.3470        nan        nan        nan         nan         nan\n",
       "team_Cal St. Bakersfield       -0.3897        nan        nan        nan         nan         nan\n",
       "team_Cal St. Fullerton         -0.8610        nan        nan        nan         nan         nan\n",
       "team_Cal St. Northridge        -4.9673        nan        nan        nan         nan         nan\n",
       "team_California                 4.1117        nan        nan        nan         nan         nan\n",
       "team_Campbell                  -1.6650        nan        nan        nan         nan         nan\n",
       "team_Canisius                  -1.7780        nan        nan        nan         nan         nan\n",
       "team_Centenary                 -0.0188        nan        nan        nan         nan         nan\n",
       "team_Central Arkansas          -0.5279        nan        nan        nan         nan         nan\n",
       "team_Central Connecticut       -3.1637        nan        nan        nan         nan         nan\n",
       "team_Central Michigan          -0.8671        nan        nan        nan         nan         nan\n",
       "team_Charleston Southern       -0.6593        nan        nan        nan         nan         nan\n",
       "team_Charlotte                 -1.0190        nan        nan        nan         nan         nan\n",
       "team_Chattanooga               -1.8445        nan        nan        nan         nan         nan\n",
       "team_Chicago St.               -0.1686        nan        nan        nan         nan         nan\n",
       "team_Cincinnati                 1.4819        nan        nan        nan         nan         nan\n",
       "team_Clemson                    2.2638        nan        nan        nan         nan         nan\n",
       "team_Cleveland St.              4.0736        nan        nan        nan         nan         nan\n",
       "team_Coastal Carolina          -1.1694        nan        nan        nan         nan         nan\n",
       "team_Colgate                   -1.3008        nan        nan        nan         nan         nan\n",
       "team_College of Charleston      4.0212        nan        nan        nan         nan         nan\n",
       "team_Colorado                   4.1498        nan        nan        nan         nan         nan\n",
       "team_Colorado St.               3.3349        nan        nan        nan         nan         nan\n",
       "team_Columbia                  -0.9980        nan        nan        nan         nan         nan\n",
       "team_Connecticut                3.0308        nan        nan        nan         nan         nan\n",
       "team_Coppin St.                -0.2473        nan        nan        nan         nan         nan\n",
       "team_Cornell                   -2.2127        nan        nan        nan         nan         nan\n",
       "team_Creighton                  2.6561        nan        nan        nan         nan         nan\n",
       "team_Dartmouth                 -0.4341        nan        nan        nan         nan         nan\n",
       "team_Davidson                  -4.7332        nan        nan        nan         nan         nan\n",
       "team_Dayton                     2.9324        nan        nan        nan         nan         nan\n",
       "team_DePaul                    -1.5304        nan        nan        nan         nan         nan\n",
       "team_Delaware                  -1.8520        nan        nan        nan         nan         nan\n",
       "team_Delaware St.              -0.6421        nan        nan        nan         nan         nan\n",
       "team_Denver                    -2.0404        nan        nan        nan         nan         nan\n",
       "team_Detroit                    4.1260        nan        nan        nan         nan         nan\n",
       "team_Dixie St.                       0        nan        nan        nan         nan         nan\n",
       "team_Drake                     -0.8036        nan        nan        nan         nan         nan\n",
       "team_Drexel                    -1.9042        nan        nan        nan         nan         nan\n",
       "team_Duke                       3.3559        nan        nan        nan         nan         nan\n",
       "team_Duquesne                  -4.5708        nan        nan        nan         nan         nan\n",
       "team_East Carolina             -0.9645        nan        nan        nan         nan         nan\n",
       "team_East Tennessee St.        -1.8583        nan        nan        nan         nan         nan\n",
       "team_Eastern Illinois          -0.2561        nan        nan        nan         nan         nan\n",
       "team_Eastern Kentucky          -3.0108        nan        nan        nan         nan         nan\n",
       "team_Eastern Michigan          -1.8767        nan        nan        nan         nan         nan\n",
       "team_Eastern Washington         4.2031        nan        nan        nan         nan         nan\n",
       "team_Elon                      -0.7282        nan        nan        nan         nan         nan\n",
       "team_Evansville                -4.7173        nan        nan        nan         nan         nan\n",
       "team_FIU                       -0.9508        nan        nan        nan         nan         nan\n",
       "team_Fairfield                 -2.0044        nan        nan        nan         nan         nan\n",
       "team_Fairleigh Dickinson       -0.3290        nan        nan        nan         nan         nan\n",
       "team_Florida                    3.0144        nan        nan        nan         nan         nan\n",
       "team_Florida A&M               -0.4043        nan        nan        nan         nan         nan\n",
       "team_Florida Atlantic          -1.6036        nan        nan        nan         nan         nan\n",
       "team_Florida Gulf Coast        -1.4572        nan        nan        nan         nan         nan\n",
       "team_Florida St.                4.5830        nan        nan        nan         nan         nan\n",
       "team_Fordham                   -1.1035        nan        nan        nan         nan         nan\n",
       "team_Fort Wayne                -1.7447        nan        nan        nan         nan         nan\n",
       "team_Fresno St.                 2.9763        nan        nan        nan         nan         nan\n",
       "team_Furman                    -0.8244        nan        nan        nan         nan         nan\n",
       "team_Gardner Webb              -0.7284        nan        nan        nan         nan         nan\n",
       "team_George Mason              -1.7119        nan        nan        nan         nan         nan\n",
       "team_George Washington         -2.3131        nan        nan        nan         nan         nan\n",
       "team_Georgetown                 0.8144        nan        nan        nan         nan         nan\n",
       "team_Georgia                    2.1559        nan        nan        nan         nan         nan\n",
       "team_Georgia Southern          -1.3959        nan        nan        nan         nan         nan\n",
       "team_Georgia St.               -4.9266        nan        nan        nan         nan         nan\n",
       "team_Georgia Tech               3.3122        nan        nan        nan         nan         nan\n",
       "team_Gonzaga                    2.5125        nan        nan        nan         nan         nan\n",
       "team_Grambling St.             -0.2497        nan        nan        nan         nan         nan\n",
       "team_Grand Canyon              -0.6573        nan        nan        nan         nan         nan\n",
       "team_Green Bay                  3.6114        nan        nan        nan         nan         nan\n",
       "team_Hampton                   -1.3445        nan        nan        nan         nan         nan\n",
       "team_Hartford                  -0.7479        nan        nan        nan         nan         nan\n",
       "team_Harvard                   -2.5650        nan        nan        nan         nan         nan\n",
       "team_Hawaii                    -1.9040        nan        nan        nan         nan         nan\n",
       "team_High Point                -1.3860        nan        nan        nan         nan         nan\n",
       "team_Hofstra                    3.0553        nan        nan        nan         nan         nan\n",
       "team_Holy Cross                -0.4916        nan        nan        nan         nan         nan\n",
       "team_Houston                    2.4092        nan        nan        nan         nan         nan\n",
       "team_Houston Baptist           -0.5558        nan        nan        nan         nan         nan\n",
       "team_Howard                    -0.8456        nan        nan        nan         nan         nan\n",
       "team_IPFW                      -0.8910        nan        nan        nan         nan         nan\n",
       "team_IUPUI                     -1.9115        nan        nan        nan         nan         nan\n",
       "team_Idaho                     -0.7657        nan        nan        nan         nan         nan\n",
       "team_Idaho St.                 -0.3545        nan        nan        nan         nan         nan\n",
       "team_Illinois                   1.3916        nan        nan        nan         nan         nan\n",
       "team_Illinois Chicago          -1.5030        nan        nan        nan         nan         nan\n",
       "team_Illinois St.              -3.8705        nan        nan        nan         nan         nan\n",
       "team_Incarnate Word            -0.1890        nan        nan        nan         nan         nan\n",
       "team_Indiana                    2.8259        nan        nan        nan         nan         nan\n",
       "team_Indiana St.               -0.7938        nan        nan        nan         nan         nan\n",
       "team_Iona                      -4.9339        nan        nan        nan         nan         nan\n",
       "team_Iowa                       0.6138        nan        nan        nan         nan         nan\n",
       "team_Iowa St.                   3.1237        nan        nan        nan         nan         nan\n",
       "team_Jackson St.               -0.4806        nan        nan        nan         nan         nan\n",
       "team_Jacksonville              -0.7400        nan        nan        nan         nan         nan\n",
       "team_Jacksonville St.          -0.4733        nan        nan        nan         nan         nan\n",
       "team_James Madison             -4.6688        nan        nan        nan         nan         nan\n",
       "team_Kansas                     3.1775        nan        nan        nan         nan         nan\n",
       "team_Kansas St.                -6.3273        nan        nan        nan         nan         nan\n",
       "team_Kennesaw St.              -0.3849        nan        nan        nan         nan         nan\n",
       "team_Kent St.                  -1.5827        nan        nan        nan         nan         nan\n",
       "team_Kentucky                   5.8335        nan        nan        nan         nan         nan\n",
       "team_LIU Brooklyn              -1.2535        nan        nan        nan         nan         nan\n",
       "team_LSU                        4.5069        nan        nan        nan         nan         nan\n",
       "team_La Salle                  -3.1954        nan        nan        nan         nan         nan\n",
       "team_Lafayette                 -0.4847        nan        nan        nan         nan         nan\n",
       "team_Lamar                     -0.3427        nan        nan        nan         nan         nan\n",
       "team_Lehigh                    -6.3645        nan        nan        nan         nan         nan\n",
       "team_Liberty                   -1.8599        nan        nan        nan         nan         nan\n",
       "team_Lipscomb                  -1.9018        nan        nan        nan         nan         nan\n",
       "team_Little Rock               -0.8540        nan        nan        nan         nan         nan\n",
       "team_Long Beach St.            -1.2728        nan        nan        nan         nan         nan\n",
       "team_Longwood                  -0.3367        nan        nan        nan         nan         nan\n",
       "team_Louisiana Lafayette       -3.6512        nan        nan        nan         nan         nan\n",
       "team_Louisiana Monroe          -1.5662        nan        nan        nan         nan         nan\n",
       "team_Louisiana Tech            -3.1011        nan        nan        nan         nan         nan\n",
       "team_Louisville                 3.4235        nan        nan        nan         nan         nan\n",
       "team_Loyola Chicago            -1.8842        nan        nan        nan         nan         nan\n",
       "team_Loyola MD                 -1.5555        nan        nan        nan         nan         nan\n",
       "team_Loyola Marymount          -1.2707        nan        nan        nan         nan         nan\n",
       "team_Maine                     -0.4314        nan        nan        nan         nan         nan\n",
       "team_Manhattan                 -1.3019        nan        nan        nan         nan         nan\n",
       "team_Marist                    -0.4559        nan        nan        nan         nan         nan\n",
       "team_Marquette                  3.6039        nan        nan        nan         nan         nan\n",
       "team_Marshall                   1.5605        nan        nan        nan         nan         nan\n",
       "team_Maryland                   4.3040        nan        nan        nan         nan         nan\n",
       "team_Maryland Eastern Shore    -0.2184        nan        nan        nan         nan         nan\n",
       "team_Massachusetts              4.2171        nan        nan        nan         nan         nan\n",
       "team_McNeese St.               -0.7157        nan        nan        nan         nan         nan\n",
       "team_Memphis                    2.4741        nan        nan        nan         nan         nan\n",
       "team_Mercer                    -1.3611        nan        nan        nan         nan         nan\n",
       "team_Merrimack                 -0.0344        nan        nan        nan         nan         nan\n",
       "team_Miami FL                   4.4224        nan        nan        nan         nan         nan\n",
       "team_Miami OH                  -0.6315        nan        nan        nan         nan         nan\n",
       "team_Michigan                   3.2820        nan        nan        nan         nan         nan\n",
       "team_Michigan St.               2.4449        nan        nan        nan         nan         nan\n",
       "team_Middle Tennessee          -2.4854        nan        nan        nan         nan         nan\n",
       "team_Milwaukee                 -0.5077        nan        nan        nan         nan         nan\n",
       "team_Minnesota                  0.7601        nan        nan        nan         nan         nan\n",
       "team_Mississippi               -3.2639        nan        nan        nan         nan         nan\n",
       "team_Mississippi St.            3.4323        nan        nan        nan         nan         nan\n",
       "team_Mississippi Valley St.    -0.2481        nan        nan        nan         nan         nan\n",
       "team_Missouri                   4.3988        nan        nan        nan         nan         nan\n",
       "team_Missouri St.               4.5064        nan        nan        nan         nan         nan\n",
       "team_Monmouth                  -0.6634        nan        nan        nan         nan         nan\n",
       "team_Montana                   -2.3492        nan        nan        nan         nan         nan\n",
       "team_Montana St.               -0.4650        nan        nan        nan         nan         nan\n",
       "team_Morehead St.               1.6594        nan        nan        nan         nan         nan\n",
       "team_Morgan St.                -0.8181        nan        nan        nan         nan         nan\n",
       "team_Mount St. Mary's          -0.4949        nan        nan        nan         nan         nan\n",
       "team_Murray St.                 3.6875        nan        nan        nan         nan         nan\n",
       "team_NJIT                      -0.5952        nan        nan        nan         nan         nan\n",
       "team_Navy                      -0.4754        nan        nan        nan         nan         nan\n",
       "team_Nebraska                   2.1036        nan        nan        nan         nan         nan\n",
       "team_Nebraska Omaha            -0.3974        nan        nan        nan         nan         nan\n",
       "team_Nevada                     2.7194        nan        nan        nan         nan         nan\n",
       "team_New Hampshire             -0.5279        nan        nan        nan         nan         nan\n",
       "team_New Mexico                 2.9661        nan        nan        nan         nan         nan\n",
       "team_New Mexico St.             1.5328        nan        nan        nan         nan         nan\n",
       "team_New Orleans               -0.3360        nan        nan        nan         nan         nan\n",
       "team_Niagara                   -1.1409        nan        nan        nan         nan         nan\n",
       "team_Nicholls St.              -0.5442        nan        nan        nan         nan         nan\n",
       "team_Norfolk St.                3.9780        nan        nan        nan         nan         nan\n",
       "team_North Alabama             -0.0268        nan        nan        nan         nan         nan\n",
       "team_North Carolina             3.4490        nan        nan        nan         nan         nan\n",
       "team_North Carolina A&T        -0.9066        nan        nan        nan         nan         nan\n",
       "team_North Carolina Central    -0.8736        nan        nan        nan         nan         nan\n",
       "team_North Carolina St.         2.0196        nan        nan        nan         nan         nan\n",
       "team_North Dakota              -0.9689        nan        nan        nan         nan         nan\n",
       "team_North Dakota St.          -2.3104        nan        nan        nan         nan         nan\n",
       "team_North Florida             -0.7136        nan        nan        nan         nan         nan\n",
       "team_North Texas                4.8309        nan        nan        nan         nan         nan\n",
       "team_Northeastern              -3.1168        nan        nan        nan         nan         nan\n",
       "team_Northern Arizona          -0.3447        nan        nan        nan         nan         nan\n",
       "team_Northern Colorado         -2.9040        nan        nan        nan         nan         nan\n",
       "team_Northern Illinois         -0.7512        nan        nan        nan         nan         nan\n",
       "team_Northern Iowa             -2.7208        nan        nan        nan         nan         nan\n",
       "team_Northern Kentucky         -1.3150        nan        nan        nan         nan         nan\n",
       "team_Northwestern              -5.6405        nan        nan        nan         nan         nan\n",
       "team_Northwestern St.          -1.3253        nan        nan        nan         nan         nan\n",
       "team_Notre Dame                 2.9522        nan        nan        nan         nan         nan\n",
       "team_Oakland                    2.3677        nan        nan        nan         nan         nan\n",
       "team_Ohio                      -3.0371        nan        nan        nan         nan         nan\n",
       "team_Ohio St.                   2.3078        nan        nan        nan         nan         nan\n",
       "team_Oklahoma                   3.9814        nan        nan        nan         nan         nan\n",
       "team_Oklahoma St.               3.8176        nan        nan        nan         nan         nan\n",
       "team_Old Dominion              -3.0648        nan        nan        nan         nan         nan\n",
       "team_Oral Roberts              -1.6029        nan        nan        nan         nan         nan\n",
       "team_Oregon                     3.5682        nan        nan        nan         nan         nan\n",
       "team_Oregon St.                 1.6525        nan        nan        nan         nan         nan\n",
       "team_Pacific                   -0.6034        nan        nan        nan         nan         nan\n",
       "team_Penn                      -1.9611        nan        nan        nan         nan         nan\n",
       "team_Penn St.                   0.8473        nan        nan        nan         nan         nan\n",
       "team_Pepperdine                -2.0229        nan        nan        nan         nan         nan\n",
       "team_Pittsburgh                 2.9666        nan        nan        nan         nan         nan\n",
       "team_Portland                  -0.7020        nan        nan        nan         nan         nan\n",
       "team_Portland St.              -0.3765        nan        nan        nan         nan         nan\n",
       "team_Prairie View A&M          -0.3011        nan        nan        nan         nan         nan\n",
       "team_Presbyterian              -0.4899        nan        nan        nan         nan         nan\n",
       "team_Princeton                 -2.3369        nan        nan        nan         nan         nan\n",
       "team_Providence                 2.1611        nan        nan        nan         nan         nan\n",
       "team_Purdue                     2.2307        nan        nan        nan         nan         nan\n",
       "team_Quinnipiac                -1.0506        nan        nan        nan         nan         nan\n",
       "team_Radford                   -2.6162        nan        nan        nan         nan         nan\n",
       "team_Rhode Island              -2.5776        nan        nan        nan         nan         nan\n",
       "team_Rice                      -1.6574        nan        nan        nan         nan         nan\n",
       "team_Richmond                   2.0528        nan        nan        nan         nan         nan\n",
       "team_Rider                     -0.7746        nan        nan        nan         nan         nan\n",
       "team_Robert Morris             -1.3765        nan        nan        nan         nan         nan\n",
       "team_Rutgers                    3.9639        nan        nan        nan         nan         nan\n",
       "team_SIU Edwardsville          -0.2538        nan        nan        nan         nan         nan\n",
       "team_SMU                        2.4351        nan        nan        nan         nan         nan\n",
       "team_Sacramento St.            -0.4662        nan        nan        nan         nan         nan\n",
       "team_Sacred Heart              -0.5615        nan        nan        nan         nan         nan\n",
       "team_Saint Joseph's             1.9778        nan        nan        nan         nan         nan\n",
       "team_Saint Louis               -3.5671        nan        nan        nan         nan         nan\n",
       "team_Saint Mary's              -6.7987        nan        nan        nan         nan         nan\n",
       "team_Saint Peter's             -0.6416        nan        nan        nan         nan         nan\n",
       "team_Sam Houston St.           -0.4798        nan        nan        nan         nan         nan\n",
       "team_Samford                   -0.4311        nan        nan        nan         nan         nan\n",
       "team_San Diego                 -2.2121        nan        nan        nan         nan         nan\n",
       "team_San Diego St.              4.0329        nan        nan        nan         nan         nan\n",
       "team_San Francisco             -1.3929        nan        nan        nan         nan         nan\n",
       "team_San Jose St.              -1.9442        nan        nan        nan         nan         nan\n",
       "team_Santa Clara               -2.3898        nan        nan        nan         nan         nan\n",
       "team_Savannah St.              -0.3043        nan        nan        nan         nan         nan\n",
       "team_Seattle                   -0.9197        nan        nan        nan         nan         nan\n",
       "team_Seton Hall                 1.2768        nan        nan        nan         nan         nan\n",
       "team_Siena                     -1.7737        nan        nan        nan         nan         nan\n",
       "team_South Alabama             -0.8885        nan        nan        nan         nan         nan\n",
       "team_South Carolina             2.2311        nan        nan        nan         nan         nan\n",
       "team_South Carolina St.        -0.1495        nan        nan        nan         nan         nan\n",
       "team_South Dakota              -1.6490        nan        nan        nan         nan         nan\n",
       "team_South Dakota St.           2.2624        nan        nan        nan         nan         nan\n",
       "team_South Florida             -1.6755        nan        nan        nan         nan         nan\n",
       "team_Southeast Missouri St.    -0.5439        nan        nan        nan         nan         nan\n",
       "team_Southeastern Louisiana    -1.0275        nan        nan        nan         nan         nan\n",
       "team_Southern                  -1.1942        nan        nan        nan         nan         nan\n",
       "team_Southern Illinois         -0.9616        nan        nan        nan         nan         nan\n",
       "team_Southern Miss             -2.3130        nan        nan        nan         nan         nan\n",
       "team_Southern Utah             -0.3012        nan        nan        nan         nan         nan\n",
       "team_St. Bonaventure            2.5636        nan        nan        nan         nan         nan\n",
       "team_St. Francis NY            -0.4440        nan        nan        nan         nan         nan\n",
       "team_St. Francis PA            -0.6320        nan        nan        nan         nan         nan\n",
       "team_St. John's                 2.2013        nan        nan        nan         nan         nan\n",
       "team_Stanford                   4.5773        nan        nan        nan         nan         nan\n",
       "team_Stephen F. Austin         -4.8989        nan        nan        nan         nan         nan\n",
       "team_Stetson                   -0.3672        nan        nan        nan         nan         nan\n",
       "team_Stony Brook               -4.0936        nan        nan        nan         nan         nan\n",
       "team_Syracuse                   3.4620        nan        nan        nan         nan         nan\n",
       "team_TCU                        2.0216        nan        nan        nan         nan         nan\n",
       "team_Tarleton St.                    0        nan        nan        nan         nan         nan\n",
       "team_Temple                     2.4501        nan        nan        nan         nan         nan\n",
       "team_Tennessee                  4.2137        nan        nan        nan         nan         nan\n",
       "team_Tennessee Martin          -0.2952        nan        nan        nan         nan         nan\n",
       "team_Tennessee St.             -0.9391        nan        nan        nan         nan         nan\n",
       "team_Tennessee Tech            -0.4358        nan        nan        nan         nan         nan\n",
       "team_Texas                      4.1334        nan        nan        nan         nan         nan\n",
       "team_Texas A&M                 -5.3300        nan        nan        nan         nan         nan\n",
       "team_Texas A&M Corpus Chris    -2.8188        nan        nan        nan         nan         nan\n",
       "team_Texas Southern            -2.3490        nan        nan        nan         nan         nan\n",
       "team_Texas St.                 -1.3019        nan        nan        nan         nan         nan\n",
       "team_Texas Tech                 3.6328        nan        nan        nan         nan         nan\n",
       "team_The Citadel               -0.2421        nan        nan        nan         nan         nan\n",
       "team_Toledo                    -2.1299        nan        nan        nan         nan         nan\n",
       "team_Towson                    -1.0201        nan        nan        nan         nan         nan\n",
       "team_Troy                      -0.5486        nan        nan        nan         nan         nan\n",
       "team_Tulane                    -1.2180        nan        nan        nan         nan         nan\n",
       "team_Tulsa                      2.7450        nan        nan        nan         nan         nan\n",
       "team_UAB                       -3.5571        nan        nan        nan         nan         nan\n",
       "team_UC Davis                  -2.0572        nan        nan        nan         nan         nan\n",
       "team_UC Irvine                 -5.8041        nan        nan        nan         nan         nan\n",
       "team_UC Riverside              -0.4628        nan        nan        nan         nan         nan\n",
       "team_UC San Diego                    0        nan        nan        nan         nan         nan\n",
       "team_UC Santa Barbara           2.4961        nan        nan        nan         nan         nan\n",
       "team_UCF                       -9.7422        nan        nan        nan         nan         nan\n",
       "team_UCLA                       4.3008        nan        nan        nan         nan         nan\n",
       "team_UMBC                      -0.6975        nan        nan        nan         nan         nan\n",
       "team_UMKC                      -0.3872        nan        nan        nan         nan         nan\n",
       "team_UMass Lowell              -0.2582        nan        nan        nan         nan         nan\n",
       "team_UNC Asheville             -1.1013        nan        nan        nan         nan         nan\n",
       "team_UNC Greensboro            -1.5339        nan        nan        nan         nan         nan\n",
       "team_UNC Wilmington            -0.9676        nan        nan        nan         nan         nan\n",
       "team_UNLV                       0.5744        nan        nan        nan         nan         nan\n",
       "team_USC                        2.8529        nan        nan        nan         nan         nan\n",
       "team_USC Upstate               -1.4095        nan        nan        nan         nan         nan\n",
       "team_UT Arlington               3.6709        nan        nan        nan         nan         nan\n",
       "team_UT Rio Grande Valley      -0.4003        nan        nan        nan         nan         nan\n",
       "team_UTEP                       3.5101        nan        nan        nan         nan         nan\n",
       "team_UTSA                      -0.7450        nan        nan        nan         nan         nan\n",
       "team_Utah                       3.1768        nan        nan        nan         nan         nan\n",
       "team_Utah St.                   2.7896        nan        nan        nan         nan         nan\n",
       "team_Utah Valley               -0.7691        nan        nan        nan         nan         nan\n",
       "team_VCU                        2.2337        nan        nan        nan         nan         nan\n",
       "team_VMI                       -0.9119        nan        nan        nan         nan         nan\n",
       "team_Valparaiso                 1.8765        nan        nan        nan         nan         nan\n",
       "team_Vanderbilt                 4.2071        nan        nan        nan         nan         nan\n",
       "team_Vermont                   -6.2479        nan        nan        nan         nan         nan\n",
       "team_Villanova                  2.8918        nan        nan        nan         nan         nan\n",
       "team_Virginia                   3.7716        nan        nan        nan         nan         nan\n",
       "team_Virginia Tech              2.4768        nan        nan        nan         nan         nan\n",
       "team_Wagner                    -0.5700        nan        nan        nan         nan         nan\n",
       "team_Wake Forest                2.6031        nan        nan        nan         nan         nan\n",
       "team_Washington                 4.3090        nan        nan        nan         nan         nan\n",
       "team_Washington St.             0.6532        nan        nan        nan         nan         nan\n",
       "team_Weber St.                  3.5561        nan        nan        nan         nan         nan\n",
       "team_West Virginia              2.7738        nan        nan        nan         nan         nan\n",
       "team_Western Carolina          -0.5709        nan        nan        nan         nan         nan\n",
       "team_Western Illinois          -1.2674        nan        nan        nan         nan         nan\n",
       "team_Western Kentucky           2.5592        nan        nan        nan         nan         nan\n",
       "team_Western Michigan          -2.1992        nan        nan        nan         nan         nan\n",
       "team_Wichita St.                3.1715        nan        nan        nan         nan         nan\n",
       "team_William & Mary             3.4010        nan        nan        nan         nan         nan\n",
       "team_Winston Salem St.         -0.0255        nan        nan        nan         nan         nan\n",
       "team_Winthrop                  -1.5291        nan        nan        nan         nan         nan\n",
       "team_Wisconsin                  0.0422        nan        nan        nan         nan         nan\n",
       "team_Wofford                   -1.9523        nan        nan        nan         nan         nan\n",
       "team_Wright St.                -1.5615        nan        nan        nan         nan         nan\n",
       "team_Wyoming                    2.7601        nan        nan        nan         nan         nan\n",
       "team_Xavier                     3.0310        nan        nan        nan         nan         nan\n",
       "team_Yale                       2.8697        nan        nan        nan         nan         nan\n",
       "team_Youngstown St.            -1.3588        nan        nan        nan         nan         nan\n",
       "0.0/1.0                        11.8852        nan        nan        nan         nan         nan\n",
       "===============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_log = OrderedModel(y_train,\n",
    "                        X_train,\n",
    "                        distr='logit')\n",
    "res_log = mod_log.fit(method='bfgs')\n",
    "res_log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.38527063e-07, 6.92393659e-08, 5.57754047e-07, ...,\n",
       "       1.59992350e-08, 6.91601199e-09, 1.38930422e-07])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted2 = res_log.model.predict(res_log.params, exog=X_test)[:,1]\n",
    "predicted2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_round_drafted\n",
       "0.0    28\n",
       "1.0     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_df5 = pd.DataFrame(predicted2)\n",
    "pred_proba_df5.columns = ['pred-prob']\n",
    "df_2021 = df_2021.reset_index(drop=True)\n",
    "\n",
    "merged_df5 = df_2021.merge(pred_proba_df5, left_index=True, right_index=True)\n",
    "\n",
    "selected_by_model = merged_df5.sort_values('pred-prob', ascending=False).head(30)\n",
    "selected_by_model.first_round_drafted.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
